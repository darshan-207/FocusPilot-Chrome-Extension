{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5332e5c9-de61-4b26-b195-8d795ac49048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory\n",
    "base_dir = \"./dataset\"\n",
    "categories = [\"productive\", \"unproductive\"]\n",
    "\n",
    "for cat in categories:\n",
    "    path = os.path.join(base_dir, cat)\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ab4afc-1cca-415a-b22a-c4d8f724f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PHASE 1: COLLECTING PRODUCTIVE CONTENT\n",
      "======================================================================\n",
      "\n",
      "[Wikipedia] Scraping category: Computer_science\n",
      "  Collected 16 pages from Computer_science\n",
      "\n",
      "[Wikipedia] Scraping category: Algorithms\n",
      "  Collected 137 pages from Algorithms\n",
      "\n",
      "[Wikipedia] Scraping category: Data_structures\n",
      "  Collected 22 pages from Data_structures\n",
      "\n",
      "[Wikipedia] Scraping category: Programming_languages\n",
      "  Collected 172 pages from Programming_languages\n",
      "\n",
      "[Wikipedia] Scraping category: Machine_learning\n",
      "  Collected 200 pages from Machine_learning\n",
      "\n",
      "[Wikipedia] Scraping category: Software_engineering\n",
      "  Collected 59 pages from Software_engineering\n",
      "\n",
      "[Wikipedia] Scraping category: Computer_programming\n",
      "  Collected 139 pages from Computer_programming\n",
      "\n",
      "[Wikipedia] Scraping category: Mathematics\n",
      "  Collected 3 pages from Mathematics\n",
      "\n",
      "[Wikipedia] Scraping category: Physics\n",
      "  Collected 24 pages from Physics\n",
      "\n",
      "[Wikipedia] Scraping category: Biology\n",
      "  Collected 22 pages from Biology\n",
      "\n",
      "Total productive URLs collected: 797\n",
      "\n",
      "======================================================================\n",
      "Scraping 797 items for: PRODUCTIVE\n",
      "Target: 3000 samples\n",
      "======================================================================\n",
      "\n",
      "[1/797] Productive: 0 saved | https://en.wikipedia.org/wiki/Computer_science...\n",
      "  ✓ Saved (1 total)\n",
      "[2/797] Productive: 1 saved | https://en.wikipedia.org/wiki/Glossary_of_computer_science...\n",
      "  ✓ Saved (2 total)\n",
      "[3/797] Productive: 2 saved | https://en.wikipedia.org/wiki/Agnostic_(data)...\n",
      "  ✓ Saved (3 total)\n",
      "[4/797] Productive: 3 saved | https://en.wikipedia.org/wiki/Boolean...\n",
      "  ✓ Saved (4 total)\n",
      "[5/797] Productive: 4 saved | https://en.wikipedia.org/wiki/Catalytic_computing...\n",
      "  ✓ Saved (5 total)\n",
      "[6/797] Productive: 5 saved | https://en.wikipedia.org/wiki/Computational_gastronomy...\n",
      "  ✓ Saved (6 total)\n",
      "[7/797] Productive: 6 saved | https://en.wikipedia.org/wiki/Computer_science_in_sport...\n",
      "  ✓ Saved (7 total)\n",
      "[8/797] Productive: 7 saved | https://en.wikipedia.org/wiki/Filter_and_refine...\n",
      "  ✓ Saved (8 total)\n",
      "[9/797] Productive: 8 saved | https://en.wikipedia.org/wiki/LinkML...\n",
      "  ✓ Saved (9 total)\n",
      "[10/797] Productive: 9 saved | https://en.wikipedia.org/wiki/List_of_abstractions_(computer...\n",
      "  ✓ Saved (10 total)\n",
      "[11/797] Productive: 10 saved | https://en.wikipedia.org/wiki/Outline_of_computer_science...\n",
      "  ✓ Saved (11 total)\n",
      "[12/797] Productive: 11 saved | https://en.wikipedia.org/wiki/Peripheral...\n",
      "  ✓ Saved (12 total)\n",
      "[13/797] Productive: 12 saved | https://en.wikipedia.org/wiki/Prefetching...\n",
      "  ✓ Saved (13 total)\n",
      "[14/797] Productive: 13 saved | https://en.wikipedia.org/wiki/Technology_transfer_in_compute...\n",
      "  ✓ Saved (14 total)\n",
      "[15/797] Productive: 14 saved | https://en.wikipedia.org/wiki/Thermodynamic_computing...\n",
      "  ✓ Saved (15 total)\n",
      "[16/797] Productive: 15 saved | https://en.wikipedia.org/wiki/Transition_(computer_science)...\n",
      "  ✓ Saved (16 total)\n",
      "[17/797] Productive: 16 saved | https://en.wikipedia.org/wiki/Algorithm...\n",
      "  ✓ Saved (17 total)\n",
      "[18/797] Productive: 17 saved | https://en.wikipedia.org/wiki/List_of_algorithm_general_topi...\n",
      "  ✓ Saved (18 total)\n",
      "[19/797] Productive: 18 saved | https://en.wikipedia.org/wiki/List_of_algorithms...\n",
      "  ✓ Saved (19 total)\n",
      "[20/797] Productive: 19 saved | https://en.wikipedia.org/wiki/Unrestricted_algorithm...\n",
      "  ✓ Saved (20 total)\n",
      "[21/797] Productive: 20 saved | https://en.wikipedia.org/wiki/Adaptive_algorithm...\n",
      "  ✓ Saved (21 total)\n",
      "[22/797] Productive: 21 saved | https://en.wikipedia.org/wiki/Algorism...\n",
      "  ✓ Saved (22 total)\n",
      "[23/797] Productive: 22 saved | https://en.wikipedia.org/wiki/The_Algorithm_Auction...\n",
      "  ✓ Saved (23 total)\n",
      "[24/797] Productive: 23 saved | https://en.wikipedia.org/wiki/Algorithm_characterizations...\n",
      "  ✓ Saved (24 total)\n",
      "[25/797] Productive: 24 saved | https://en.wikipedia.org/wiki/Algorithm_engineering...\n",
      "  ✓ Saved (25 total)\n",
      "[26/797] Productive: 25 saved | https://en.wikipedia.org/wiki/Algorithmic_game_theory...\n",
      "  ✓ Saved (26 total)\n",
      "[27/797] Productive: 26 saved | https://en.wikipedia.org/wiki/Algorithmic_logic...\n",
      "  ✓ Saved (27 total)\n",
      "[28/797] Productive: 27 saved | https://en.wikipedia.org/wiki/Algorithmic_management...\n",
      "  ✓ Saved (28 total)\n",
      "[29/797] Productive: 28 saved | https://en.wikipedia.org/wiki/Algorithmic_mechanism_design...\n",
      "  ✓ Saved (29 total)\n",
      "[30/797] Productive: 29 saved | https://en.wikipedia.org/wiki/Algorithmic_paradigm...\n",
      "  ✓ Saved (30 total)\n",
      "[31/797] Productive: 30 saved | https://en.wikipedia.org/wiki/Algorithmic_Puzzles...\n",
      "  ✓ Saved (31 total)\n",
      "[32/797] Productive: 31 saved | https://en.wikipedia.org/wiki/Algorithmic_transparency...\n",
      "  ✓ Saved (32 total)\n",
      "[33/797] Productive: 32 saved | https://en.wikipedia.org/wiki/Algorithms_and_Combinatorics...\n",
      "  ✓ Saved (33 total)\n",
      "[34/797] Productive: 33 saved | https://en.wikipedia.org/wiki/Algorithms_of_Oppression...\n",
      "  ✓ Saved (34 total)\n",
      "[35/797] Productive: 34 saved | https://en.wikipedia.org/wiki/Automate_This...\n",
      "  ✓ Saved (35 total)\n",
      "[36/797] Productive: 35 saved | https://en.wikipedia.org/wiki/AVT_Statistical_filtering_algo...\n",
      "  ✓ Saved (36 total)\n",
      "[37/797] Productive: 36 saved | https://en.wikipedia.org/wiki/Bartels–Stewart_algorithm...\n",
      "  ✓ Saved (37 total)\n",
      "[38/797] Productive: 37 saved | https://en.wikipedia.org/wiki/Behavior_selection_algorithm...\n",
      "  ✓ Saved (38 total)\n",
      "[39/797] Productive: 38 saved | https://en.wikipedia.org/wiki/Berlekamp–Rabin_algorithm...\n",
      "  ✓ Saved (39 total)\n",
      "[40/797] Productive: 39 saved | https://en.wikipedia.org/wiki/Birkhoff_algorithm...\n",
      "  ✓ Saved (40 total)\n",
      "[41/797] Productive: 40 saved | https://en.wikipedia.org/wiki/Bisection_(software_engineerin...\n",
      "  ✓ Saved (41 total)\n",
      "[42/797] Productive: 41 saved | https://en.wikipedia.org/wiki/Block_swap_algorithms...\n",
      "  ✓ Saved (42 total)\n",
      "[43/797] Productive: 42 saved | https://en.wikipedia.org/wiki/British_Museum_algorithm...\n",
      "  ✓ Saved (43 total)\n",
      "[44/797] Productive: 43 saved | https://en.wikipedia.org/wiki/Broadcast_(parallel_pattern)...\n",
      "  ✓ Saved (44 total)\n",
      "[45/797] Productive: 44 saved | https://en.wikipedia.org/wiki/Car–Parrinello_molecular_dynam...\n",
      "  ✓ Saved (45 total)\n",
      "[46/797] Productive: 45 saved | https://en.wikipedia.org/wiki/Catalytic_computing...\n",
      "  ✓ Saved (46 total)\n",
      "[47/797] Productive: 46 saved | https://en.wikipedia.org/wiki/Certifying_algorithm...\n",
      "  ✓ Saved (47 total)\n",
      "[48/797] Productive: 47 saved | https://en.wikipedia.org/wiki/Chandy–Misra–Haas_algorithm_re...\n",
      "  ✓ Saved (48 total)\n",
      "[49/797] Productive: 48 saved | https://en.wikipedia.org/wiki/Collaborative_diffusion...\n",
      "  ✓ Saved (49 total)\n",
      "[50/797] Productive: 49 saved | https://en.wikipedia.org/wiki/Collective_operation...\n",
      "  ✓ Saved (50 total)\n",
      "[51/797] Productive: 50 saved | https://en.wikipedia.org/wiki/Collision_problem...\n",
      "  ✓ Saved (51 total)\n",
      "[52/797] Productive: 51 saved | https://en.wikipedia.org/wiki/Communication-avoiding_algorit...\n",
      "  ✓ Saved (52 total)\n",
      "[53/797] Productive: 52 saved | https://en.wikipedia.org/wiki/Symposium_on_Experimental_Algo...\n",
      "  ✓ Saved (53 total)\n",
      "[54/797] Productive: 53 saved | https://en.wikipedia.org/wiki/Decrease-and-conquer...\n",
      "  ✓ Saved (54 total)\n",
      "[55/797] Productive: 54 saved | https://en.wikipedia.org/wiki/Dependency_network_(graphical_...\n",
      "  ✓ Saved (55 total)\n",
      "[56/797] Productive: 55 saved | https://en.wikipedia.org/wiki/Devex_algorithm...\n",
      "  ✓ Saved (56 total)\n",
      "[57/797] Productive: 56 saved | https://en.wikipedia.org/wiki/Distributed_tree_search...\n",
      "  ✓ Saved (57 total)\n",
      "[58/797] Productive: 57 saved | https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm...\n",
      "  ✓ Saved (58 total)\n",
      "[59/797] Productive: 58 saved | https://en.wikipedia.org/wiki/Domain_reduction_algorithm...\n",
      "  ✓ Saved (59 total)\n",
      "[60/797] Productive: 59 saved | https://en.wikipedia.org/wiki/DONE...\n",
      "  ✓ Saved (60 total)\n",
      "[61/797] Productive: 60 saved | https://en.wikipedia.org/wiki/Driver_scheduling_problem...\n",
      "  ✓ Saved (61 total)\n",
      "[62/797] Productive: 61 saved | https://en.wikipedia.org/wiki/EdgeRank...\n",
      "  ✓ Saved (62 total)\n",
      "[63/797] Productive: 62 saved | https://en.wikipedia.org/wiki/Education_by_algorithm...\n",
      "  ✓ Saved (63 total)\n",
      "[64/797] Productive: 63 saved | https://en.wikipedia.org/wiki/Emergent_algorithm...\n",
      "  ✓ Saved (64 total)\n",
      "[65/797] Productive: 64 saved | https://en.wikipedia.org/wiki/Enumeration_algorithm...\n",
      "  ✓ Saved (65 total)\n",
      "[66/797] Productive: 65 saved | https://en.wikipedia.org/wiki/External_memory_algorithm...\n",
      "  ✓ Saved (66 total)\n",
      "[67/797] Productive: 66 saved | https://en.wikipedia.org/wiki/Flajolet–Martin_algorithm...\n",
      "  ✓ Saved (67 total)\n",
      "[68/797] Productive: 67 saved | https://en.wikipedia.org/wiki/Free_Spaced_Repetition_Schedul...\n",
      "  ✓ Saved (68 total)\n",
      "[69/797] Productive: 68 saved | https://en.wikipedia.org/wiki/Generalized_distributive_law...\n",
      "  ✓ Saved (69 total)\n",
      "[70/797] Productive: 69 saved | https://en.wikipedia.org/wiki/Gutmann_method...\n",
      "  ✓ Saved (70 total)\n",
      "[71/797] Productive: 70 saved | https://en.wikipedia.org/wiki/HAKMEM...\n",
      "  ✓ Saved (71 total)\n",
      "[72/797] Productive: 71 saved | https://en.wikipedia.org/wiki/Hall_circles...\n",
      "  ✓ Saved (72 total)\n",
      "[73/797] Productive: 72 saved | https://en.wikipedia.org/wiki/Higuchi_dimension...\n",
      "  ✓ Saved (73 total)\n",
      "[74/797] Productive: 73 saved | https://en.wikipedia.org/wiki/Hindley–Milner_type_system...\n",
      "  ✓ Saved (74 total)\n",
      "[75/797] Productive: 74 saved | https://en.wikipedia.org/wiki/Holographic_algorithm...\n",
      "  ✓ Saved (75 total)\n",
      "[76/797] Productive: 75 saved | https://en.wikipedia.org/wiki/How_to_Solve_it_by_Computer...\n",
      "  ✓ Saved (76 total)\n",
      "[77/797] Productive: 76 saved | https://en.wikipedia.org/wiki/Hybrid_algorithm...\n",
      "  ✓ Saved (77 total)\n",
      "[78/797] Productive: 77 saved | https://en.wikipedia.org/wiki/Hyphenation_algorithm...\n",
      "  ✓ Saved (78 total)\n",
      "[79/797] Productive: 78 saved | https://en.wikipedia.org/wiki/In-place_algorithm...\n",
      "  ✓ Saved (79 total)\n",
      "[80/797] Productive: 79 saved | https://en.wikipedia.org/wiki/Irish_logarithm...\n",
      "  ✓ Saved (80 total)\n",
      "[81/797] Productive: 80 saved | https://en.wikipedia.org/wiki/Iteration...\n",
      "  ✓ Saved (81 total)\n",
      "[82/797] Productive: 81 saved | https://en.wikipedia.org/wiki/Jumble_algorithm...\n",
      "  ✓ Saved (82 total)\n",
      "[83/797] Productive: 82 saved | https://en.wikipedia.org/wiki/Jump-and-Walk_algorithm...\n",
      "  ✓ Saved (83 total)\n",
      "[84/797] Productive: 83 saved | https://en.wikipedia.org/wiki/Kinodynamic_planning...\n",
      "  ✓ Saved (84 total)\n",
      "[85/797] Productive: 84 saved | https://en.wikipedia.org/wiki/KiSAO...\n",
      "  ✓ Saved (85 total)\n",
      "[86/797] Productive: 85 saved | https://en.wikipedia.org/wiki/Kleene's_algorithm...\n",
      "  ✓ Saved (86 total)\n",
      "[87/797] Productive: 86 saved | https://en.wikipedia.org/wiki/Knuth–Eve_algorithm...\n",
      "  ✓ Saved (87 total)\n",
      "[88/797] Productive: 87 saved | https://en.wikipedia.org/wiki/Knuth–Plass_line-breaking_algo...\n",
      "  ✓ Saved (88 total)\n",
      "[89/797] Productive: 88 saved | https://en.wikipedia.org/wiki/Kunstweg...\n",
      "  ✓ Saved (89 total)\n",
      "[90/797] Productive: 89 saved | https://en.wikipedia.org/wiki/Lancichinetti–Fortunato–Radicc...\n",
      "  ✓ Saved (90 total)\n",
      "[91/797] Productive: 90 saved | https://en.wikipedia.org/wiki/Learning_augmented_algorithm...\n",
      "  ✓ Saved (91 total)\n",
      "[92/797] Productive: 91 saved | https://en.wikipedia.org/wiki/Least-squares_spectral_analysi...\n",
      "  ✓ Saved (92 total)\n",
      "[93/797] Productive: 92 saved | https://en.wikipedia.org/wiki/Leiden_algorithm...\n",
      "  ✓ Saved (93 total)\n",
      "[94/797] Productive: 93 saved | https://en.wikipedia.org/wiki/Lion_algorithm...\n",
      "  ✓ Saved (94 total)\n",
      "[95/797] Productive: 94 saved | https://en.wikipedia.org/wiki/List_of_cryptosystems...\n",
      "  ✓ Saved (95 total)\n",
      "[96/797] Productive: 95 saved | https://en.wikipedia.org/wiki/Long_division...\n",
      "  ✓ Saved (96 total)\n",
      "[97/797] Productive: 96 saved | https://en.wikipedia.org/wiki/Magic_state_distillation...\n",
      "  ✓ Saved (97 total)\n",
      "[98/797] Productive: 97 saved | https://en.wikipedia.org/wiki/Plotting_algorithms_for_the_Ma...\n",
      "  ✓ Saved (98 total)\n",
      "[99/797] Productive: 98 saved | https://en.wikipedia.org/wiki/Manhattan_address_algorithm...\n",
      "  ✓ Saved (99 total)\n",
      "[100/797] Productive: 99 saved | https://en.wikipedia.org/wiki/March_algorithm...\n",
      "  ✓ Saved (100 total)\n",
      "[101/797] Productive: 100 saved | https://en.wikipedia.org/wiki/The_Master_Algorithm...\n",
      "  ✓ Saved (101 total)\n",
      "[102/797] Productive: 101 saved | https://en.wikipedia.org/wiki/Maze_generation_algorithm...\n",
      "  ✓ Saved (102 total)\n",
      "[103/797] Productive: 102 saved | https://en.wikipedia.org/wiki/Maze-solving_algorithm...\n",
      "  ✓ Saved (103 total)\n",
      "[104/797] Productive: 103 saved | https://en.wikipedia.org/wiki/Medical_algorithm...\n",
      "  ✓ Saved (104 total)\n",
      "[105/797] Productive: 104 saved | https://en.wikipedia.org/wiki/Miller's_recurrence_algorithm...\n",
      "  ✓ Saved (105 total)\n",
      "[106/797] Productive: 105 saved | https://en.wikipedia.org/wiki/Multiplicative_weight_update_m...\n",
      "  ✓ Saved (106 total)\n",
      "[107/797] Productive: 106 saved | https://en.wikipedia.org/wiki/Neural_style_transfer...\n",
      "  ✓ Saved (107 total)\n",
      "[108/797] Productive: 107 saved | https://en.wikipedia.org/wiki/Newest_vertex_bisection...\n",
      "  ✓ Saved (108 total)\n",
      "[109/797] Productive: 108 saved | https://en.wikipedia.org/wiki/Newman–Janis_algorithm...\n",
      "  ✓ Saved (109 total)\n",
      "[110/797] Productive: 109 saved | https://en.wikipedia.org/wiki/Non-malleable_code...\n",
      "  ✓ Saved (110 total)\n",
      "[111/797] Productive: 110 saved | https://en.wikipedia.org/wiki/Note_G...\n",
      "  ✓ Saved (111 total)\n",
      "[112/797] Productive: 111 saved | https://en.wikipedia.org/wiki/Online_optimization...\n",
      "  ✓ Saved (112 total)\n",
      "[113/797] Productive: 112 saved | https://en.wikipedia.org/wiki/Pan–Tompkins_algorithm...\n",
      "  ✓ Saved (113 total)\n",
      "[114/797] Productive: 113 saved | https://en.wikipedia.org/wiki/Parallel_external_memory...\n",
      "  ✓ Saved (114 total)\n",
      "[115/797] Productive: 114 saved | https://en.wikipedia.org/wiki/Parameterized_approximation_al...\n",
      "  ✓ Saved (115 total)\n",
      "[116/797] Productive: 115 saved | https://en.wikipedia.org/wiki/PHY-Level_Collision_Avoidance...\n",
      "  ✓ Saved (116 total)\n",
      "[117/797] Productive: 116 saved | https://en.wikipedia.org/wiki/Ping-pong_scheme...\n",
      "  ✓ Saved (117 total)\n",
      "[118/797] Productive: 117 saved | https://en.wikipedia.org/wiki/Pointer_algorithm...\n",
      "  ✓ Saved (118 total)\n",
      "[119/797] Productive: 118 saved | https://en.wikipedia.org/wiki/Pointer_jumping...\n",
      "  ✓ Saved (119 total)\n",
      "[120/797] Productive: 119 saved | https://en.wikipedia.org/wiki/Pol.is...\n",
      "  ✓ Saved (120 total)\n",
      "[121/797] Productive: 120 saved | https://en.wikipedia.org/wiki/Predictor–corrector_method...\n",
      "  ✓ Saved (121 total)\n",
      "[122/797] Productive: 121 saved | https://en.wikipedia.org/wiki/Proof_of_authority...\n",
      "  ✓ Saved (122 total)\n",
      "[123/797] Productive: 122 saved | https://en.wikipedia.org/wiki/Randomized_rounding...\n",
      "  ✓ Saved (123 total)\n",
      "[124/797] Productive: 123 saved | https://en.wikipedia.org/wiki/Regulation_of_algorithms...\n",
      "  ✓ Saved (124 total)\n",
      "[125/797] Productive: 124 saved | https://en.wikipedia.org/wiki/Rendezvous_hashing...\n",
      "  ✓ Saved (125 total)\n",
      "[126/797] Productive: 125 saved | https://en.wikipedia.org/wiki/Reservoir_sampling...\n",
      "  ✓ Saved (126 total)\n",
      "[127/797] Productive: 126 saved | https://en.wikipedia.org/wiki/Right_to_explanation...\n",
      "  ✓ Saved (127 total)\n",
      "[128/797] Productive: 127 saved | https://en.wikipedia.org/wiki/Run-time_algorithm_specializat...\n",
      "  ✓ Saved (128 total)\n",
      "[129/797] Productive: 128 saved | https://en.wikipedia.org/wiki/Run-to-completion_scheduling...\n",
      "  ✓ Saved (129 total)\n",
      "[130/797] Productive: 129 saved | https://en.wikipedia.org/wiki/Sardinas–Patterson_algorithm...\n",
      "  ✓ Saved (130 total)\n",
      "[131/797] Productive: 130 saved | https://en.wikipedia.org/wiki/Sequential_algorithm...\n",
      "  ✓ Saved (131 total)\n",
      "[132/797] Productive: 131 saved | https://en.wikipedia.org/wiki/Serial_algorithm...\n",
      "  ✓ Saved (132 total)\n",
      "[133/797] Productive: 132 saved | https://en.wikipedia.org/wiki/Shapiro–Senapathy_algorithm...\n",
      "  ✓ Saved (133 total)\n",
      "[134/797] Productive: 133 saved | https://en.wikipedia.org/wiki/Shuffling_algorithm...\n",
      "  ✓ Saved (134 total)\n",
      "[135/797] Productive: 134 saved | https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes...\n",
      "  ✓ Saved (135 total)\n",
      "[136/797] Productive: 135 saved | https://en.wikipedia.org/wiki/Sieve_of_Pritchard...\n",
      "  ✓ Saved (136 total)\n",
      "[137/797] Productive: 136 saved | https://en.wikipedia.org/wiki/Sikidy...\n",
      "  ✓ Saved (137 total)\n",
      "[138/797] Productive: 137 saved | https://en.wikipedia.org/wiki/Snap_rounding...\n",
      "  ✓ Saved (138 total)\n",
      "[139/797] Productive: 138 saved | https://en.wikipedia.org/wiki/Sparse_identification_of_non-l...\n",
      "  ✓ Saved (139 total)\n",
      "[140/797] Productive: 139 saved | https://en.wikipedia.org/wiki/Spreading_activation...\n",
      "  ✓ Saved (140 total)\n",
      "[141/797] Productive: 140 saved | https://en.wikipedia.org/wiki/Tarjan's_algorithm...\n",
      "  ✓ Saved (141 total)\n",
      "[142/797] Productive: 141 saved | https://en.wikipedia.org/wiki/Text-to-video_model...\n",
      "  ✓ Saved (142 total)\n",
      "[143/797] Productive: 142 saved | https://en.wikipedia.org/wiki/Time_Warp_Edit_Distance...\n",
      "  ✓ Saved (143 total)\n",
      "[144/797] Productive: 143 saved | https://en.wikipedia.org/wiki/Timeline_of_algorithms...\n",
      "  ✓ Saved (144 total)\n",
      "[145/797] Productive: 144 saved | https://en.wikipedia.org/wiki/Token-based_replay...\n",
      "  ✓ Saved (145 total)\n",
      "[146/797] Productive: 145 saved | https://en.wikipedia.org/wiki/Recommender_system...\n",
      "  ✓ Saved (146 total)\n",
      "[147/797] Productive: 146 saved | https://en.wikipedia.org/wiki/Upper_Confidence_Bound...\n",
      "  ✓ Saved (147 total)\n",
      "[148/797] Productive: 147 saved | https://en.wikipedia.org/wiki/Weak_stability_boundary...\n",
      "  ✓ Saved (148 total)\n",
      "[149/797] Productive: 148 saved | https://en.wikipedia.org/wiki/Whitehead's_algorithm...\n",
      "  ✓ Saved (149 total)\n",
      "[150/797] Productive: 149 saved | https://en.wikipedia.org/wiki/Wiki_survey...\n",
      "  ✓ Saved (150 total)\n",
      "[151/797] Productive: 150 saved | https://en.wikipedia.org/wiki/XOR_swap_algorithm...\n",
      "  ✓ Saved (151 total)\n",
      "[152/797] Productive: 151 saved | https://en.wikipedia.org/wiki/Xulvi-Brunet–Sokolov_algorithm...\n",
      "  ✓ Saved (152 total)\n",
      "[153/797] Productive: 152 saved | https://en.wikipedia.org/wiki/Zassenhaus_algorithm...\n",
      "  ✓ Saved (153 total)\n",
      "[154/797] Productive: 153 saved | https://en.wikipedia.org/wiki/Data_structure...\n",
      "  ✓ Saved (154 total)\n",
      "[155/797] Productive: 154 saved | https://en.wikipedia.org/wiki/Region_(model_checking)...\n",
      "  ✓ Saved (155 total)\n",
      "[156/797] Productive: 155 saved | https://en.wikipedia.org/wiki/List_of_data_structures...\n",
      "  ✓ Saved (156 total)\n",
      "[157/797] Productive: 156 saved | https://en.wikipedia.org/wiki/Active_data_structure...\n",
      "  ✓ Saved (157 total)\n",
      "[158/797] Productive: 157 saved | https://en.wikipedia.org/wiki/Block_availability_map...\n",
      "  ✓ Saved (158 total)\n",
      "[159/797] Productive: 158 saved | https://en.wikipedia.org/wiki/Comparison_of_data_structures...\n",
      "  ✓ Saved (159 total)\n",
      "[160/797] Productive: 159 saved | https://en.wikipedia.org/wiki/Compressed_data_structure...\n",
      "  ✓ Saved (160 total)\n",
      "[161/797] Productive: 160 saved | https://en.wikipedia.org/wiki/Dynamization...\n",
      "  ✓ Saved (161 total)\n",
      "[162/797] Productive: 161 saved | https://en.wikipedia.org/wiki/Implicit_data_structure...\n",
      "  ✓ Saved (162 total)\n",
      "[163/797] Productive: 162 saved | https://en.wikipedia.org/wiki/Interval_union-split-find...\n",
      "  ✓ Saved (163 total)\n",
      "[164/797] Productive: 163 saved | https://en.wikipedia.org/wiki/Monoque...\n",
      "  ✓ Saved (164 total)\n",
      "[165/797] Productive: 164 saved | https://en.wikipedia.org/wiki/Oblivious_data_structure...\n",
      "  ✓ Saved (165 total)\n",
      "[166/797] Productive: 165 saved | https://en.wikipedia.org/wiki/Partition_refinement...\n",
      "  ✓ Saved (166 total)\n",
      "[167/797] Productive: 166 saved | https://en.wikipedia.org/wiki/Partitioned_Elias–Fano_indexes...\n",
      "  ✓ Saved (167 total)\n",
      "[168/797] Productive: 167 saved | https://en.wikipedia.org/wiki/Persistent_data_structure...\n",
      "  ✓ Saved (168 total)\n",
      "[169/797] Productive: 168 saved | https://en.wikipedia.org/wiki/Postings_list...\n",
      "  ✓ Saved (169 total)\n",
      "[170/797] Productive: 169 saved | https://en.wikipedia.org/wiki/Predecessor_problem...\n",
      "  ✓ Saved (170 total)\n",
      "[171/797] Productive: 170 saved | https://en.wikipedia.org/wiki/Retroactive_data_structure...\n",
      "  ✓ Saved (171 total)\n",
      "[172/797] Productive: 171 saved | https://en.wikipedia.org/wiki/Routing_table...\n",
      "  ✓ Saved (172 total)\n",
      "[173/797] Productive: 172 saved | https://en.wikipedia.org/wiki/Search_data_structure...\n",
      "  ✓ Saved (173 total)\n",
      "[174/797] Productive: 173 saved | https://en.wikipedia.org/wiki/Set_intersection_oracle...\n",
      "  ✓ Saved (174 total)\n",
      "[175/797] Productive: 174 saved | https://en.wikipedia.org/wiki/Term_indexing...\n",
      "  ✓ Saved (175 total)\n",
      "[176/797] Productive: 175 saved | https://en.wikipedia.org/wiki/Programming_language...\n",
      "  ✓ Saved (176 total)\n",
      "[177/797] Productive: 176 saved | https://en.wikipedia.org/wiki/ABAP...\n",
      "  ✓ Saved (177 total)\n",
      "[178/797] Productive: 177 saved | https://en.wikipedia.org/wiki/Ada_(programming_language)...\n",
      "  ✓ Saved (178 total)\n",
      "[179/797] Productive: 178 saved | https://en.wikipedia.org/wiki/Address_programming_language...\n",
      "  ✓ Saved (179 total)\n",
      "[180/797] Productive: 179 saved | https://en.wikipedia.org/wiki/Agda_(programming_language)...\n",
      "  ✓ Saved (180 total)\n",
      "[181/797] Productive: 180 saved | https://en.wikipedia.org/wiki/ALGOL_68...\n",
      "  ✓ Saved (181 total)\n",
      "[182/797] Productive: 181 saved | https://en.wikipedia.org/wiki/Apache_Groovy...\n",
      "  ✓ Saved (182 total)\n",
      "[183/797] Productive: 182 saved | https://en.wikipedia.org/wiki/APL_(programming_language)...\n",
      "  ✓ Saved (183 total)\n",
      "[184/797] Productive: 183 saved | https://en.wikipedia.org/wiki/Apple_(programming_language)...\n",
      "  ✓ Saved (184 total)\n",
      "[185/797] Productive: 184 saved | https://en.wikipedia.org/wiki/AppleScript...\n",
      "  ✓ Saved (185 total)\n",
      "[186/797] Productive: 185 saved | https://en.wikipedia.org/wiki/AspectJ...\n",
      "  ✓ Saved (186 total)\n",
      "[187/797] Productive: 186 saved | https://en.wikipedia.org/wiki/B_(programming_language)...\n",
      "  ✓ Saved (187 total)\n",
      "[188/797] Productive: 187 saved | https://en.wikipedia.org/wiki/BASIC...\n",
      "  ✓ Saved (188 total)\n",
      "[189/797] Productive: 188 saved | https://en.wikipedia.org/wiki/Behavioral_Description_Languag...\n",
      "  ✓ Saved (189 total)\n",
      "[190/797] Productive: 189 saved | https://en.wikipedia.org/wiki/BLISS...\n",
      "  ✓ Saved (190 total)\n",
      "[191/797] Productive: 190 saved | https://en.wikipedia.org/wiki/Boo_(programming_language)...\n",
      "  ✓ Saved (191 total)\n",
      "[192/797] Productive: 191 saved | https://en.wikipedia.org/wiki/Boomerang_(programming_languag...\n",
      "  ✓ Saved (192 total)\n",
      "[193/797] Productive: 192 saved | https://en.wikipedia.org/wiki/Brainfuck...\n",
      "  ✓ Saved (193 total)\n",
      "[194/797] Productive: 193 saved | https://en.wikipedia.org/wiki/Bs_(programming_language)...\n",
      "  ✓ Saved (194 total)\n",
      "[195/797] Productive: 194 saved | https://en.wikipedia.org/wiki/Cameleon_(programming_language...\n",
      "  ✓ Saved (195 total)\n",
      "[196/797] Productive: 195 saved | https://en.wikipedia.org/wiki/C_(programming_language)...\n",
      "  ✓ Saved (196 total)\n",
      "[197/797] Productive: 196 saved | https://en.wikipedia.org/wiki/The_C_Programming_Language...\n",
      "  ✓ Saved (197 total)\n",
      "[198/797] Productive: 197 saved | https://en.wikipedia.org/wiki/C_Sharp_(programming_language)...\n",
      "  ✓ Saved (198 total)\n",
      "[199/797] Productive: 198 saved | https://en.wikipedia.org/wiki/Caml...\n",
      "  ✓ Saved (199 total)\n",
      "[200/797] Productive: 199 saved | https://en.wikipedia.org/wiki/Carbon_(programming_language)...\n",
      "  ✓ Saved (200 total)\n",
      "[201/797] Productive: 200 saved | https://en.wikipedia.org/wiki/Cedar_(programming_language)...\n",
      "  ✓ Saved (201 total)\n",
      "[202/797] Productive: 201 saved | https://en.wikipedia.org/wiki/Céu_(programming_language)...\n",
      "  ✓ Saved (202 total)\n",
      "[203/797] Productive: 202 saved | https://en.wikipedia.org/wiki/Charm_(programming_language)...\n",
      "  ✓ Saved (203 total)\n",
      "[204/797] Productive: 203 saved | https://en.wikipedia.org/wiki/Clascal...\n",
      "  ✓ Saved (204 total)\n",
      "[205/797] Productive: 204 saved | https://en.wikipedia.org/wiki/Clipper_(programming_language)...\n",
      "  ✓ Saved (205 total)\n",
      "[206/797] Productive: 205 saved | https://en.wikipedia.org/wiki/Clojure...\n",
      "  ✓ Saved (206 total)\n",
      "[207/797] Productive: 206 saved | https://en.wikipedia.org/wiki/COMAL...\n",
      "  ✓ Saved (207 total)\n",
      "[208/797] Productive: 207 saved | https://en.wikipedia.org/wiki/Concordion...\n",
      "  ✓ Saved (208 total)\n",
      "[209/797] Productive: 208 saved | https://en.wikipedia.org/wiki/Concurrent_Haskell...\n",
      "  ✓ Saved (209 total)\n",
      "[210/797] Productive: 209 saved | https://en.wikipedia.org/wiki/CorbaScript...\n",
      "  ✓ Saved (210 total)\n",
      "[211/797] Productive: 210 saved | https://en.wikipedia.org/wiki/COWSEL...\n",
      "  ✓ Saved (211 total)\n",
      "[212/797] Productive: 211 saved | https://en.wikipedia.org/wiki/Crystal_(programming_language)...\n",
      "  ✓ Saved (212 total)\n",
      "[213/797] Productive: 212 saved | https://en.wikipedia.org/wiki/Cuneiform_(programming_languag...\n",
      "  ✓ Saved (213 total)\n",
      "[214/797] Productive: 213 saved | https://en.wikipedia.org/wiki/D_(programming_language)...\n",
      "  ✓ Saved (214 total)\n",
      "[215/797] Productive: 214 saved | https://en.wikipedia.org/wiki/DARSIMCO...\n",
      "  ✓ Saved (215 total)\n",
      "[216/797] Productive: 215 saved | https://en.wikipedia.org/wiki/Dartmouth_Oversimplified_Progr...\n",
      "  ✓ Saved (216 total)\n",
      "[217/797] Productive: 216 saved | https://en.wikipedia.org/wiki/Darwin_(programming_language)...\n",
      "  ✓ Saved (217 total)\n",
      "[218/797] Productive: 217 saved | https://en.wikipedia.org/wiki/DataFlex...\n",
      "  ✓ Saved (218 total)\n",
      "[219/797] Productive: 218 saved | https://en.wikipedia.org/wiki/Deductive_language...\n",
      "  ✓ Saved (219 total)\n",
      "[220/797] Productive: 219 saved | https://en.wikipedia.org/wiki/DIBOL...\n",
      "  ✓ Saved (220 total)\n",
      "[221/797] Productive: 220 saved | https://en.wikipedia.org/wiki/E_(programming_language)...\n",
      "  ✓ Saved (221 total)\n",
      "[222/797] Productive: 221 saved | https://en.wikipedia.org/wiki/ELAN_(programming_language)...\n",
      "  ✓ Saved (222 total)\n",
      "[223/797] Productive: 222 saved | https://en.wikipedia.org/wiki/Elixir_(programming_language)...\n",
      "  ✓ Saved (223 total)\n",
      "[224/797] Productive: 223 saved | https://en.wikipedia.org/wiki/Erlang_(programming_language)...\n",
      "  ✓ Saved (224 total)\n",
      "[225/797] Productive: 224 saved | https://en.wikipedia.org/wiki/EXAPT...\n",
      "  ✓ Saved (225 total)\n",
      "[226/797] Productive: 225 saved | https://en.wikipedia.org/wiki/F_(programming_language)...\n",
      "  ✓ Saved (226 total)\n",
      "[227/797] Productive: 226 saved | https://en.wikipedia.org/wiki/Factor_(programming_language)...\n",
      "  ✓ Saved (227 total)\n",
      "[228/797] Productive: 227 saved | https://en.wikipedia.org/wiki/Flow_chart_language...\n",
      "  ✓ Saved (228 total)\n",
      "[229/797] Productive: 228 saved | https://en.wikipedia.org/wiki/Flowcode...\n",
      "  ✓ Saved (229 total)\n",
      "[230/797] Productive: 229 saved | https://en.wikipedia.org/wiki/Forth_(programming_language)...\n",
      "  ✓ Saved (230 total)\n",
      "[231/797] Productive: 230 saved | https://en.wikipedia.org/wiki/FreeBASIC...\n",
      "  ✓ Saved (231 total)\n",
      "[232/797] Productive: 231 saved | https://en.wikipedia.org/wiki/Futhark_(programming_language)...\n",
      "  ✓ Saved (232 total)\n",
      "[233/797] Productive: 232 saved | https://en.wikipedia.org/wiki/FX-87...\n",
      "  ✓ Saved (233 total)\n",
      "[234/797] Productive: 233 saved | https://en.wikipedia.org/wiki/General-purpose_programming_la...\n",
      "  ✓ Saved (234 total)\n",
      "[235/797] Productive: 234 saved | https://en.wikipedia.org/wiki/GEORGE_(programming_language)...\n",
      "  ✓ Saved (235 total)\n",
      "[236/797] Productive: 235 saved | https://en.wikipedia.org/wiki/Gleam_(programming_language)...\n",
      "  ✓ Saved (236 total)\n",
      "[237/797] Productive: 236 saved | https://en.wikipedia.org/wiki/Go_(programming_language)...\n",
      "  ✓ Saved (237 total)\n",
      "[238/797] Productive: 237 saved | https://en.wikipedia.org/wiki/Golo_(programming_language)...\n",
      "  ✓ Saved (238 total)\n",
      "[239/797] Productive: 238 saved | https://en.wikipedia.org/wiki/GOLOG...\n",
      "  ✓ Saved (239 total)\n",
      "[240/797] Productive: 239 saved | https://en.wikipedia.org/wiki/Gosu_(programming_language)...\n",
      "  ✓ Saved (240 total)\n",
      "[241/797] Productive: 240 saved | https://en.wikipedia.org/wiki/Haggis_(programming_language)...\n",
      "  ✓ Saved (241 total)\n",
      "[242/797] Productive: 241 saved | https://en.wikipedia.org/wiki/Haxe...\n",
      "  ✓ Saved (242 total)\n",
      "[243/797] Productive: 242 saved | https://en.wikipedia.org/wiki/Hermes_(programming_language)...\n",
      "  ✓ Saved (243 total)\n",
      "[244/797] Productive: 243 saved | https://en.wikipedia.org/wiki/Io_(programming_language)...\n",
      "  ✓ Saved (244 total)\n",
      "[245/797] Productive: 244 saved | https://en.wikipedia.org/wiki/Janus_(time-reversible_computi...\n",
      "  ✓ Saved (245 total)\n",
      "[246/797] Productive: 245 saved | https://en.wikipedia.org/wiki/Java_(programming_language)...\n",
      "  ✓ Saved (246 total)\n",
      "[247/797] Productive: 246 saved | https://en.wikipedia.org/wiki/Java_technology...\n",
      "  ✓ Saved (247 total)\n",
      "[248/797] Productive: 247 saved | https://en.wikipedia.org/wiki/JavaScript...\n",
      "  ✓ Saved (248 total)\n",
      "[249/797] Productive: 248 saved | https://en.wikipedia.org/wiki/Jolie_(programming_language)...\n",
      "  ✓ Saved (249 total)\n",
      "[250/797] Productive: 249 saved | https://en.wikipedia.org/wiki/Joy_(programming_language)...\n",
      "  ✓ Saved (250 total)\n",
      "[251/797] Productive: 250 saved | https://en.wikipedia.org/wiki/Jq_(programming_language)...\n",
      "  ✓ Saved (251 total)\n",
      "[252/797] Productive: 251 saved | https://en.wikipedia.org/wiki/JS++...\n",
      "  ✓ Saved (252 total)\n",
      "[253/797] Productive: 252 saved | https://en.wikipedia.org/wiki/Julia_(programming_language)...\n",
      "  ✓ Saved (253 total)\n",
      "[254/797] Productive: 253 saved | https://en.wikipedia.org/wiki/K_(programming_language)...\n",
      "  ✓ Saved (254 total)\n",
      "[255/797] Productive: 254 saved | https://en.wikipedia.org/wiki/Kinetic_Rule_Language...\n",
      "  ✓ Saved (255 total)\n",
      "[256/797] Productive: 255 saved | https://en.wikipedia.org/wiki/Kojo_(learning_environment)...\n",
      "  ✓ Saved (256 total)\n",
      "[257/797] Productive: 256 saved | https://en.wikipedia.org/wiki/KOMPILER...\n",
      "  ✓ Saved (257 total)\n",
      "[258/797] Productive: 257 saved | https://en.wikipedia.org/wiki/Kotlin...\n",
      "  ✓ Saved (258 total)\n",
      "[259/797] Productive: 258 saved | https://en.wikipedia.org/wiki/Language_interoperability...\n",
      "  ✓ Saved (259 total)\n",
      "[260/797] Productive: 259 saved | https://en.wikipedia.org/wiki/LFE_(programming_language)...\n",
      "  ✓ Saved (260 total)\n",
      "[261/797] Productive: 260 saved | https://en.wikipedia.org/wiki/Lightweight_programming_langua...\n",
      "  ✓ Saved (261 total)\n",
      "[262/797] Productive: 261 saved | https://en.wikipedia.org/wiki/Linda_(coordination_language)...\n",
      "  ✓ Saved (262 total)\n",
      "[263/797] Productive: 262 saved | https://en.wikipedia.org/wiki/Lisp_(programming_language)...\n",
      "  ✓ Saved (263 total)\n",
      "[264/797] Productive: 263 saved | https://en.wikipedia.org/wiki/List_of_open-source_programmin...\n",
      "  ✓ Saved (264 total)\n",
      "[265/797] Productive: 264 saved | https://en.wikipedia.org/wiki/List_of_software_programming_j...\n",
      "  ✓ Saved (265 total)\n",
      "[266/797] Productive: 265 saved | https://en.wikipedia.org/wiki/Lists_of_programming_software_...\n",
      "  ✓ Saved (266 total)\n",
      "[267/797] Productive: 266 saved | https://en.wikipedia.org/wiki/Little_b_(programming_language...\n",
      "  ✓ Saved (267 total)\n",
      "[268/797] Productive: 267 saved | https://en.wikipedia.org/wiki/LiveCode...\n",
      "  ✓ Saved (268 total)\n",
      "[269/797] Productive: 268 saved | https://en.wikipedia.org/wiki/Logo_(programming_language)...\n",
      "  ✓ Saved (269 total)\n",
      "[270/797] Productive: 269 saved | https://en.wikipedia.org/wiki/Lua...\n",
      "  ✓ Saved (270 total)\n",
      "[271/797] Productive: 270 saved | https://en.wikipedia.org/wiki/Macroprogramming...\n",
      "  ✓ Saved (271 total)\n",
      "[272/797] Productive: 271 saved | https://en.wikipedia.org/wiki/MATH-MATIC...\n",
      "  ✓ Saved (272 total)\n",
      "[273/797] Productive: 272 saved | https://en.wikipedia.org/wiki/Mercury_(RemObjects_BASIC_prog...\n",
      "  ✓ Saved (273 total)\n",
      "[274/797] Productive: 273 saved | https://en.wikipedia.org/wiki/MiniKanren...\n",
      "  ✓ Saved (274 total)\n",
      "[275/797] Productive: 274 saved | https://en.wikipedia.org/wiki/Mocklisp...\n",
      "  ✓ Saved (275 total)\n",
      "[276/797] Productive: 275 saved | https://en.wikipedia.org/wiki/Mojo_(programming_language)...\n",
      "  ✓ Saved (276 total)\n",
      "[277/797] Productive: 276 saved | https://en.wikipedia.org/wiki/Multi-adjoint_logic_programmin...\n",
      "  ✓ Saved (277 total)\n",
      "[278/797] Productive: 277 saved | https://en.wikipedia.org/wiki/Nemerle...\n",
      "  ✓ Saved (278 total)\n",
      "[279/797] Productive: 278 saved | https://en.wikipedia.org/wiki/Nim_(programming_language)...\n",
      "  ✓ Saved (279 total)\n",
      "[280/797] Productive: 279 saved | https://en.wikipedia.org/wiki/OpenQASM...\n",
      "  ✓ Saved (280 total)\n",
      "[281/797] Productive: 280 saved | https://en.wikipedia.org/wiki/Outline_of_the_C_programming_l...\n",
      "  ✓ Saved (281 total)\n",
      "[282/797] Productive: 281 saved | https://en.wikipedia.org/wiki/Outline_of_the_C_sharp_program...\n",
      "  ✓ Saved (282 total)\n",
      "[283/797] Productive: 282 saved | https://en.wikipedia.org/wiki/Outline_of_the_Python_programm...\n",
      "  ✓ Saved (283 total)\n",
      "[284/797] Productive: 283 saved | https://en.wikipedia.org/wiki/Outline_of_the_Rust_programmin...\n",
      "  ✓ Saved (284 total)\n",
      "[285/797] Productive: 284 saved | https://en.wikipedia.org/wiki/Pencil_Code_(programming_langu...\n",
      "  ✓ Saved (285 total)\n",
      "[286/797] Productive: 285 saved | https://en.wikipedia.org/wiki/Perl...\n",
      "  ✓ Saved (286 total)\n",
      "[287/797] Productive: 286 saved | https://en.wikipedia.org/wiki/Petit_Computer...\n",
      "  ✓ Saved (287 total)\n",
      "[288/797] Productive: 287 saved | https://en.wikipedia.org/wiki/Pharo...\n",
      "  ✓ Saved (288 total)\n",
      "[289/797] Productive: 288 saved | https://en.wikipedia.org/wiki/PHP...\n",
      "  ✓ Saved (289 total)\n",
      "[290/797] Productive: 289 saved | https://en.wikipedia.org/wiki/PIC_(markup_language)...\n",
      "  ✓ Saved (290 total)\n",
      "[291/797] Productive: 290 saved | https://en.wikipedia.org/wiki/Pico_(programming_language)...\n",
      "  ✓ Saved (291 total)\n",
      "[292/797] Productive: 291 saved | https://en.wikipedia.org/wiki/PL/M...\n",
      "  ✓ Saved (292 total)\n",
      "[293/797] Productive: 292 saved | https://en.wikipedia.org/wiki/Pony_(programming_language)...\n",
      "  ✓ Saved (293 total)\n",
      "[294/797] Productive: 293 saved | https://en.wikipedia.org/wiki/POP-2...\n",
      "  ✓ Saved (294 total)\n",
      "[295/797] Productive: 294 saved | https://en.wikipedia.org/wiki/Processing...\n",
      "  ✓ Saved (295 total)\n",
      "[296/797] Productive: 295 saved | https://en.wikipedia.org/wiki/Programming_Languages:_Applica...\n",
      "  ✓ Saved (296 total)\n",
      "[297/797] Productive: 296 saved | https://en.wikipedia.org/wiki/PureBasic...\n",
      "  ✓ Saved (297 total)\n",
      "[298/797] Productive: 297 saved | https://en.wikipedia.org/wiki/PV-Wave...\n",
      "  ✓ Saved (298 total)\n",
      "[299/797] Productive: 298 saved | https://en.wikipedia.org/wiki/Python_(programming_language)...\n",
      "  ✓ Saved (299 total)\n",
      "[300/797] Productive: 299 saved | https://en.wikipedia.org/wiki/Qore_(programming_language)...\n",
      "  ✓ Saved (300 total)\n",
      "[301/797] Productive: 300 saved | https://en.wikipedia.org/wiki/Quantum_Computation_Language...\n",
      "  ✓ Saved (301 total)\n",
      "[302/797] Productive: 301 saved | https://en.wikipedia.org/wiki/Raku_(programming_language)...\n",
      "  ✓ Saved (302 total)\n",
      "[303/797] Productive: 302 saved | https://en.wikipedia.org/wiki/Real-time_Programming_Language...\n",
      "  ✓ Saved (303 total)\n",
      "[304/797] Productive: 303 saved | https://en.wikipedia.org/wiki/Rebol...\n",
      "  ✓ Saved (304 total)\n",
      "[305/797] Productive: 304 saved | https://en.wikipedia.org/wiki/Red_(programming_language)...\n",
      "  ✓ Saved (305 total)\n",
      "[306/797] Productive: 305 saved | https://en.wikipedia.org/wiki/Refal...\n",
      "  ✓ Saved (306 total)\n",
      "[307/797] Productive: 306 saved | https://en.wikipedia.org/wiki/Reversible_programming_languag...\n",
      "  ✓ Saved (307 total)\n",
      "[308/797] Productive: 307 saved | https://en.wikipedia.org/wiki/Ring_(programming_language)...\n",
      "  ✓ Saved (308 total)\n",
      "[309/797] Productive: 308 saved | https://en.wikipedia.org/wiki/Rosetta_Code...\n",
      "  ✓ Saved (309 total)\n",
      "[310/797] Productive: 309 saved | https://en.wikipedia.org/wiki/S-PLUS...\n",
      "  ✓ Saved (310 total)\n",
      "[311/797] Productive: 310 saved | https://en.wikipedia.org/wiki/Scala_(programming_language)...\n",
      "  ✓ Saved (311 total)\n",
      "[312/797] Productive: 311 saved | https://en.wikipedia.org/wiki/Scientific_Vector_Language...\n",
      "  ✓ Saved (312 total)\n",
      "[313/797] Productive: 312 saved | https://en.wikipedia.org/wiki/Scriptol...\n",
      "  ✓ Saved (313 total)\n",
      "[314/797] Productive: 313 saved | https://en.wikipedia.org/wiki/Self_(programming_language)...\n",
      "  ✓ Saved (314 total)\n",
      "[315/797] Productive: 314 saved | https://en.wikipedia.org/wiki/SenseTalk...\n",
      "  ✓ Saved (315 total)\n",
      "[316/797] Productive: 315 saved | https://en.wikipedia.org/wiki/Simula...\n",
      "  ✓ Saved (316 total)\n",
      "[317/797] Productive: 316 saved | https://en.wikipedia.org/wiki/SLIP_(programming_language)...\n",
      "  ✓ Saved (317 total)\n",
      "[318/797] Productive: 317 saved | https://en.wikipedia.org/wiki/Smalltalk...\n",
      "  ✓ Saved (318 total)\n",
      "[319/797] Productive: 318 saved | https://en.wikipedia.org/wiki/Smart_Pascal...\n",
      "  ✓ Saved (319 total)\n",
      "[320/797] Productive: 319 saved | https://en.wikipedia.org/wiki/SNOBOL...\n",
      "  ✓ Saved (320 total)\n",
      "[321/797] Productive: 320 saved | https://en.wikipedia.org/wiki/Source_(programming_language)...\n",
      "  ✓ Saved (321 total)\n",
      "[322/797] Productive: 321 saved | https://en.wikipedia.org/wiki/Squeak...\n",
      "  ✓ Saved (322 total)\n",
      "[323/797] Productive: 322 saved | https://en.wikipedia.org/wiki/Squirrel_(programming_language...\n",
      "  ✓ Saved (323 total)\n",
      "[324/797] Productive: 323 saved | https://en.wikipedia.org/wiki/StaDyn_(programming_language)...\n",
      "  ✓ Saved (324 total)\n",
      "[325/797] Productive: 324 saved | https://en.wikipedia.org/wiki/Starlark...\n",
      "  ✓ Saved (325 total)\n",
      "[326/797] Productive: 325 saved | https://en.wikipedia.org/wiki/Structured_text...\n",
      "  ✓ Saved (326 total)\n",
      "[327/797] Productive: 326 saved | https://en.wikipedia.org/wiki/Swift_(parallel_scripting_lang...\n",
      "  ✓ Saved (327 total)\n",
      "[328/797] Productive: 327 saved | https://en.wikipedia.org/wiki/Swift_(programming_language)...\n",
      "  ✓ Saved (328 total)\n",
      "[329/797] Productive: 328 saved | https://en.wikipedia.org/wiki/Synergy_DBL...\n",
      "  ✓ Saved (329 total)\n",
      "[330/797] Productive: 329 saved | https://en.wikipedia.org/wiki/Tea_(programming_language)...\n",
      "  ✓ Saved (330 total)\n",
      "[331/797] Productive: 330 saved | https://en.wikipedia.org/wiki/TI-BASIC_83...\n",
      "  ✓ Saved (331 total)\n",
      "[332/797] Productive: 331 saved | https://en.wikipedia.org/wiki/TREE-META...\n",
      "  ✓ Saved (332 total)\n",
      "[333/797] Productive: 332 saved | https://en.wikipedia.org/wiki/TreeDL...\n",
      "  ✓ Saved (333 total)\n",
      "[334/797] Productive: 333 saved | https://en.wikipedia.org/wiki/Trellis-Owl...\n",
      "  ✓ Saved (334 total)\n",
      "[335/797] Productive: 334 saved | https://en.wikipedia.org/wiki/Tritium_(programming_language)...\n",
      "  ✓ Saved (335 total)\n",
      "[336/797] Productive: 335 saved | https://en.wikipedia.org/wiki/TTCN-3...\n",
      "  ✓ Saved (336 total)\n",
      "[337/797] Productive: 336 saved | https://en.wikipedia.org/wiki/Tuple_space...\n",
      "  ✓ Saved (337 total)\n",
      "[338/797] Productive: 337 saved | https://en.wikipedia.org/wiki/TypeScript...\n",
      "  ✓ Saved (338 total)\n",
      "[339/797] Productive: 338 saved | https://en.wikipedia.org/wiki/Universal_Test_Specification_L...\n",
      "  ✓ Saved (339 total)\n",
      "[340/797] Productive: 339 saved | https://en.wikipedia.org/wiki/V_(programming_language)...\n",
      "  ✓ Saved (340 total)\n",
      "[341/797] Productive: 340 saved | https://en.wikipedia.org/wiki/Vala_(programming_language)...\n",
      "  ✓ Saved (341 total)\n",
      "[342/797] Productive: 341 saved | https://en.wikipedia.org/wiki/Visual_Basic_(classic)...\n",
      "  ✓ Saved (342 total)\n",
      "[343/797] Productive: 342 saved | https://en.wikipedia.org/wiki/Visual_FoxPro...\n",
      "  ✓ Saved (343 total)\n",
      "[344/797] Productive: 343 saved | https://en.wikipedia.org/wiki/Visual_Prolog...\n",
      "  ✓ Saved (344 total)\n",
      "[345/797] Productive: 344 saved | https://en.wikipedia.org/wiki/XPL...\n",
      "  ✓ Saved (345 total)\n",
      "[346/797] Productive: 345 saved | https://en.wikipedia.org/wiki/XSLT...\n",
      "  ✓ Saved (346 total)\n",
      "[347/797] Productive: 346 saved | https://en.wikipedia.org/wiki/Zig_(programming_language)...\n",
      "  ✓ Saved (347 total)\n",
      "[348/797] Productive: 347 saved | https://en.wikipedia.org/wiki/Machine_learning...\n",
      "  ✓ Saved (348 total)\n",
      "[349/797] Productive: 348 saved | https://en.wikipedia.org/wiki/Outline_of_machine_learning...\n",
      "  ✓ Saved (349 total)\n",
      "[350/797] Productive: 349 saved | https://en.wikipedia.org/wiki/80_Million_Tiny_Images...\n",
      "  ✓ Saved (350 total)\n",
      "[351/797] Productive: 350 saved | https://en.wikipedia.org/wiki/A_Logical_Calculus_of_the_Idea...\n",
      "  ✓ Saved (351 total)\n",
      "[352/797] Productive: 351 saved | https://en.wikipedia.org/wiki/Accelerated_Linear_Algebra...\n",
      "  ✓ Saved (352 total)\n",
      "[353/797] Productive: 352 saved | https://en.wikipedia.org/wiki/Action_model_learning...\n",
      "  ✓ Saved (353 total)\n",
      "[354/797] Productive: 353 saved | https://en.wikipedia.org/wiki/Active_learning_(machine_learn...\n",
      "  ✓ Saved (354 total)\n",
      "[355/797] Productive: 354 saved | https://en.wikipedia.org/wiki/Adversarial_machine_learning...\n",
      "  ✓ Saved (355 total)\n",
      "[356/797] Productive: 355 saved | https://en.wikipedia.org/wiki/AI_Factory...\n",
      "  ✓ Saved (356 total)\n",
      "[357/797] Productive: 356 saved | https://en.wikipedia.org/wiki/AIOps...\n",
      "  ✓ Saved (357 total)\n",
      "[358/797] Productive: 357 saved | https://en.wikipedia.org/wiki/AIXI...\n",
      "  ✓ Saved (358 total)\n",
      "[359/797] Productive: 358 saved | https://en.wikipedia.org/wiki/Algorithm_selection...\n",
      "  ✓ Saved (359 total)\n",
      "[360/797] Productive: 359 saved | https://en.wikipedia.org/wiki/Algorithmic_bias...\n",
      "  ✓ Saved (360 total)\n",
      "[361/797] Productive: 360 saved | https://en.wikipedia.org/wiki/Algorithmic_inference...\n",
      "  ✓ Saved (361 total)\n",
      "[362/797] Productive: 361 saved | https://en.wikipedia.org/wiki/Anomaly_detection...\n",
      "  ✓ Saved (362 total)\n",
      "[363/797] Productive: 362 saved | https://en.wikipedia.org/wiki/Aporia_(company)...\n",
      "  ✓ Saved (363 total)\n",
      "[364/797] Productive: 363 saved | https://en.wikipedia.org/wiki/Apprenticeship_learning...\n",
      "  ✓ Saved (364 total)\n",
      "[365/797] Productive: 364 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_in_hir...\n",
      "  ✓ Saved (365 total)\n",
      "[366/797] Productive: 365 saved | https://en.wikipedia.org/wiki/Astrostatistics...\n",
      "  ✓ Saved (366 total)\n",
      "[367/797] Productive: 366 saved | https://en.wikipedia.org/wiki/Attention_(machine_learning)...\n",
      "  ✓ Saved (367 total)\n",
      "[368/797] Productive: 367 saved | https://en.wikipedia.org/wiki/Audio_inpainting...\n",
      "  ✓ Saved (368 total)\n",
      "[369/797] Productive: 368 saved | https://en.wikipedia.org/wiki/Automated_decision-making...\n",
      "  ✓ Saved (369 total)\n",
      "[370/797] Productive: 369 saved | https://en.wikipedia.org/wiki/Automated_machine_learning...\n",
      "  ✓ Saved (370 total)\n",
      "[371/797] Productive: 370 saved | https://en.wikipedia.org/wiki/Automation_in_construction...\n",
      "  ✓ Saved (371 total)\n",
      "[372/797] Productive: 371 saved | https://en.wikipedia.org/wiki/Bag-of-words_model...\n",
      "  ✓ Saved (372 total)\n",
      "[373/797] Productive: 372 saved | https://en.wikipedia.org/wiki/Ball_tree...\n",
      "  ✓ Saved (373 total)\n",
      "[374/797] Productive: 373 saved | https://en.wikipedia.org/wiki/Base_rate...\n",
      "  ✓ Saved (374 total)\n",
      "[375/797] Productive: 374 saved | https://en.wikipedia.org/wiki/Bayesian_interpretation_of_ker...\n",
      "  ✓ Saved (375 total)\n",
      "[376/797] Productive: 375 saved | https://en.wikipedia.org/wiki/Bayesian_learning_mechanisms...\n",
      "  ✓ Saved (376 total)\n",
      "[377/797] Productive: 376 saved | https://en.wikipedia.org/wiki/Bayesian_optimization...\n",
      "  ✓ Saved (377 total)\n",
      "[378/797] Productive: 377 saved | https://en.wikipedia.org/wiki/Bayesian_regret...\n",
      "  ✓ Saved (378 total)\n",
      "[379/797] Productive: 378 saved | https://en.wikipedia.org/wiki/Bayesian_structural_time_serie...\n",
      "  ✓ Saved (379 total)\n",
      "[380/797] Productive: 379 saved | https://en.wikipedia.org/wiki/Bias–variance_tradeoff...\n",
      "  ✓ Saved (380 total)\n",
      "[381/797] Productive: 380 saved | https://en.wikipedia.org/wiki/Binary_classification...\n",
      "  ✓ Saved (381 total)\n",
      "[382/797] Productive: 381 saved | https://en.wikipedia.org/wiki/Bioserenity...\n",
      "  ✓ Saved (382 total)\n",
      "[383/797] Productive: 382 saved | https://en.wikipedia.org/wiki/Bradley–Terry_model...\n",
      "  ✓ Saved (383 total)\n",
      "[384/797] Productive: 383 saved | https://en.wikipedia.org/wiki/Category_utility...\n",
      "  ✓ Saved (384 total)\n",
      "[385/797] Productive: 384 saved | https://en.wikipedia.org/wiki/CIML_community_portal...\n",
      "  ✓ Saved (385 total)\n",
      "[386/797] Productive: 385 saved | https://en.wikipedia.org/wiki/Claude_(language_model)...\n",
      "  ✓ Saved (386 total)\n",
      "[387/797] Productive: 386 saved | https://en.wikipedia.org/wiki/Cognitive_robotics...\n",
      "  ✓ Saved (387 total)\n",
      "[388/797] Productive: 387 saved | https://en.wikipedia.org/wiki/Concept_drift...\n",
      "  ✓ Saved (388 total)\n",
      "[389/797] Productive: 388 saved | https://en.wikipedia.org/wiki/Conditional_random_field...\n",
      "  ✓ Saved (389 total)\n",
      "[390/797] Productive: 389 saved | https://en.wikipedia.org/wiki/Confusion_matrix...\n",
      "  ✓ Saved (390 total)\n",
      "[391/797] Productive: 390 saved | https://en.wikipedia.org/wiki/Contrastive_Language-Image_Pre...\n",
      "  ✓ Saved (391 total)\n",
      "[392/797] Productive: 391 saved | https://en.wikipedia.org/wiki/Cost-sensitive_machine_learnin...\n",
      "  ✓ Saved (392 total)\n",
      "[393/797] Productive: 392 saved | https://en.wikipedia.org/wiki/Coupled_pattern_learner...\n",
      "  ✓ Saved (393 total)\n",
      "[394/797] Productive: 393 saved | https://en.wikipedia.org/wiki/Croissant_(metadata_format)...\n",
      "  ✓ Saved (394 total)\n",
      "[395/797] Productive: 394 saved | https://en.wikipedia.org/wiki/Cross-entropy_method...\n",
      "  ✓ Saved (395 total)\n",
      "[396/797] Productive: 395 saved | https://en.wikipedia.org/wiki/Cross-validation_(statistics)...\n",
      "  ✓ Saved (396 total)\n",
      "[397/797] Productive: 396 saved | https://en.wikipedia.org/wiki/Curse_of_dimensionality...\n",
      "  ✓ Saved (397 total)\n",
      "[398/797] Productive: 397 saved | https://en.wikipedia.org/wiki/Data_augmentation...\n",
      "  ✓ Saved (398 total)\n",
      "[399/797] Productive: 398 saved | https://en.wikipedia.org/wiki/Data_exploration...\n",
      "  ✓ Saved (399 total)\n",
      "[400/797] Productive: 399 saved | https://en.wikipedia.org/wiki/Data_preprocessing...\n",
      "  ✓ Saved (400 total)\n",
      "[401/797] Productive: 400 saved | https://en.wikipedia.org/wiki/Data-driven_astronomy...\n",
      "  ✓ Saved (401 total)\n",
      "[402/797] Productive: 401 saved | https://en.wikipedia.org/wiki/Data-driven_model...\n",
      "  ✓ Saved (402 total)\n",
      "[403/797] Productive: 402 saved | https://en.wikipedia.org/wiki/Decision_list...\n",
      "  ✓ Saved (403 total)\n",
      "[404/797] Productive: 403 saved | https://en.wikipedia.org/wiki/Decision_tree_pruning...\n",
      "  ✓ Saved (404 total)\n",
      "[405/797] Productive: 404 saved | https://en.wikipedia.org/wiki/Deep_tomographic_reconstructio...\n",
      "  ✓ Saved (405 total)\n",
      "[406/797] Productive: 405 saved | https://en.wikipedia.org/wiki/Developmental_robotics...\n",
      "  ✓ Saved (406 total)\n",
      "[407/797] Productive: 406 saved | https://en.wikipedia.org/wiki/Discovery_system_(artificial_i...\n",
      "  ✓ Saved (407 total)\n",
      "[408/797] Productive: 407 saved | https://en.wikipedia.org/wiki/Document_classification...\n",
      "  ✓ Saved (408 total)\n",
      "[409/797] Productive: 408 saved | https://en.wikipedia.org/wiki/Domain_adaptation...\n",
      "  ✓ Saved (409 total)\n",
      "[410/797] Productive: 409 saved | https://en.wikipedia.org/wiki/Double_descent...\n",
      "  ✓ Saved (410 total)\n",
      "[411/797] Productive: 410 saved | https://en.wikipedia.org/wiki/Eager_learning...\n",
      "  ✓ Saved (411 total)\n",
      "[412/797] Productive: 411 saved | https://en.wikipedia.org/wiki/EfficientNet...\n",
      "  ✓ Saved (412 total)\n",
      "[413/797] Productive: 412 saved | https://en.wikipedia.org/wiki/ELMo...\n",
      "  ✓ Saved (413 total)\n",
      "[414/797] Productive: 413 saved | https://en.wikipedia.org/wiki/EM_algorithm_and_GMM_model...\n",
      "  ✓ Saved (414 total)\n",
      "[415/797] Productive: 414 saved | https://en.wikipedia.org/wiki/Embedding_(machine_learning)...\n",
      "  ✓ Saved (415 total)\n",
      "[416/797] Productive: 415 saved | https://en.wikipedia.org/wiki/Empirical_dynamic_modeling...\n",
      "  ✓ Saved (416 total)\n",
      "[417/797] Productive: 416 saved | https://en.wikipedia.org/wiki/Empirical_risk_minimization...\n",
      "  ✓ Saved (417 total)\n",
      "[418/797] Productive: 417 saved | https://en.wikipedia.org/wiki/Energy-based_model...\n",
      "  ✓ Saved (418 total)\n",
      "[419/797] Productive: 418 saved | https://en.wikipedia.org/wiki/Equalized_odds...\n",
      "  ✓ Saved (419 total)\n",
      "[420/797] Productive: 419 saved | https://en.wikipedia.org/wiki/Evaluation_of_binary_classifie...\n",
      "  ✓ Saved (420 total)\n",
      "[421/797] Productive: 420 saved | https://en.wikipedia.org/wiki/Evolvability_(computer_science...\n",
      "  ✓ Saved (421 total)\n",
      "[422/797] Productive: 421 saved | https://en.wikipedia.org/wiki/Expectation_propagation...\n",
      "  ✓ Saved (422 total)\n",
      "[423/797] Productive: 422 saved | https://en.wikipedia.org/wiki/Explanation-based_learning...\n",
      "  ✓ Saved (423 total)\n",
      "[424/797] Productive: 423 saved | https://en.wikipedia.org/wiki/Exploration–exploitation_dilem...\n",
      "  ✓ Saved (424 total)\n",
      "[425/797] Productive: 424 saved | https://en.wikipedia.org/wiki/Fairness_(machine_learning)...\n",
      "  ✓ Saved (425 total)\n",
      "[426/797] Productive: 425 saved | https://en.wikipedia.org/wiki/Feature_(machine_learning)...\n",
      "  ✓ Saved (426 total)\n",
      "[427/797] Productive: 426 saved | https://en.wikipedia.org/wiki/Feature_engineering...\n",
      "  ✓ Saved (427 total)\n",
      "[428/797] Productive: 427 saved | https://en.wikipedia.org/wiki/Feature_hashing...\n",
      "  ✓ Saved (428 total)\n",
      "[429/797] Productive: 428 saved | https://en.wikipedia.org/wiki/Feature_learning...\n",
      "  ✓ Saved (429 total)\n",
      "[430/797] Productive: 429 saved | https://en.wikipedia.org/wiki/Feature_scaling...\n",
      "  ✓ Saved (430 total)\n",
      "[431/797] Productive: 430 saved | https://en.wikipedia.org/wiki/Federated_learning...\n",
      "  ✓ Saved (431 total)\n",
      "[432/797] Productive: 431 saved | https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)...\n",
      "  ✓ Saved (432 total)\n",
      "[433/797] Productive: 432 saved | https://en.wikipedia.org/wiki/Flow-based_generative_model...\n",
      "  ✓ Saved (433 total)\n",
      "[434/797] Productive: 433 saved | https://en.wikipedia.org/wiki/Flux_(machine-learning_framewo...\n",
      "  ✓ Saved (434 total)\n",
      "[435/797] Productive: 434 saved | https://en.wikipedia.org/wiki/Force_control...\n",
      "  ✓ Saved (435 total)\n",
      "[436/797] Productive: 435 saved | https://en.wikipedia.org/wiki/Formal_concept_analysis...\n",
      "  ✓ Saved (436 total)\n",
      "[437/797] Productive: 436 saved | https://en.wikipedia.org/wiki/Generalized_additive_model_for...\n",
      "  ✓ Saved (437 total)\n",
      "[438/797] Productive: 437 saved | https://en.wikipedia.org/wiki/Generative_artificial_intellig...\n",
      "  ✓ Saved (438 total)\n",
      "[439/797] Productive: 438 saved | https://en.wikipedia.org/wiki/Generative_model...\n",
      "  ✓ Saved (439 total)\n",
      "[440/797] Productive: 439 saved | https://en.wikipedia.org/wiki/Geometric_feature_learning...\n",
      "  ✓ Saved (440 total)\n",
      "[441/797] Productive: 440 saved | https://en.wikipedia.org/wiki/Glossary_of_artificial_intelli...\n",
      "  ✓ Saved (441 total)\n",
      "[442/797] Productive: 441 saved | https://en.wikipedia.org/wiki/Google_Colab...\n",
      "  ✓ Saved (442 total)\n",
      "[443/797] Productive: 442 saved | https://en.wikipedia.org/wiki/Google_Research...\n",
      "  ✓ Saved (443 total)\n",
      "[444/797] Productive: 443 saved | https://en.wikipedia.org/wiki/Granular_computing...\n",
      "  ✓ Saved (444 total)\n",
      "[445/797] Productive: 444 saved | https://en.wikipedia.org/wiki/Grokking_(machine_learning)...\n",
      "  ✓ Saved (445 total)\n",
      "[446/797] Productive: 445 saved | https://en.wikipedia.org/wiki/H_(company)...\n",
      "  ✓ Saved (446 total)\n",
      "[447/797] Productive: 446 saved | https://en.wikipedia.org/wiki/Hallucination_(artificial_inte...\n",
      "  ✓ Saved (447 total)\n",
      "[448/797] Productive: 447 saved | https://en.wikipedia.org/wiki/Hidden_layer...\n",
      "  ✓ Saved (448 total)\n",
      "[449/797] Productive: 448 saved | https://en.wikipedia.org/wiki/Hierarchical_navigable_small_w...\n",
      "  ✓ Saved (449 total)\n",
      "[450/797] Productive: 449 saved | https://en.wikipedia.org/wiki/Hierarchical_Risk_Parity...\n",
      "  ✓ Saved (450 total)\n",
      "[451/797] Productive: 450 saved | https://en.wikipedia.org/wiki/Highway_network...\n",
      "  ✓ Saved (451 total)\n",
      "[452/797] Productive: 451 saved | https://en.wikipedia.org/wiki/Hugging_Face...\n",
      "  ✓ Saved (452 total)\n",
      "[453/797] Productive: 452 saved | https://en.wikipedia.org/wiki/Human-in-the-loop...\n",
      "  ✓ Saved (453 total)\n",
      "[454/797] Productive: 453 saved | https://en.wikipedia.org/wiki/Hyperparameter_(machine_learni...\n",
      "  ✓ Saved (454 total)\n",
      "[455/797] Productive: 454 saved | https://en.wikipedia.org/wiki/Hyperparameter_optimization...\n",
      "  ✓ Saved (455 total)\n",
      "[456/797] Productive: 455 saved | https://en.wikipedia.org/wiki/In-context_learning_(natural_l...\n",
      "  ✓ Saved (456 total)\n",
      "[457/797] Productive: 456 saved | https://en.wikipedia.org/wiki/Inauthentic_text...\n",
      "  ✓ Saved (457 total)\n",
      "[458/797] Productive: 457 saved | https://en.wikipedia.org/wiki/Inception_score...\n",
      "  ✓ Saved (458 total)\n",
      "[459/797] Productive: 458 saved | https://en.wikipedia.org/wiki/Inductive_bias...\n",
      "  ✓ Saved (459 total)\n",
      "[460/797] Productive: 459 saved | https://en.wikipedia.org/wiki/Inductive_probability...\n",
      "  ✓ Saved (460 total)\n",
      "[461/797] Productive: 460 saved | https://en.wikipedia.org/wiki/Inductive_programming...\n",
      "  ✓ Saved (461 total)\n",
      "[462/797] Productive: 461 saved | https://en.wikipedia.org/wiki/Inferential_theory_of_learning...\n",
      "  ✓ Saved (462 total)\n",
      "[463/797] Productive: 462 saved | https://en.wikipedia.org/wiki/Instance_selection...\n",
      "  ✓ Saved (463 total)\n",
      "[464/797] Productive: 463 saved | https://en.wikipedia.org/wiki/Instance-based_learning...\n",
      "  ✓ Saved (464 total)\n",
      "[465/797] Productive: 464 saved | https://en.wikipedia.org/wiki/Intelligent_automation...\n",
      "  ✓ Saved (465 total)\n",
      "[466/797] Productive: 465 saved | https://en.wikipedia.org/wiki/Isotropic_position...\n",
      "  ✓ Saved (466 total)\n",
      "[467/797] Productive: 466 saved | https://en.wikipedia.org/wiki/JAX_(software)...\n",
      "  ✓ Saved (467 total)\n",
      "[468/797] Productive: 467 saved | https://en.wikipedia.org/wiki/Journal_of_Machine_Learning_Re...\n",
      "  ✓ Saved (468 total)\n",
      "[469/797] Productive: 468 saved | https://en.wikipedia.org/wiki/Kernel_density_estimation...\n",
      "  ✓ Saved (469 total)\n",
      "[470/797] Productive: 469 saved | https://en.wikipedia.org/wiki/Kernel_embedding_of_distributi...\n",
      "  ✓ Saved (470 total)\n",
      "[471/797] Productive: 470 saved | https://en.wikipedia.org/wiki/Knowledge_graph_embedding...\n",
      "  ✓ Saved (471 total)\n",
      "[472/797] Productive: 471 saved | https://en.wikipedia.org/wiki/Knowledge_integration...\n",
      "  ✓ Saved (472 total)\n",
      "[473/797] Productive: 472 saved | https://en.wikipedia.org/wiki/Kolmogorov-Arnold_Networks...\n",
      "  ✓ Saved (473 total)\n",
      "[474/797] Productive: 473 saved | https://en.wikipedia.org/wiki/Labeled_data...\n",
      "  ✓ Saved (474 total)\n",
      "[475/797] Productive: 474 saved | https://en.wikipedia.org/wiki/LaBSE...\n",
      "  ✓ Saved (475 total)\n",
      "[476/797] Productive: 475 saved | https://en.wikipedia.org/wiki/Lazy_learning...\n",
      "  ✓ Saved (476 total)\n",
      "[477/797] Productive: 476 saved | https://en.wikipedia.org/wiki/Leakage_(machine_learning)...\n",
      "  ✓ Saved (477 total)\n",
      "[478/797] Productive: 477 saved | https://en.wikipedia.org/wiki/Learnable_function_class...\n",
      "  ✓ Saved (478 total)\n",
      "[479/797] Productive: 478 saved | https://en.wikipedia.org/wiki/Learning_automaton...\n",
      "  ✓ Saved (479 total)\n",
      "[480/797] Productive: 479 saved | https://en.wikipedia.org/wiki/Learning_curve_(machine_learni...\n",
      "  ✓ Saved (480 total)\n",
      "[481/797] Productive: 480 saved | https://en.wikipedia.org/wiki/Learning_rate...\n",
      "  ✓ Saved (481 total)\n",
      "[482/797] Productive: 481 saved | https://en.wikipedia.org/wiki/Learning_to_rank...\n",
      "  ✓ Saved (482 total)\n",
      "[483/797] Productive: 482 saved | https://en.wikipedia.org/wiki/Life-time_of_correlation...\n",
      "  ✓ Saved (483 total)\n",
      "[484/797] Productive: 483 saved | https://en.wikipedia.org/wiki/Linear_predictor_function...\n",
      "  ✓ Saved (484 total)\n",
      "[485/797] Productive: 484 saved | https://en.wikipedia.org/wiki/Linear_separability...\n",
      "  ✓ Saved (485 total)\n",
      "[486/797] Productive: 485 saved | https://en.wikipedia.org/wiki/List_of_data_science_software...\n",
      "  ✓ Saved (486 total)\n",
      "[487/797] Productive: 486 saved | https://en.wikipedia.org/wiki/Local_case-control_sampling...\n",
      "  ✓ Saved (487 total)\n",
      "[488/797] Productive: 487 saved | https://en.wikipedia.org/wiki/Lottery_ticket_hypothesis...\n",
      "  ✓ Saved (488 total)\n",
      "[489/797] Productive: 488 saved | https://en.wikipedia.org/wiki/Lyra_(codec)...\n",
      "  ✓ Saved (489 total)\n",
      "[490/797] Productive: 489 saved | https://en.wikipedia.org/wiki/M-theory_(learning_framework)...\n",
      "  ✓ Saved (490 total)\n",
      "[491/797] Productive: 490 saved | https://en.wikipedia.org/wiki/Machine_Learning_(journal)...\n",
      "  ✓ Saved (491 total)\n",
      "[492/797] Productive: 491 saved | https://en.wikipedia.org/wiki/Machine_Learning_and_Knowledge...\n",
      "  ✓ Saved (492 total)\n",
      "[493/797] Productive: 492 saved | https://en.wikipedia.org/wiki/Machine_learning_control...\n",
      "  ✓ Saved (493 total)\n",
      "[494/797] Productive: 493 saved | https://en.wikipedia.org/wiki/Machine_learning_in_bioinforma...\n",
      "  ✓ Saved (494 total)\n",
      "[495/797] Productive: 494 saved | https://en.wikipedia.org/wiki/Machine_learning_in_earth_scie...\n",
      "  ✓ Saved (495 total)\n",
      "[496/797] Productive: 495 saved | https://en.wikipedia.org/wiki/Machine_learning_in_physics...\n",
      "  ✓ Saved (496 total)\n",
      "[497/797] Productive: 496 saved | https://en.wikipedia.org/wiki/Machine_learning_in_video_game...\n",
      "  ✓ Saved (497 total)\n",
      "[498/797] Productive: 497 saved | https://en.wikipedia.org/wiki/Machine_unlearning...\n",
      "  ✓ Saved (498 total)\n",
      "[499/797] Productive: 498 saved | https://en.wikipedia.org/wiki/Machine-learned_interatomic_po...\n",
      "  ✓ Saved (499 total)\n",
      "[500/797] Productive: 499 saved | https://en.wikipedia.org/wiki/Manifold_hypothesis...\n",
      "  ✓ Saved (500 total)\n",
      "[501/797] Productive: 500 saved | https://en.wikipedia.org/wiki/Manifold_regularization...\n",
      "  ✓ Saved (501 total)\n",
      "[502/797] Productive: 501 saved | https://en.wikipedia.org/wiki/The_Master_Algorithm...\n",
      "  ✓ Saved (502 total)\n",
      "[503/797] Productive: 502 saved | https://en.wikipedia.org/wiki/Matchbox_Educable_Noughts_and_...\n",
      "  ✓ Saved (503 total)\n",
      "[504/797] Productive: 503 saved | https://en.wikipedia.org/wiki/Matrix_regularization...\n",
      "  ✓ Saved (504 total)\n",
      "[505/797] Productive: 504 saved | https://en.wikipedia.org/wiki/Maximum_inner-product_search...\n",
      "  ✓ Saved (505 total)\n",
      "[506/797] Productive: 505 saved | https://en.wikipedia.org/wiki/Mechanistic_interpretability...\n",
      "  ✓ Saved (506 total)\n",
      "[507/797] Productive: 506 saved | https://en.wikipedia.org/wiki/Meta-Labeling...\n",
      "  ✓ Saved (507 total)\n",
      "[508/797] Productive: 507 saved | https://en.wikipedia.org/wiki/Meta-learning_(computer_scienc...\n",
      "  ✓ Saved (508 total)\n",
      "[509/797] Productive: 508 saved | https://en.wikipedia.org/wiki/MLOps...\n",
      "  ✓ Saved (509 total)\n",
      "[510/797] Productive: 509 saved | https://en.wikipedia.org/wiki/MobileNet...\n",
      "  ✓ Saved (510 total)\n",
      "[511/797] Productive: 510 saved | https://en.wikipedia.org/wiki/Mode_collapse...\n",
      "  ✓ Saved (511 total)\n",
      "[512/797] Productive: 511 saved | https://en.wikipedia.org/wiki/Model_compression...\n",
      "  ✓ Saved (512 total)\n",
      "[513/797] Productive: 512 saved | https://en.wikipedia.org/wiki/Mountain_car_problem...\n",
      "  ✓ Saved (513 total)\n",
      "[514/797] Productive: 513 saved | https://en.wikipedia.org/wiki/Multi-armed_bandit...\n",
      "  ✓ Saved (514 total)\n",
      "[515/797] Productive: 514 saved | https://en.wikipedia.org/wiki/Multi-task_learning...\n",
      "  ✓ Saved (515 total)\n",
      "[516/797] Productive: 515 saved | https://en.wikipedia.org/wiki/Multimodal_representation_lear...\n",
      "  ✓ Saved (516 total)\n",
      "[517/797] Productive: 516 saved | https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis...\n",
      "  ✓ Saved (517 total)\n",
      "[518/797] Productive: 517 saved | https://en.wikipedia.org/wiki/Multiple_instance_learning...\n",
      "  ✓ Saved (518 total)\n",
      "[519/797] Productive: 518 saved | https://en.wikipedia.org/wiki/Multiple-instance_learning...\n",
      "  ✓ Saved (519 total)\n",
      "[520/797] Productive: 519 saved | https://en.wikipedia.org/wiki/Multiplicative_weight_update_m...\n",
      "  ✓ Saved (520 total)\n",
      "[521/797] Productive: 520 saved | https://en.wikipedia.org/wiki/Multitask_optimization...\n",
      "  ✓ Saved (521 total)\n",
      "[522/797] Productive: 521 saved | https://en.wikipedia.org/wiki/Multivariate_adaptive_regressi...\n",
      "  ✓ Saved (522 total)\n",
      "[523/797] Productive: 522 saved | https://en.wikipedia.org/wiki/Native-language_identification...\n",
      "  ✓ Saved (523 total)\n",
      "[524/797] Productive: 523 saved | https://en.wikipedia.org/wiki/Nature_Machine_Intelligence...\n",
      "  ✓ Saved (524 total)\n",
      "[525/797] Productive: 524 saved | https://en.wikipedia.org/wiki/Neural_modeling_fields...\n",
      "  ✓ Saved (525 total)\n",
      "[526/797] Productive: 525 saved | https://en.wikipedia.org/wiki/Neural_network_quantum_states...\n",
      "  ✓ Saved (526 total)\n",
      "[527/797] Productive: 526 saved | https://en.wikipedia.org/wiki/Normalization_(machine_learnin...\n",
      "  ✓ Saved (527 total)\n",
      "[528/797] Productive: 527 saved | https://en.wikipedia.org/wiki/Novelty_detection...\n",
      "  ✓ Saved (528 total)\n",
      "[529/797] Productive: 528 saved | https://en.wikipedia.org/wiki/OAGI_Ontogenetic_Architecture_...\n",
      "  ✓ Saved (529 total)\n",
      "[530/797] Productive: 529 saved | https://en.wikipedia.org/wiki/Offline_learning...\n",
      "  ✓ Saved (530 total)\n",
      "[531/797] Productive: 530 saved | https://en.wikipedia.org/wiki/Optuna...\n",
      "  ✓ Saved (531 total)\n",
      "[532/797] Productive: 531 saved | https://en.wikipedia.org/wiki/Overfitting...\n",
      "  ✓ Saved (532 total)\n",
      "[533/797] Productive: 532 saved | https://en.wikipedia.org/wiki/Paraphrasing_(computational_li...\n",
      "  ✓ Saved (533 total)\n",
      "[534/797] Productive: 533 saved | https://en.wikipedia.org/wiki/Parity_learning...\n",
      "  ✓ Saved (534 total)\n",
      "[535/797] Productive: 534 saved | https://en.wikipedia.org/wiki/Pattern_language_(formal_langu...\n",
      "  ✓ Saved (535 total)\n",
      "[536/797] Productive: 535 saved | https://en.wikipedia.org/wiki/Pattern_recognition...\n",
      "  ✓ Saved (536 total)\n",
      "[537/797] Productive: 536 saved | https://en.wikipedia.org/wiki/Perceiver...\n",
      "  ✓ Saved (537 total)\n",
      "[538/797] Productive: 537 saved | https://en.wikipedia.org/wiki/PHerc._Paris._4...\n",
      "  ✓ Saved (538 total)\n",
      "[539/797] Productive: 538 saved | https://en.wikipedia.org/wiki/Phi_coefficient...\n",
      "  ✓ Saved (539 total)\n",
      "[540/797] Productive: 539 saved | https://en.wikipedia.org/wiki/Predictive_learning...\n",
      "  ✓ Saved (540 total)\n",
      "[541/797] Productive: 540 saved | https://en.wikipedia.org/wiki/Predictive_state_representatio...\n",
      "  ✓ Saved (541 total)\n",
      "[542/797] Productive: 541 saved | https://en.wikipedia.org/wiki/Preference_learning...\n",
      "  ✓ Saved (542 total)\n",
      "[543/797] Productive: 542 saved | https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_re...\n",
      "  ✓ Saved (543 total)\n",
      "[544/797] Productive: 543 saved | https://en.wikipedia.org/wiki/Proactive_learning...\n",
      "  ✓ Saved (544 total)\n",
      "[545/797] Productive: 544 saved | https://en.wikipedia.org/wiki/Proaftn...\n",
      "  ✓ Saved (545 total)\n",
      "[546/797] Productive: 545 saved | https://en.wikipedia.org/wiki/Probabilistic_numerics...\n",
      "  ✓ Saved (546 total)\n",
      "[547/797] Productive: 546 saved | https://en.wikipedia.org/wiki/Probability_matching...\n",
      "  ✓ Saved (547 total)\n",
      "[548/797] Productive: 547 saved | https://en.wikipedia.org/wiki/Platform_engineering...\n",
      "  ✓ Saved (548 total)\n",
      "[549/797] Productive: 548 saved | https://en.wikipedia.org/wiki/Software_engineering...\n",
      "  ✓ Saved (549 total)\n",
      "[550/797] Productive: 549 saved | https://en.wikipedia.org/wiki/Outline_of_software_engineerin...\n",
      "  ✓ Saved (550 total)\n",
      "[551/797] Productive: 550 saved | https://en.wikipedia.org/wiki/Index_of_software_engineering_...\n",
      "  ✓ Saved (551 total)\n",
      "[552/797] Productive: 551 saved | https://en.wikipedia.org/wiki/Abstraction_(computer_science)...\n",
      "  ✓ Saved (552 total)\n",
      "[553/797] Productive: 552 saved | https://en.wikipedia.org/wiki/Agile_software_development...\n",
      "  ✓ Saved (553 total)\n",
      "[554/797] Productive: 553 saved | https://en.wikipedia.org/wiki/Behavior_tree...\n",
      "  ✓ Saved (554 total)\n",
      "[555/797] Productive: 554 saved | https://en.wikipedia.org/wiki/Bookmark_manager...\n",
      "  ✓ Saved (555 total)\n",
      "[556/797] Productive: 555 saved | https://en.wikipedia.org/wiki/Brownout_(software_engineering...\n",
      "  ✓ Saved (556 total)\n",
      "[557/797] Productive: 556 saved | https://en.wikipedia.org/wiki/Certified_software_development...\n",
      "  ✓ Saved (557 total)\n",
      "[558/797] Productive: 557 saved | https://en.wikipedia.org/wiki/Component-based_software_engin...\n",
      "  ✓ Saved (558 total)\n",
      "[559/797] Productive: 558 saved | https://en.wikipedia.org/wiki/Configuration_management...\n",
      "  ✓ Saved (559 total)\n",
      "[560/797] Productive: 559 saved | https://en.wikipedia.org/wiki/Data_engineering...\n",
      "  ✓ Saved (560 total)\n",
      "[561/797] Productive: 560 saved | https://en.wikipedia.org/wiki/Developer_Experience...\n",
      "  ✓ Saved (561 total)\n",
      "[562/797] Productive: 561 saved | https://en.wikipedia.org/wiki/Developer_relations...\n",
      "  ✓ Saved (562 total)\n",
      "[563/797] Productive: 562 saved | https://en.wikipedia.org/wiki/Empirical_software_engineering...\n",
      "  ✓ Saved (563 total)\n",
      "[564/797] Productive: 563 saved | https://en.wikipedia.org/wiki/Kim_Guldstrand_Larsen...\n",
      "  ✓ Saved (564 total)\n",
      "[565/797] Productive: 564 saved | https://en.wikipedia.org/wiki/History_of_software_engineerin...\n",
      "  ✓ Saved (565 total)\n",
      "[566/797] Productive: 565 saved | https://en.wikipedia.org/wiki/Integrated_development_environ...\n",
      "  ✓ Saved (566 total)\n",
      "[567/797] Productive: 566 saved | https://en.wikipedia.org/wiki/Mining_software_repositories...\n",
      "  ✓ Saved (567 total)\n",
      "[568/797] Productive: 567 saved | https://en.wikipedia.org/wiki/Mixed_criticality...\n",
      "  ✓ Saved (568 total)\n",
      "[569/797] Productive: 568 saved | https://en.wikipedia.org/wiki/Mobile_DevOps...\n",
      "  ✓ Saved (569 total)\n",
      "[570/797] Productive: 569 saved | https://en.wikipedia.org/wiki/Object_model...\n",
      "  ✓ Saved (570 total)\n",
      "[571/797] Productive: 570 saved | https://en.wikipedia.org/wiki/Observability_(software)...\n",
      "  ✓ Saved (571 total)\n",
      "[572/797] Productive: 571 saved | https://en.wikipedia.org/wiki/Outline_of_the_Python_programm...\n",
      "  ✓ Saved (572 total)\n",
      "[573/797] Productive: 572 saved | https://en.wikipedia.org/wiki/Process_map...\n",
      "  ✓ Saved (573 total)\n",
      "[574/797] Productive: 573 saved | https://en.wikipedia.org/wiki/Product-family_engineering...\n",
      "  ✓ Saved (574 total)\n",
      "[575/797] Productive: 574 saved | https://en.wikipedia.org/wiki/Protocol_engineering...\n",
      "  ✓ Saved (575 total)\n",
      "[576/797] Productive: 575 saved | https://en.wikipedia.org/wiki/Real-Time_UML...\n",
      "  ✓ Saved (576 total)\n",
      "[577/797] Productive: 576 saved | https://en.wikipedia.org/wiki/Research_software_engineering...\n",
      "  ✓ Saved (577 total)\n",
      "[578/797] Productive: 577 saved | https://en.wikipedia.org/wiki/SEMAT...\n",
      "  ✓ Saved (578 total)\n",
      "[579/797] Productive: 578 saved | https://en.wikipedia.org/wiki/Service-oriented_software_engi...\n",
      "  ✓ Saved (579 total)\n",
      "[580/797] Productive: 579 saved | https://en.wikipedia.org/wiki/Site_reliability_engineering...\n",
      "  ✓ Saved (580 total)\n",
      "[581/797] Productive: 580 saved | https://en.wikipedia.org/wiki/Social_software_engineering...\n",
      "  ✓ Saved (581 total)\n",
      "[582/797] Productive: 581 saved | https://en.wikipedia.org/wiki/Software_bot...\n",
      "  ✓ Saved (582 total)\n",
      "[583/797] Productive: 582 saved | https://en.wikipedia.org/wiki/Software_component...\n",
      "  ✓ Saved (583 total)\n",
      "[584/797] Productive: 583 saved | https://en.wikipedia.org/wiki/Software_configuration_managem...\n",
      "  ✓ Saved (584 total)\n",
      "[585/797] Productive: 584 saved | https://en.wikipedia.org/wiki/Software_construction...\n",
      "  ✓ Saved (585 total)\n",
      "[586/797] Productive: 585 saved | https://en.wikipedia.org/wiki/Software_design...\n",
      "  ✓ Saved (586 total)\n",
      "[587/797] Productive: 586 saved | https://en.wikipedia.org/wiki/Software_development_process...\n",
      "  ✓ Saved (587 total)\n",
      "[588/797] Productive: 587 saved | https://en.wikipedia.org/wiki/Software_diagnosis...\n",
      "  ✓ Saved (588 total)\n",
      "[589/797] Productive: 588 saved | https://en.wikipedia.org/wiki/Software_diversity...\n",
      "  ✓ Saved (589 total)\n",
      "[590/797] Productive: 589 saved | https://en.wikipedia.org/wiki/Software_durability...\n",
      "  ✓ Saved (590 total)\n",
      "[591/797] Productive: 590 saved | https://en.wikipedia.org/wiki/Software_engine...\n",
      "  ✓ Saved (591 total)\n",
      "[592/797] Productive: 591 saved | https://en.wikipedia.org/wiki/Software_engineering_demograph...\n",
      "  ✓ Saved (592 total)\n",
      "[593/797] Productive: 592 saved | https://en.wikipedia.org/wiki/Software_engineering_professio...\n",
      "  ✓ Saved (593 total)\n",
      "[594/797] Productive: 593 saved | https://en.wikipedia.org/wiki/Software_requirements...\n",
      "  ✓ Saved (594 total)\n",
      "[595/797] Productive: 594 saved | https://en.wikipedia.org/wiki/Static_program_analysis...\n",
      "  ✓ Saved (595 total)\n",
      "[596/797] Productive: 595 saved | https://en.wikipedia.org/wiki/Stevens_Award...\n",
      "  ✓ Saved (596 total)\n",
      "[597/797] Productive: 596 saved | https://en.wikipedia.org/wiki/Structural_synthesis_of_progra...\n",
      "  ✓ Saved (597 total)\n",
      "[598/797] Productive: 597 saved | https://en.wikipedia.org/wiki/System_appreciation...\n",
      "  ✓ Saved (598 total)\n",
      "[599/797] Productive: 598 saved | https://en.wikipedia.org/wiki/System_context_diagram...\n",
      "  ✓ Saved (599 total)\n",
      "[600/797] Productive: 599 saved | https://en.wikipedia.org/wiki/System_requirements_specificat...\n",
      "  ✓ Saved (600 total)\n",
      "[601/797] Productive: 600 saved | https://en.wikipedia.org/wiki/Systems_development_life_cycle...\n",
      "  ✓ Saved (601 total)\n",
      "[602/797] Productive: 601 saved | https://en.wikipedia.org/wiki/Tertiary_review...\n",
      "  ✓ Saved (602 total)\n",
      "[603/797] Productive: 602 saved | https://en.wikipedia.org/wiki/Test_data...\n",
      "  ✓ Saved (603 total)\n",
      "[604/797] Productive: 603 saved | https://en.wikipedia.org/wiki/Traceability...\n",
      "  ✓ Saved (604 total)\n",
      "[605/797] Productive: 604 saved | https://en.wikipedia.org/wiki/Unit_of_work...\n",
      "  ✓ Saved (605 total)\n",
      "[606/797] Productive: 605 saved | https://en.wikipedia.org/wiki/View_model...\n",
      "  ✓ Saved (606 total)\n",
      "[607/797] Productive: 606 saved | https://en.wikipedia.org/wiki/Computer_programming...\n",
      "  ✓ Saved (607 total)\n",
      "[608/797] Productive: 607 saved | https://en.wikipedia.org/wiki/Outline_of_computer_programmin...\n",
      "  ✓ Saved (608 total)\n",
      "[609/797] Productive: 608 saved | https://en.wikipedia.org/wiki/List_of_programming_languages...\n",
      "  ✓ Saved (609 total)\n",
      "[610/797] Productive: 609 saved | https://en.wikipedia.org/wiki/Algorave...\n",
      "  ✓ Saved (610 total)\n",
      "[611/797] Productive: 610 saved | https://en.wikipedia.org/wiki/Asynchronous_procedure_call...\n",
      "  ✓ Saved (611 total)\n",
      "[612/797] Productive: 611 saved | https://en.wikipedia.org/wiki/Asynchrony_(computer_programmi...\n",
      "  ✓ Saved (612 total)\n",
      "[613/797] Productive: 612 saved | https://en.wikipedia.org/wiki/Bayesian_program_synthesis...\n",
      "  ✓ Saved (613 total)\n",
      "[614/797] Productive: 613 saved | https://en.wikipedia.org/wiki/Boolean_flag...\n",
      "  ✓ Saved (614 total)\n",
      "[615/797] Productive: 614 saved | https://en.wikipedia.org/wiki/Cheat_sheet...\n",
      "  ✓ Saved (615 total)\n",
      "[616/797] Productive: 615 saved | https://en.wikipedia.org/wiki/Code_Club...\n",
      "  ✓ Saved (616 total)\n",
      "[617/797] Productive: 616 saved | https://en.wikipedia.org/wiki/Code_Words...\n",
      "  ✓ Saved (617 total)\n",
      "[618/797] Productive: 617 saved | https://en.wikipedia.org/wiki/Codecademy...\n",
      "  ✓ Saved (618 total)\n",
      "[619/797] Productive: 618 saved | https://en.wikipedia.org/wiki/CodeCombat...\n",
      "  ✓ Saved (619 total)\n",
      "[620/797] Productive: 619 saved | https://en.wikipedia.org/wiki/CodeHS...\n",
      "  ✓ Saved (620 total)\n",
      "[621/797] Productive: 620 saved | https://en.wikipedia.org/wiki/CoderDojo...\n",
      "  ✓ Saved (621 total)\n",
      "[622/797] Productive: 621 saved | https://en.wikipedia.org/wiki/Codewars...\n",
      "  ✓ Saved (622 total)\n",
      "[623/797] Productive: 622 saved | https://en.wikipedia.org/wiki/Coding_best_practices...\n",
      "  ✓ Saved (623 total)\n",
      "[624/797] Productive: 623 saved | https://en.wikipedia.org/wiki/Compile_and_go_system...\n",
      "  ✓ Saved (624 total)\n",
      "[625/797] Productive: 624 saved | https://en.wikipedia.org/wiki/Computer_network_programming...\n",
      "  ✓ Saved (625 total)\n",
      "[626/797] Productive: 625 saved | https://en.wikipedia.org/wiki/Computer_program...\n",
      "  ✓ Saved (626 total)\n",
      "[627/797] Productive: 626 saved | https://en.wikipedia.org/wiki/Copy-and-paste_programming...\n",
      "  ✓ Saved (627 total)\n",
      "[628/797] Productive: 627 saved | https://en.wikipedia.org/wiki/Creative_coding...\n",
      "  ✓ Saved (628 total)\n",
      "[629/797] Productive: 628 saved | https://en.wikipedia.org/wiki/Daily_build...\n",
      "  ✓ Saved (629 total)\n",
      "[630/797] Productive: 629 saved | https://en.wikipedia.org/wiki/Dangling_else...\n",
      "  ✓ Saved (630 total)\n",
      "[631/797] Productive: 630 saved | https://en.wikipedia.org/wiki/DatalogZ...\n",
      "  ✓ Saved (631 total)\n",
      "[632/797] Productive: 631 saved | https://en.wikipedia.org/wiki/Deductive_language...\n",
      "  ✓ Saved (632 total)\n",
      "[633/797] Productive: 632 saved | https://en.wikipedia.org/wiki/Derivative_code...\n",
      "  ✓ Saved (633 total)\n",
      "[634/797] Productive: 633 saved | https://en.wikipedia.org/wiki/Deutsch_limit...\n",
      "  ✓ Saved (634 total)\n",
      "[635/797] Productive: 634 saved | https://en.wikipedia.org/wiki/Directive_(programming)...\n",
      "  ✓ Saved (635 total)\n",
      "[636/797] Productive: 635 saved | https://en.wikipedia.org/wiki/End-user_development...\n",
      "  ✓ Saved (636 total)\n",
      "[637/797] Productive: 636 saved | https://en.wikipedia.org/wiki/Energy_modeling...\n",
      "  ✓ Saved (637 total)\n",
      "[638/797] Productive: 637 saved | https://en.wikipedia.org/wiki/Entry_point...\n",
      "  ✓ Saved (638 total)\n",
      "[639/797] Productive: 638 saved | https://en.wikipedia.org/wiki/EPANET...\n",
      "  ✓ Saved (639 total)\n",
      "[640/797] Productive: 639 saved | https://en.wikipedia.org/wiki/Error_guessing...\n",
      "  ✓ Saved (640 total)\n",
      "[641/797] Productive: 640 saved | https://en.wikipedia.org/wiki/Event_(computing)...\n",
      "  ✓ Saved (641 total)\n",
      "[642/797] Productive: 641 saved | https://en.wikipedia.org/wiki/Example-centric_programming...\n",
      "  ✓ Saved (642 total)\n",
      "[643/797] Productive: 642 saved | https://en.wikipedia.org/wiki/Extempore_(software)...\n",
      "  ✓ Saved (643 total)\n",
      "[644/797] Productive: 643 saved | https://en.wikipedia.org/wiki/Feature_toggle...\n",
      "  ✓ Saved (644 total)\n",
      "[645/797] Productive: 644 saved | https://en.wikipedia.org/wiki/Flatiron_School...\n",
      "  ✓ Saved (645 total)\n",
      "[646/797] Productive: 645 saved | https://en.wikipedia.org/wiki/Flowchart...\n",
      "  ✓ Saved (646 total)\n",
      "[647/797] Productive: 646 saved | https://en.wikipedia.org/wiki/Floyd's_triangle...\n",
      "  ✓ Saved (647 total)\n",
      "[648/797] Productive: 647 saved | https://en.wikipedia.org/wiki/Fluxus_(programming_environmen...\n",
      "  ✓ Saved (648 total)\n",
      "[649/797] Productive: 648 saved | https://en.wikipedia.org/wiki/Free_variables_and_bound_varia...\n",
      "  ✓ Saved (649 total)\n",
      "[650/797] Productive: 649 saved | https://en.wikipedia.org/wiki/FreeCodeCamp...\n",
      "  ✓ Saved (650 total)\n",
      "[651/797] Productive: 650 saved | https://en.wikipedia.org/wiki/Fully_qualified_name...\n",
      "  ✓ Saved (651 total)\n",
      "[652/797] Productive: 651 saved | https://en.wikipedia.org/wiki/Function_prototype...\n",
      "  ✓ Saved (652 total)\n",
      "[653/797] Productive: 652 saved | https://en.wikipedia.org/wiki/Garbage_(computer_science)...\n",
      "  ✓ Saved (653 total)\n",
      "[654/797] Productive: 653 saved | https://en.wikipedia.org/wiki/Geocoder_(Ruby)...\n",
      "  ✓ Saved (654 total)\n",
      "[655/797] Productive: 654 saved | https://en.wikipedia.org/wiki/Ghana_Code_Club...\n",
      "  ✓ Saved (655 total)\n",
      "[656/797] Productive: 655 saved | https://en.wikipedia.org/wiki/Global_Offset_Table...\n",
      "  ✓ Saved (656 total)\n",
      "[657/797] Productive: 656 saved | https://en.wikipedia.org/wiki/Glue_code...\n",
      "  ✓ Saved (657 total)\n",
      "[658/797] Productive: 657 saved | https://en.wikipedia.org/wiki/GUVI...\n",
      "  ✓ Saved (658 total)\n",
      "[659/797] Productive: 658 saved | https://en.wikipedia.org/wiki/Hack_Club...\n",
      "  ✓ Saved (659 total)\n",
      "[660/797] Productive: 659 saved | https://en.wikipedia.org/wiki/Hacker...\n",
      "  ✓ Saved (660 total)\n",
      "[661/797] Productive: 660 saved | https://en.wikipedia.org/wiki/Hand_coding...\n",
      "  ✓ Saved (661 total)\n",
      "[662/797] Productive: 661 saved | https://en.wikipedia.org/wiki/Happy_path...\n",
      "  ✓ Saved (662 total)\n",
      "[663/797] Productive: 662 saved | https://en.wikipedia.org/wiki/Identity_transform...\n",
      "  ✓ Saved (663 total)\n",
      "[664/797] Productive: 663 saved | https://en.wikipedia.org/wiki/Integrated_Water_Flow_Model...\n",
      "  ✓ Saved (664 total)\n",
      "[665/797] Productive: 664 saved | https://en.wikipedia.org/wiki/Intrinsic_function...\n",
      "  ✓ Saved (665 total)\n",
      "[666/797] Productive: 665 saved | https://en.wikipedia.org/wiki/Invariant_(computer_science)...\n",
      "  ✓ Saved (666 total)\n",
      "[667/797] Productive: 666 saved | https://en.wikipedia.org/wiki/Ixi_lang...\n",
      "  ✓ Saved (667 total)\n",
      "[668/797] Productive: 667 saved | https://en.wikipedia.org/wiki/JuMP...\n",
      "  ✓ Saved (668 total)\n",
      "[669/797] Productive: 668 saved | https://en.wikipedia.org/wiki/Language-Theoretic_Security...\n",
      "  ✓ Saved (669 total)\n",
      "[670/797] Productive: 669 saved | https://en.wikipedia.org/wiki/LaunchCode...\n",
      "  ✓ Saved (670 total)\n",
      "[671/797] Productive: 670 saved | https://en.wikipedia.org/wiki/Lighthouse_Labs...\n",
      "  ✓ Saved (671 total)\n",
      "[672/797] Productive: 671 saved | https://en.wikipedia.org/wiki/Lightweight_programming_langua...\n",
      "  ✓ Saved (672 total)\n",
      "[673/797] Productive: 672 saved | https://en.wikipedia.org/wiki/List_of_program_transformation...\n",
      "  ✓ Saved (673 total)\n",
      "[674/797] Productive: 673 saved | https://en.wikipedia.org/wiki/Lists_of_programming_software_...\n",
      "  ✓ Saved (674 total)\n",
      "[675/797] Productive: 674 saved | https://en.wikipedia.org/wiki/Live_coding...\n",
      "  ✓ Saved (675 total)\n",
      "[676/797] Productive: 675 saved | https://en.wikipedia.org/wiki/Locks-and-keys_(computing)...\n",
      "  ✓ Saved (676 total)\n",
      "[677/797] Productive: 676 saved | https://en.wikipedia.org/wiki/Loop-switch_sequence...\n",
      "  ✓ Saved (677 total)\n",
      "[678/797] Productive: 677 saved | https://en.wikipedia.org/wiki/Macro_instruction...\n",
      "  ✓ Saved (678 total)\n",
      "[679/797] Productive: 678 saved | https://en.wikipedia.org/wiki/Makers_Academy...\n",
      "  ✓ Saved (679 total)\n",
      "[680/797] Productive: 679 saved | https://en.wikipedia.org/wiki/Malware...\n",
      "  ✓ Saved (680 total)\n",
      "[681/797] Productive: 680 saved | https://en.wikipedia.org/wiki/Nassi–Shneiderman_diagram...\n",
      "  ✓ Saved (681 total)\n",
      "[682/797] Productive: 681 saved | https://en.wikipedia.org/wiki/National_Computer_Rank_Examina...\n",
      "  ✓ Saved (682 total)\n",
      "[683/797] Productive: 682 saved | https://en.wikipedia.org/wiki/Natural_language_programming...\n",
      "  ✓ Saved (683 total)\n",
      "[684/797] Productive: 683 saved | https://en.wikipedia.org/wiki/Nested_quotation...\n",
      "  ✓ Saved (684 total)\n",
      "[685/797] Productive: 684 saved | https://en.wikipedia.org/wiki/Nesting_(computing)...\n",
      "  ✓ Saved (685 total)\n",
      "[686/797] Productive: 685 saved | https://en.wikipedia.org/wiki/Neutral_build...\n",
      "  ✓ Saved (686 total)\n",
      "[687/797] Productive: 686 saved | https://en.wikipedia.org/wiki/Nondeterministic_programming...\n",
      "  ✓ Saved (687 total)\n",
      "[688/797] Productive: 687 saved | https://en.wikipedia.org/wiki/Observer_effect_(information_t...\n",
      "  ✓ Saved (688 total)\n",
      "[689/797] Productive: 688 saved | https://en.wikipedia.org/wiki/OLE_DB_for_OLAP...\n",
      "  ✓ Saved (689 total)\n",
      "[690/797] Productive: 689 saved | https://en.wikipedia.org/wiki/One-liner_program...\n",
      "  ✓ Saved (690 total)\n",
      "[691/797] Productive: 690 saved | https://en.wikipedia.org/wiki/Opaque_pointer...\n",
      "  ✓ Saved (691 total)\n",
      "[692/797] Productive: 691 saved | https://en.wikipedia.org/wiki/Opaque_predicate...\n",
      "  ✓ Saved (692 total)\n",
      "[693/797] Productive: 692 saved | https://en.wikipedia.org/wiki/Open_Agent_Architecture...\n",
      "  ✓ Saved (693 total)\n",
      "[694/797] Productive: 693 saved | https://en.wikipedia.org/wiki/Open_Database_Connectivity...\n",
      "  ✓ Saved (694 total)\n",
      "[695/797] Productive: 694 saved | https://en.wikipedia.org/wiki/Open_energy_system_models...\n",
      "  ✓ Saved (695 total)\n",
      "[696/797] Productive: 695 saved | https://en.wikipedia.org/wiki/Performance_portability...\n",
      "  ✓ Saved (696 total)\n",
      "[697/797] Productive: 696 saved | https://en.wikipedia.org/wiki/Persistence_(computer_science)...\n",
      "  ✓ Saved (697 total)\n",
      "[698/797] Productive: 697 saved | https://en.wikipedia.org/wiki/Phase_distinction...\n",
      "  ✓ Saved (698 total)\n",
      "[699/797] Productive: 698 saved | https://en.wikipedia.org/wiki/Polyglot_(computing)...\n",
      "  ✓ Saved (699 total)\n",
      "[700/797] Productive: 699 saved | https://en.wikipedia.org/wiki/Polyglot_persistence...\n",
      "  ✓ Saved (700 total)\n",
      "[701/797] Productive: 700 saved | https://en.wikipedia.org/wiki/Predeclared...\n",
      "  ✓ Saved (701 total)\n",
      "[702/797] Productive: 701 saved | https://en.wikipedia.org/wiki/Privatization_(computer_progra...\n",
      "  ✓ Saved (702 total)\n",
      "[703/797] Productive: 702 saved | https://en.wikipedia.org/wiki/Procedural_design...\n",
      "  ✓ Saved (703 total)\n",
      "[704/797] Productive: 703 saved | https://en.wikipedia.org/wiki/Program_comprehension...\n",
      "  ✓ Saved (704 total)\n",
      "[705/797] Productive: 704 saved | https://en.wikipedia.org/wiki/Program-specific_information...\n",
      "  ✓ Saved (705 total)\n",
      "[706/797] Productive: 705 saved | https://en.wikipedia.org/wiki/Programming_by_permutation...\n",
      "  ✓ Saved (706 total)\n",
      "[707/797] Productive: 706 saved | https://en.wikipedia.org/wiki/Programming_model...\n",
      "  ✓ Saved (707 total)\n",
      "[708/797] Productive: 707 saved | https://en.wikipedia.org/wiki/Proto.io...\n",
      "  ✓ Saved (708 total)\n",
      "[709/797] Productive: 708 saved | https://en.wikipedia.org/wiki/Psychology_of_programming...\n",
      "  ✓ Saved (709 total)\n",
      "[710/797] Productive: 709 saved | https://en.wikipedia.org/wiki/Computer_programming_in_the_pu...\n",
      "  ✓ Saved (710 total)\n",
      "[711/797] Productive: 710 saved | https://en.wikipedia.org/wiki/Refinement_(computing)...\n",
      "  ✓ Saved (711 total)\n",
      "[712/797] Productive: 711 saved | https://en.wikipedia.org/wiki/Reverse_architecture...\n",
      "  ✓ Saved (712 total)\n",
      "[713/797] Productive: 712 saved | https://en.wikipedia.org/wiki/Rewrite_(programming)...\n",
      "  ✓ Saved (713 total)\n",
      "[714/797] Productive: 713 saved | https://en.wikipedia.org/wiki/Rosalind_(education_platform)...\n",
      "  ✓ Saved (714 total)\n",
      "[715/797] Productive: 714 saved | https://en.wikipedia.org/wiki/List_of_Ruby_software_and_tool...\n",
      "  ✓ Saved (715 total)\n",
      "[716/797] Productive: 715 saved | https://en.wikipedia.org/wiki/Scaffold_(programming)...\n",
      "  ✓ Saved (716 total)\n",
      "[717/797] Productive: 716 saved | https://en.wikipedia.org/wiki/Self-documenting_code...\n",
      "  ✓ Saved (717 total)\n",
      "[718/797] Productive: 717 saved | https://en.wikipedia.org/wiki/Self-hosting_(compilers)...\n",
      "  ✓ Saved (718 total)\n",
      "[719/797] Productive: 718 saved | https://en.wikipedia.org/wiki/Self-relocation...\n",
      "  ✓ Saved (719 total)\n",
      "[720/797] Productive: 719 saved | https://en.wikipedia.org/wiki/Services_computing...\n",
      "  ✓ Saved (720 total)\n",
      "[721/797] Productive: 720 saved | https://en.wikipedia.org/wiki/Side_effect_(computer_science)...\n",
      "  ✓ Saved (721 total)\n",
      "[722/797] Productive: 721 saved | https://en.wikipedia.org/wiki/Signed_overpunch...\n",
      "  ✓ Saved (722 total)\n",
      "[723/797] Productive: 722 saved | https://en.wikipedia.org/wiki/Skeleton_(computer_programming...\n",
      "  ✓ Saved (723 total)\n",
      "[724/797] Productive: 723 saved | https://en.wikipedia.org/wiki/Software_build...\n",
      "  ✓ Saved (724 total)\n",
      "[725/797] Productive: 724 saved | https://en.wikipedia.org/wiki/Software_craftsmanship...\n",
      "  ✓ Saved (725 total)\n",
      "[726/797] Productive: 725 saved | https://en.wikipedia.org/wiki/Sonic_Pi...\n",
      "  ✓ Saved (726 total)\n",
      "[727/797] Productive: 726 saved | https://en.wikipedia.org/wiki/Standalone_program...\n",
      "  ✓ Saved (727 total)\n",
      "[728/797] Productive: 727 saved | https://en.wikipedia.org/wiki/Stanza_(computing)...\n",
      "  ✓ Saved (728 total)\n",
      "[729/797] Productive: 728 saved | https://en.wikipedia.org/wiki/Stripped_binary...\n",
      "  ✓ Saved (729 total)\n",
      "[730/797] Productive: 729 saved | https://en.wikipedia.org/wiki/SwitchUp...\n",
      "  ✓ Saved (730 total)\n",
      "[731/797] Productive: 730 saved | https://en.wikipedia.org/wiki/System_time...\n",
      "  ✓ Saved (731 total)\n",
      "[732/797] Productive: 731 saved | https://en.wikipedia.org/wiki/Systems_programming...\n",
      "  ✓ Saved (732 total)\n",
      "[733/797] Productive: 732 saved | https://en.wikipedia.org/wiki/Taint_checking...\n",
      "  ✓ Saved (733 total)\n",
      "[734/797] Productive: 733 saved | https://en.wikipedia.org/wiki/Term_(programming)...\n",
      "  ✓ Saved (734 total)\n",
      "[735/797] Productive: 734 saved | https://en.wikipedia.org/wiki/Third-party_software_component...\n",
      "  ✓ Saved (735 total)\n",
      "[736/797] Productive: 735 saved | https://en.wikipedia.org/wiki/TidalCycles...\n",
      "  ✓ Saved (736 total)\n",
      "[737/797] Productive: 736 saved | https://en.wikipedia.org/wiki/Timeout_(computing)...\n",
      "  ✓ Saved (737 total)\n",
      "[738/797] Productive: 737 saved | https://en.wikipedia.org/wiki/Tombstone_diagram...\n",
      "  ✓ Saved (738 total)\n",
      "[739/797] Productive: 738 saved | https://en.wikipedia.org/wiki/Transient_(computer_programmin...\n",
      "  ✓ Saved (739 total)\n",
      "[740/797] Productive: 739 saved | https://en.wikipedia.org/wiki/Treehouse_(company)...\n",
      "  ✓ Saved (740 total)\n",
      "[741/797] Productive: 740 saved | https://en.wikipedia.org/wiki/Unspecified_behavior...\n",
      "  ✓ Saved (741 total)\n",
      "[742/797] Productive: 741 saved | https://en.wikipedia.org/wiki/Variadic_template...\n",
      "  ✓ Saved (742 total)\n",
      "[743/797] Productive: 742 saved | https://en.wikipedia.org/wiki/Winner-take-all_in_action_sele...\n",
      "  ✓ Saved (743 total)\n",
      "[744/797] Productive: 743 saved | https://en.wikipedia.org/wiki/Workspace...\n",
      "  ✓ Saved (744 total)\n",
      "[745/797] Productive: 744 saved | https://en.wikipedia.org/wiki/Yoda_conditions...\n",
      "  ✓ Saved (745 total)\n",
      "[746/797] Productive: 745 saved | https://en.wikipedia.org/wiki/Mathematics...\n",
      "  ✓ Saved (746 total)\n",
      "[747/797] Productive: 746 saved | https://en.wikipedia.org/wiki/Language_of_mathematics...\n",
      "  ✓ Saved (747 total)\n",
      "[748/797] Productive: 747 saved | https://en.wikipedia.org/wiki/Lorenz_system...\n",
      "  ✓ Saved (748 total)\n",
      "[749/797] Productive: 748 saved | https://en.wikipedia.org/wiki/Physics...\n",
      "  ✓ Saved (749 total)\n",
      "[750/797] Productive: 749 saved | https://en.wikipedia.org/wiki/Edge_states...\n",
      "  ✓ Saved (750 total)\n",
      "[751/797] Productive: 750 saved | https://en.wikipedia.org/wiki/Electrostatic_solitary_wave...\n",
      "  ✓ Saved (751 total)\n",
      "[752/797] Productive: 751 saved | https://en.wikipedia.org/wiki/Frenesy_(physics)...\n",
      "  ✓ Saved (752 total)\n",
      "[753/797] Productive: 752 saved | https://en.wikipedia.org/wiki/Haloscope_(physics)...\n",
      "  ✓ Saved (753 total)\n",
      "[754/797] Productive: 753 saved | https://en.wikipedia.org/wiki/HUN-REN_Wigner_Research_Centre...\n",
      "  ✓ Saved (754 total)\n",
      "[755/797] Productive: 754 saved | https://en.wikipedia.org/wiki/Joaquim_da_Costa_Ribeiro...\n",
      "  ✓ Saved (755 total)\n",
      "[756/797] Productive: 755 saved | https://en.wikipedia.org/wiki/Missile_lofting...\n",
      "  ✓ Saved (756 total)\n",
      "[757/797] Productive: 756 saved | https://en.wikipedia.org/wiki/Modern_physics...\n",
      "  ✓ Saved (757 total)\n",
      "[758/797] Productive: 757 saved | https://en.wikipedia.org/wiki/Naïve_physics...\n",
      "  ✓ Saved (758 total)\n",
      "[759/797] Productive: 758 saved | https://en.wikipedia.org/wiki/Negative_air_ions...\n",
      "  ✓ Saved (759 total)\n",
      "[760/797] Productive: 759 saved | https://en.wikipedia.org/wiki/Nottingham_effect...\n",
      "  ✓ Saved (760 total)\n",
      "[761/797] Productive: 760 saved | https://en.wikipedia.org/wiki/Nucleation...\n",
      "  ✓ Saved (761 total)\n",
      "[762/797] Productive: 761 saved | https://en.wikipedia.org/wiki/Perfect_fluid...\n",
      "  ✓ Saved (762 total)\n",
      "[763/797] Productive: 762 saved | https://en.wikipedia.org/wiki/Physics_of_Life...\n",
      "  ✓ Saved (763 total)\n",
      "[764/797] Productive: 763 saved | https://en.wikipedia.org/wiki/Plasmaron...\n",
      "  ✓ Saved (764 total)\n",
      "[765/797] Productive: 764 saved | https://en.wikipedia.org/wiki/Quasi-isodynamic_stellarator...\n",
      "  ✓ Saved (765 total)\n",
      "[766/797] Productive: 765 saved | https://en.wikipedia.org/wiki/SDSS_J120136.02+300305.5...\n",
      "  ✓ Saved (766 total)\n",
      "[767/797] Productive: 766 saved | https://en.wikipedia.org/wiki/Shockwave_cosmology...\n",
      "  ✓ Saved (767 total)\n",
      "[768/797] Productive: 767 saved | https://en.wikipedia.org/wiki/Surface_stress...\n",
      "  ✓ Saved (768 total)\n",
      "[769/797] Productive: 768 saved | https://en.wikipedia.org/wiki/Synchronous_lateral_excitation...\n",
      "  ✓ Saved (769 total)\n",
      "[770/797] Productive: 769 saved | https://en.wikipedia.org/wiki/Thermal_energy...\n",
      "  ✓ Saved (770 total)\n",
      "[771/797] Productive: 770 saved | https://en.wikipedia.org/wiki/Toroidal_solenoid...\n",
      "  ✓ Saved (771 total)\n",
      "[772/797] Productive: 771 saved | https://en.wikipedia.org/wiki/Wohlfarth_Lectureship...\n",
      "  ✓ Saved (772 total)\n",
      "[773/797] Productive: 772 saved | https://en.wikipedia.org/wiki/Biology...\n",
      "  ✓ Saved (773 total)\n",
      "[774/797] Productive: 773 saved | https://en.wikipedia.org/wiki/Biologist...\n",
      "  ✓ Saved (774 total)\n",
      "[775/797] Productive: 774 saved | https://en.wikipedia.org/wiki/Bibliography_of_encyclopedias:...\n",
      "  ✓ Saved (775 total)\n",
      "[776/797] Productive: 775 saved | https://en.wikipedia.org/wiki/Bioactive_terrarium...\n",
      "  ✓ Saved (776 total)\n",
      "[777/797] Productive: 776 saved | https://en.wikipedia.org/wiki/Bioliteracy...\n",
      "  ✓ Saved (777 total)\n",
      "[778/797] Productive: 777 saved | https://en.wikipedia.org/wiki/Biological_constraints...\n",
      "  ✓ Saved (778 total)\n",
      "[779/797] Productive: 778 saved | https://en.wikipedia.org/wiki/Biology_of_romantic_love...\n",
      "  ✓ Saved (779 total)\n",
      "[780/797] Productive: 779 saved | https://en.wikipedia.org/wiki/Biospeleology...\n",
      "  ✓ Saved (780 total)\n",
      "[781/797] Productive: 780 saved | https://en.wikipedia.org/wiki/Cancer_exodus_hypothesis...\n",
      "  ✓ Saved (781 total)\n",
      "[782/797] Productive: 781 saved | https://en.wikipedia.org/wiki/Chlororespiration...\n",
      "  ✓ Saved (782 total)\n",
      "[783/797] Productive: 782 saved | https://en.wikipedia.org/wiki/Dermestarium...\n",
      "  ✓ Saved (783 total)\n",
      "[784/797] Productive: 783 saved | https://en.wikipedia.org/wiki/Endogeny_(biology)...\n",
      "  ✓ Saved (784 total)\n",
      "[785/797] Productive: 784 saved | https://en.wikipedia.org/wiki/Excretion...\n",
      "  ✓ Saved (785 total)\n",
      "[786/797] Productive: 785 saved | https://en.wikipedia.org/wiki/Functional_information...\n",
      "  ✓ Saved (786 total)\n",
      "[787/797] Productive: 786 saved | https://en.wikipedia.org/wiki/High_throughput_biology...\n",
      "  ✓ Saved (787 total)\n",
      "[788/797] Productive: 787 saved | https://en.wikipedia.org/wiki/Interdigitation...\n",
      "  ✓ Saved (788 total)\n",
      "[789/797] Productive: 788 saved | https://en.wikipedia.org/wiki/Plasmagene...\n",
      "  ✓ Saved (789 total)\n",
      "[790/797] Productive: 789 saved | https://en.wikipedia.org/wiki/Poison_exon...\n",
      "  ✓ Saved (790 total)\n",
      "[791/797] Productive: 790 saved | https://en.wikipedia.org/wiki/Polylecty...\n",
      "  ✓ Saved (791 total)\n",
      "[792/797] Productive: 791 saved | https://en.wikipedia.org/wiki/Spatial_biology...\n",
      "  ✓ Saved (792 total)\n",
      "[793/797] Productive: 792 saved | https://en.wikipedia.org/wiki/Tokogeny...\n",
      "  ✓ Saved (793 total)\n",
      "[794/797] Productive: 793 saved | https://en.wikipedia.org/wiki/Universality–diversity_paradig...\n",
      "  ✓ Saved (794 total)\n",
      "[795/797] Productive: 794 saved | https://en.wikipedia.org/wiki/Artificial_intelligence...\n",
      "  ✓ Saved (795 total)\n",
      "[796/797] Productive: 795 saved | https://en.wikipedia.org/wiki/Deep_learning...\n",
      "  ✓ Saved (796 total)\n",
      "[797/797] Productive: 796 saved | https://en.wikipedia.org/wiki/Neural_network...\n",
      "  ✓ Saved (797 total)\n",
      "\n",
      "======================================================================\n",
      "PRODUCTIVE Summary:\n",
      "  Saved: 797\n",
      "  Filtered: 0\n",
      "  Failed: 0\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: COLLECTING UNPRODUCTIVE CONTENT\n",
      "======================================================================\n",
      "\n",
      "[Reddit] Scraping r/funny (top/all)\n",
      "  Collected 1 posts from r/funny\n",
      "\n",
      "[Reddit] Scraping r/memes (top/all)\n",
      "  Collected 0 posts from r/memes\n",
      "\n",
      "[Reddit] Scraping r/gaming (top/all)\n",
      "  Collected 6 posts from r/gaming\n",
      "\n",
      "[Reddit] Scraping r/movies (top/all)\n",
      "  Collected 15 posts from r/movies\n",
      "\n",
      "[Reddit] Scraping r/television (top/all)\n",
      "  Collected 15 posts from r/television\n",
      "\n",
      "[Reddit] Scraping r/entertainment (top/all)\n",
      "  Collected 0 posts from r/entertainment\n",
      "\n",
      "[Reddit] Scraping r/Jokes (top/all)\n",
      "  Collected 89 posts from r/Jokes\n",
      "\n",
      "[Reddit] Scraping r/AdviceAnimals (top/all)\n",
      "  Collected 1 posts from r/AdviceAnimals\n",
      "\n",
      "[Reddit] Scraping r/facepalm (top/all)\n",
      "  Collected 0 posts from r/facepalm\n",
      "\n",
      "[Reddit] Scraping r/aww (top/all)\n",
      "  Collected 1 posts from r/aww\n",
      "\n",
      "Total unproductive items collected: 128\n",
      "\n",
      "======================================================================\n",
      "Scraping 128 items for: UNPRODUCTIVE\n",
      "Target: 3000 samples\n",
      "======================================================================\n",
      "\n",
      "[1/128] Unproductive: 0 saved | Direct text...\n",
      "  ✓ Saved (1 total)\n",
      "[2/128] Unproductive: 1 saved | Direct text...\n",
      "  ✓ Saved (2 total)\n",
      "[3/128] Unproductive: 2 saved | Direct text...\n",
      "  ✓ Saved (3 total)\n",
      "[4/128] Unproductive: 3 saved | Direct text...\n",
      "  ✓ Saved (4 total)\n",
      "[5/128] Unproductive: 4 saved | Direct text...\n",
      "  ✓ Saved (5 total)\n",
      "[6/128] Unproductive: 5 saved | Direct text...\n",
      "  ✓ Saved (6 total)\n",
      "[7/128] Unproductive: 6 saved | Direct text...\n",
      "  ✓ Saved (7 total)\n",
      "[8/128] Unproductive: 7 saved | Direct text...\n",
      "  ✓ Saved (8 total)\n",
      "[9/128] Unproductive: 8 saved | Direct text...\n",
      "  ✓ Saved (9 total)\n",
      "[10/128] Unproductive: 9 saved | Direct text...\n",
      "  ✓ Saved (10 total)\n",
      "[11/128] Unproductive: 10 saved | Direct text...\n",
      "  ✓ Saved (11 total)\n",
      "[12/128] Unproductive: 11 saved | Direct text...\n",
      "  ✓ Saved (12 total)\n",
      "[13/128] Unproductive: 12 saved | Direct text...\n",
      "  ✓ Saved (13 total)\n",
      "[14/128] Unproductive: 13 saved | Direct text...\n",
      "  ✓ Saved (14 total)\n",
      "[15/128] Unproductive: 14 saved | Direct text...\n",
      "  ✓ Saved (15 total)\n",
      "[16/128] Unproductive: 15 saved | Direct text...\n",
      "  ✓ Saved (16 total)\n",
      "[17/128] Unproductive: 16 saved | Direct text...\n",
      "  ✓ Saved (17 total)\n",
      "[18/128] Unproductive: 17 saved | Direct text...\n",
      "  ✓ Saved (18 total)\n",
      "[19/128] Unproductive: 18 saved | Direct text...\n",
      "  ✓ Saved (19 total)\n",
      "[20/128] Unproductive: 19 saved | Direct text...\n",
      "  ✓ Saved (20 total)\n",
      "[21/128] Unproductive: 20 saved | Direct text...\n",
      "  ✓ Saved (21 total)\n",
      "[22/128] Unproductive: 21 saved | Direct text...\n",
      "  ✓ Saved (22 total)\n",
      "[23/128] Unproductive: 22 saved | Direct text...\n",
      "  ✓ Saved (23 total)\n",
      "[24/128] Unproductive: 23 saved | Direct text...\n",
      "  ✓ Saved (24 total)\n",
      "[25/128] Unproductive: 24 saved | Direct text...\n",
      "  ✓ Saved (25 total)\n",
      "[26/128] Unproductive: 25 saved | Direct text...\n",
      "  ✓ Saved (26 total)\n",
      "[27/128] Unproductive: 26 saved | Direct text...\n",
      "  ✓ Saved (27 total)\n",
      "[28/128] Unproductive: 27 saved | Direct text...\n",
      "  ✓ Saved (28 total)\n",
      "[29/128] Unproductive: 28 saved | Direct text...\n",
      "  ✓ Saved (29 total)\n",
      "[30/128] Unproductive: 29 saved | Direct text...\n",
      "  ✓ Saved (30 total)\n",
      "[31/128] Unproductive: 30 saved | Direct text...\n",
      "  ✓ Saved (31 total)\n",
      "[32/128] Unproductive: 31 saved | Direct text...\n",
      "  ✓ Saved (32 total)\n",
      "[33/128] Unproductive: 32 saved | Direct text...\n",
      "  ✓ Saved (33 total)\n",
      "[34/128] Unproductive: 33 saved | Direct text...\n",
      "  ✓ Saved (34 total)\n",
      "[35/128] Unproductive: 34 saved | Direct text...\n",
      "  ✓ Saved (35 total)\n",
      "[36/128] Unproductive: 35 saved | Direct text...\n",
      "  ✓ Saved (36 total)\n",
      "[37/128] Unproductive: 36 saved | Direct text...\n",
      "  ✓ Saved (37 total)\n",
      "[38/128] Unproductive: 37 saved | Direct text...\n",
      "  ✓ Saved (38 total)\n",
      "[39/128] Unproductive: 38 saved | Direct text...\n",
      "  ✓ Saved (39 total)\n",
      "[40/128] Unproductive: 39 saved | Direct text...\n",
      "  ✓ Saved (40 total)\n",
      "[41/128] Unproductive: 40 saved | Direct text...\n",
      "  ✓ Saved (41 total)\n",
      "[42/128] Unproductive: 41 saved | Direct text...\n",
      "  ✓ Saved (42 total)\n",
      "[43/128] Unproductive: 42 saved | Direct text...\n",
      "  ✓ Saved (43 total)\n",
      "[44/128] Unproductive: 43 saved | Direct text...\n",
      "  ✓ Saved (44 total)\n",
      "[45/128] Unproductive: 44 saved | Direct text...\n",
      "  ✓ Saved (45 total)\n",
      "[46/128] Unproductive: 45 saved | Direct text...\n",
      "  ✓ Saved (46 total)\n",
      "[47/128] Unproductive: 46 saved | Direct text...\n",
      "  ✓ Saved (47 total)\n",
      "[48/128] Unproductive: 47 saved | Direct text...\n",
      "  ✓ Saved (48 total)\n",
      "[49/128] Unproductive: 48 saved | Direct text...\n",
      "  ✓ Saved (49 total)\n",
      "[50/128] Unproductive: 49 saved | Direct text...\n",
      "  ✓ Saved (50 total)\n",
      "[51/128] Unproductive: 50 saved | Direct text...\n",
      "  ✓ Saved (51 total)\n",
      "[52/128] Unproductive: 51 saved | Direct text...\n",
      "  ✓ Saved (52 total)\n",
      "[53/128] Unproductive: 52 saved | Direct text...\n",
      "  ✓ Saved (53 total)\n",
      "[54/128] Unproductive: 53 saved | Direct text...\n",
      "  ✓ Saved (54 total)\n",
      "[55/128] Unproductive: 54 saved | Direct text...\n",
      "  ✓ Saved (55 total)\n",
      "[56/128] Unproductive: 55 saved | Direct text...\n",
      "  ✓ Saved (56 total)\n",
      "[57/128] Unproductive: 56 saved | Direct text...\n",
      "  ✓ Saved (57 total)\n",
      "[58/128] Unproductive: 57 saved | Direct text...\n",
      "  ✓ Saved (58 total)\n",
      "[59/128] Unproductive: 58 saved | Direct text...\n",
      "  ✓ Saved (59 total)\n",
      "[60/128] Unproductive: 59 saved | Direct text...\n",
      "  ✓ Saved (60 total)\n",
      "[61/128] Unproductive: 60 saved | Direct text...\n",
      "  ✓ Saved (61 total)\n",
      "[62/128] Unproductive: 61 saved | Direct text...\n",
      "  ✓ Saved (62 total)\n",
      "[63/128] Unproductive: 62 saved | Direct text...\n",
      "  ✓ Saved (63 total)\n",
      "[64/128] Unproductive: 63 saved | Direct text...\n",
      "  ✓ Saved (64 total)\n",
      "[65/128] Unproductive: 64 saved | Direct text...\n",
      "  ✓ Saved (65 total)\n",
      "[66/128] Unproductive: 65 saved | Direct text...\n",
      "  ✓ Saved (66 total)\n",
      "[67/128] Unproductive: 66 saved | Direct text...\n",
      "  ✓ Saved (67 total)\n",
      "[68/128] Unproductive: 67 saved | Direct text...\n",
      "  ✓ Saved (68 total)\n",
      "[69/128] Unproductive: 68 saved | Direct text...\n",
      "  ✓ Saved (69 total)\n",
      "[70/128] Unproductive: 69 saved | Direct text...\n",
      "  ✓ Saved (70 total)\n",
      "[71/128] Unproductive: 70 saved | Direct text...\n",
      "  ✓ Saved (71 total)\n",
      "[72/128] Unproductive: 71 saved | Direct text...\n",
      "  ✓ Saved (72 total)\n",
      "[73/128] Unproductive: 72 saved | Direct text...\n",
      "  ✓ Saved (73 total)\n",
      "[74/128] Unproductive: 73 saved | Direct text...\n",
      "  ✓ Saved (74 total)\n",
      "[75/128] Unproductive: 74 saved | Direct text...\n",
      "  ✓ Saved (75 total)\n",
      "[76/128] Unproductive: 75 saved | Direct text...\n",
      "  ✓ Saved (76 total)\n",
      "[77/128] Unproductive: 76 saved | Direct text...\n",
      "  ✓ Saved (77 total)\n",
      "[78/128] Unproductive: 77 saved | Direct text...\n",
      "  ✓ Saved (78 total)\n",
      "[79/128] Unproductive: 78 saved | Direct text...\n",
      "  ✓ Saved (79 total)\n",
      "[80/128] Unproductive: 79 saved | Direct text...\n",
      "  ✓ Saved (80 total)\n",
      "[81/128] Unproductive: 80 saved | Direct text...\n",
      "  ✓ Saved (81 total)\n",
      "[82/128] Unproductive: 81 saved | Direct text...\n",
      "  ✓ Saved (82 total)\n",
      "[83/128] Unproductive: 82 saved | Direct text...\n",
      "  ✓ Saved (83 total)\n",
      "[84/128] Unproductive: 83 saved | Direct text...\n",
      "  ✓ Saved (84 total)\n",
      "[85/128] Unproductive: 84 saved | Direct text...\n",
      "  ✓ Saved (85 total)\n",
      "[86/128] Unproductive: 85 saved | Direct text...\n",
      "  ✓ Saved (86 total)\n",
      "[87/128] Unproductive: 86 saved | Direct text...\n",
      "  ✓ Saved (87 total)\n",
      "[88/128] Unproductive: 87 saved | Direct text...\n",
      "  ✓ Saved (88 total)\n",
      "[89/128] Unproductive: 88 saved | Direct text...\n",
      "  ✓ Saved (89 total)\n",
      "[90/128] Unproductive: 89 saved | Direct text...\n",
      "  ✓ Saved (90 total)\n",
      "[91/128] Unproductive: 90 saved | Direct text...\n",
      "  ✓ Saved (91 total)\n",
      "[92/128] Unproductive: 91 saved | Direct text...\n",
      "  ✓ Saved (92 total)\n",
      "[93/128] Unproductive: 92 saved | Direct text...\n",
      "  ✓ Saved (93 total)\n",
      "[94/128] Unproductive: 93 saved | Direct text...\n",
      "  ✓ Saved (94 total)\n",
      "[95/128] Unproductive: 94 saved | Direct text...\n",
      "  ✓ Saved (95 total)\n",
      "[96/128] Unproductive: 95 saved | Direct text...\n",
      "  ✓ Saved (96 total)\n",
      "[97/128] Unproductive: 96 saved | Direct text...\n",
      "  ✓ Saved (97 total)\n",
      "[98/128] Unproductive: 97 saved | Direct text...\n",
      "  ✓ Saved (98 total)\n",
      "[99/128] Unproductive: 98 saved | Direct text...\n",
      "  ✓ Saved (99 total)\n",
      "[100/128] Unproductive: 99 saved | Direct text...\n",
      "  ✓ Saved (100 total)\n",
      "[101/128] Unproductive: 100 saved | Direct text...\n",
      "  ✓ Saved (101 total)\n",
      "[102/128] Unproductive: 101 saved | Direct text...\n",
      "  ✓ Saved (102 total)\n",
      "[103/128] Unproductive: 102 saved | Direct text...\n",
      "  ✓ Saved (103 total)\n",
      "[104/128] Unproductive: 103 saved | Direct text...\n",
      "  ✓ Saved (104 total)\n",
      "[105/128] Unproductive: 104 saved | Direct text...\n",
      "  ✓ Saved (105 total)\n",
      "[106/128] Unproductive: 105 saved | Direct text...\n",
      "  ✓ Saved (106 total)\n",
      "[107/128] Unproductive: 106 saved | Direct text...\n",
      "  ✓ Saved (107 total)\n",
      "[108/128] Unproductive: 107 saved | Direct text...\n",
      "  ✓ Saved (108 total)\n",
      "[109/128] Unproductive: 108 saved | Direct text...\n",
      "  ✓ Saved (109 total)\n",
      "[110/128] Unproductive: 109 saved | Direct text...\n",
      "  ✓ Saved (110 total)\n",
      "[111/128] Unproductive: 110 saved | Direct text...\n",
      "  ✓ Saved (111 total)\n",
      "[112/128] Unproductive: 111 saved | Direct text...\n",
      "  ✓ Saved (112 total)\n",
      "[113/128] Unproductive: 112 saved | Direct text...\n",
      "  ✓ Saved (113 total)\n",
      "[114/128] Unproductive: 113 saved | Direct text...\n",
      "  ✓ Saved (114 total)\n",
      "[115/128] Unproductive: 114 saved | Direct text...\n",
      "  ✓ Saved (115 total)\n",
      "[116/128] Unproductive: 115 saved | Direct text...\n",
      "  ✓ Saved (116 total)\n",
      "[117/128] Unproductive: 116 saved | Direct text...\n",
      "  ✓ Saved (117 total)\n",
      "[118/128] Unproductive: 117 saved | Direct text...\n",
      "  ✓ Saved (118 total)\n",
      "[119/128] Unproductive: 118 saved | Direct text...\n",
      "  ✓ Saved (119 total)\n",
      "[120/128] Unproductive: 119 saved | Direct text...\n",
      "  ✓ Saved (120 total)\n",
      "[121/128] Unproductive: 120 saved | Direct text...\n",
      "  ✓ Saved (121 total)\n",
      "[122/128] Unproductive: 121 saved | Direct text...\n",
      "  ✓ Saved (122 total)\n",
      "[123/128] Unproductive: 122 saved | Direct text...\n",
      "  ✓ Saved (123 total)\n",
      "[124/128] Unproductive: 123 saved | Direct text...\n",
      "  ✓ Saved (124 total)\n",
      "[125/128] Unproductive: 124 saved | Direct text...\n",
      "  ✓ Saved (125 total)\n",
      "[126/128] Unproductive: 125 saved | Direct text...\n",
      "  ✓ Saved (126 total)\n",
      "[127/128] Unproductive: 126 saved | Direct text...\n",
      "  ✓ Saved (127 total)\n",
      "[128/128] Unproductive: 127 saved | Direct text...\n",
      "  ✓ Saved (128 total)\n",
      "\n",
      "======================================================================\n",
      "UNPRODUCTIVE Summary:\n",
      "  Saved: 128\n",
      "  Filtered: 0\n",
      "  Failed: 0\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "Productive: 797 samples\n",
      "Unproductive: 128 samples\n",
      "======================================================================\n",
      "TOTAL SAMPLES: 925\n",
      "======================================================================\n",
      "\n",
      "✓ Dataset ready at: dataset/\n",
      "  - Minimum 2000+ samples per class for training\n",
      "  - Ready for DistilBERT fine-tuning\n",
      "  - No overfitting on toy dataset\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "class MassDatasetScraper:\n",
    "    def __init__(self, base_dir=\"dataset\", min_words=50, delay=(1, 3), max_retries=3):\n",
    "        \"\"\"\n",
    "        Initialize the mass dataset scraper.\n",
    "        \n",
    "        Args:\n",
    "            base_dir: Base directory for the dataset\n",
    "            min_words: Minimum word count to keep content\n",
    "            delay: Tuple (min, max) seconds to wait between requests\n",
    "            max_retries: Maximum retry attempts for failed requests\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.min_words = min_words\n",
    "        self.delay = delay\n",
    "        self.max_retries = max_retries\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # Create directory structure\n",
    "        self.productive_dir = Path(base_dir) / \"productive\"\n",
    "        self.unproductive_dir = Path(base_dir) / \"unproductive\"\n",
    "        self.productive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.unproductive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Stats\n",
    "        self.stats = {\n",
    "            'productive': {'saved': 0, 'filtered': 0, 'failed': 0},\n",
    "            'unproductive': {'saved': 0, 'filtered': 0, 'failed': 0}\n",
    "        }\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text content.\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\\\"]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_text(self, html, url):\n",
    "        \"\"\"Extract clean text from HTML.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Remove unwanted elements\n",
    "        for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe', 'form']):\n",
    "            tag.decompose()\n",
    "        \n",
    "        text = \"\"\n",
    "        content_selectors = ['article', 'main', '.content', '#content', '.post-content', '.entry-content']\n",
    "        \n",
    "        for selector in content_selectors:\n",
    "            elements = soup.select(selector) if selector.startswith(('.', '#')) else soup.find_all(selector)\n",
    "            if elements:\n",
    "                text = ' '.join([elem.get_text(separator=' ', strip=True) for elem in elements])\n",
    "                break\n",
    "        \n",
    "        if not text:\n",
    "            body = soup.find('body')\n",
    "            text = body.get_text(separator=' ', strip=True) if body else \"\"\n",
    "        \n",
    "        return self.clean_text(text)\n",
    "    \n",
    "    def count_words(self, text):\n",
    "        \"\"\"Count words in text.\"\"\"\n",
    "        return len(text.split())\n",
    "    \n",
    "    def fetch_url(self, url, retries=0):\n",
    "        \"\"\"Fetch content from URL with retry logic.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except requests.RequestException as e:\n",
    "            if retries < self.max_retries:\n",
    "                wait = random.uniform(2, 5)\n",
    "                print(f\"  Retry {retries + 1}/{self.max_retries} after {wait:.1f}s...\")\n",
    "                time.sleep(wait)\n",
    "                return self.fetch_url(url, retries + 1)\n",
    "            print(f\"  Failed after {self.max_retries} retries: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_next_filename(self, directory):\n",
    "        \"\"\"Get the next sequential filename.\"\"\"\n",
    "        existing_files = list(directory.glob(\"*.txt\"))\n",
    "        if not existing_files:\n",
    "            return \"00001.txt\"\n",
    "        \n",
    "        numbers = [int(re.match(r'(\\d+)\\.txt', f.name).group(1)) \n",
    "                   for f in existing_files if re.match(r'(\\d+)\\.txt', f.name)]\n",
    "        next_num = max(numbers) + 1 if numbers else 1\n",
    "        return f\"{next_num:05d}.txt\"\n",
    "    \n",
    "    def save_text(self, text, directory, category):\n",
    "        \"\"\"Save text to file.\"\"\"\n",
    "        filename = self.get_next_filename(directory)\n",
    "        filepath = directory / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        self.stats[category]['saved'] += 1\n",
    "        return filepath\n",
    "    \n",
    "    def process_url(self, url, category):\n",
    "        \"\"\"Process a single URL and save if valid.\"\"\"\n",
    "        directory = self.productive_dir if category == 'productive' else self.unproductive_dir\n",
    "        \n",
    "        html = self.fetch_url(url)\n",
    "        if html is None:\n",
    "            self.stats[category]['failed'] += 1\n",
    "            return False\n",
    "        \n",
    "        text = self.extract_text(html, url)\n",
    "        word_count = self.count_words(text)\n",
    "        \n",
    "        if word_count < self.min_words:\n",
    "            self.stats[category]['filtered'] += 1\n",
    "            return False\n",
    "        \n",
    "        self.save_text(text, directory, category)\n",
    "        return True\n",
    "    \n",
    "    def scrape_wikipedia_category(self, category_name, max_pages=500):\n",
    "        \"\"\"Scrape Wikipedia pages from a category.\"\"\"\n",
    "        print(f\"\\n[Wikipedia] Scraping category: {category_name}\")\n",
    "        base_url = \"https://en.wikipedia.org/wiki/Category:\"\n",
    "        api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "        \n",
    "        urls = []\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'list': 'categorymembers',\n",
    "            'cmtitle': f'Category:{category_name}',\n",
    "            'cmlimit': 500,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        while len(urls) < max_pages:\n",
    "            response = self.fetch_url(api_url + '?' + '&'.join([f'{k}={v}' for k, v in params.items()]))\n",
    "            if not response:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "                members = data.get('query', {}).get('categorymembers', [])\n",
    "                \n",
    "                for member in members:\n",
    "                    if member.get('ns') == 0:  # Main namespace only\n",
    "                        title = member['title'].replace(' ', '_')\n",
    "                        urls.append(f\"https://en.wikipedia.org/wiki/{title}\")\n",
    "                \n",
    "                if 'continue' not in data or len(urls) >= max_pages:\n",
    "                    break\n",
    "                \n",
    "                params['cmcontinue'] = data['continue']['cmcontinue']\n",
    "                time.sleep(random.uniform(*self.delay))\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        return urls[:max_pages]\n",
    "    \n",
    "    def scrape_reddit_subreddit(self, subreddit, sort='top', time_filter='all', limit=500):\n",
    "        \"\"\"Scrape Reddit posts from a subreddit using JSON API.\"\"\"\n",
    "        print(f\"\\n[Reddit] Scraping r/{subreddit} ({sort}/{time_filter})\")\n",
    "        urls = []\n",
    "        after = None\n",
    "        \n",
    "        while len(urls) < limit:\n",
    "            url = f\"https://old.reddit.com/r/{subreddit}/{sort}.json?t={time_filter}&limit=100\"\n",
    "            if after:\n",
    "                url += f\"&after={after}\"\n",
    "            \n",
    "            response = self.fetch_url(url)\n",
    "            if not response:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "                posts = data['data']['children']\n",
    "                \n",
    "                for post in posts:\n",
    "                    post_data = post['data']\n",
    "                    # Get both title and selftext\n",
    "                    title = post_data.get('title', '')\n",
    "                    selftext = post_data.get('selftext', '')\n",
    "                    combined = f\"{title}. {selftext}\".strip()\n",
    "                    \n",
    "                    if self.count_words(combined) >= self.min_words:\n",
    "                        urls.append(combined)  # Store text directly\n",
    "                \n",
    "                after = data['data']['after']\n",
    "                if not after or len(urls) >= limit:\n",
    "                    break\n",
    "                \n",
    "                time.sleep(random.uniform(*self.delay))\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        return urls[:limit]\n",
    "    \n",
    "    def scrape_mass_urls(self, urls, category, target=None):\n",
    "        \"\"\"\n",
    "        Scrape a large list of URLs with progress tracking.\n",
    "        \n",
    "        Args:\n",
    "            urls: List of URLs or text content\n",
    "            category: 'productive' or 'unproductive'\n",
    "            target: Stop when this many samples saved (None = scrape all)\n",
    "        \"\"\"\n",
    "        directory = self.productive_dir if category == 'productive' else self.unproductive_dir\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Scraping {len(urls)} items for: {category.upper()}\")\n",
    "        if target:\n",
    "            print(f\"Target: {target} samples\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, item in enumerate(urls, 1):\n",
    "            if target and self.stats[category]['saved'] >= target:\n",
    "                print(f\"\\n✓ Target reached: {self.stats[category]['saved']} samples\")\n",
    "                break\n",
    "            \n",
    "            current = self.stats[category]['saved']\n",
    "            print(f\"[{i}/{len(urls)}] {category.capitalize()}: {current} saved | \", end=\"\")\n",
    "            \n",
    "            # Check if item is URL or direct text\n",
    "            if isinstance(item, str) and (item.startswith('http://') or item.startswith('https://')):\n",
    "                print(f\"{item[:60]}...\")\n",
    "                success = self.process_url(item, category)\n",
    "            else:\n",
    "                # Direct text (e.g., from Reddit)\n",
    "                print(\"Direct text...\")\n",
    "                word_count = self.count_words(item)\n",
    "                if word_count >= self.min_words:\n",
    "                    self.save_text(item, directory, category)\n",
    "                    success = True\n",
    "                else:\n",
    "                    self.stats[category]['filtered'] += 1\n",
    "                    success = False\n",
    "            \n",
    "            if success:\n",
    "                print(f\"  ✓ Saved ({self.stats[category]['saved']} total)\")\n",
    "            \n",
    "            time.sleep(random.uniform(*self.delay))\n",
    "        \n",
    "        self.print_summary(category)\n",
    "    \n",
    "    def print_summary(self, category=None):\n",
    "        \"\"\"Print statistics summary.\"\"\"\n",
    "        if category:\n",
    "            stats = self.stats[category]\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"{category.upper()} Summary:\")\n",
    "            print(f\"  Saved: {stats['saved']}\")\n",
    "            print(f\"  Filtered: {stats['filtered']}\")\n",
    "            print(f\"  Failed: {stats['failed']}\")\n",
    "            print(f\"{'='*70}\")\n",
    "        else:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(\"FINAL DATASET SUMMARY\")\n",
    "            print(f\"{'='*70}\")\n",
    "            for cat in ['productive', 'unproductive']:\n",
    "                stats = self.stats[cat]\n",
    "                print(f\"{cat.capitalize()}: {stats['saved']} samples\")\n",
    "            total = sum(s['saved'] for s in self.stats.values())\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"TOTAL SAMPLES: {total}\")\n",
    "            print(f\"{'='*70}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION - CONFIGURE YOUR DATASET HERE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = MassDatasetScraper(\n",
    "        base_dir=\"dataset\",\n",
    "        min_words=50,\n",
    "        delay=(1, 2),  # Random delay between 1-2 seconds\n",
    "        max_retries=3\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PRODUCTIVE CONTENT - Target: 3000+ samples\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 1: COLLECTING PRODUCTIVE CONTENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    productive_sources = []\n",
    "    \n",
    "    # Wikipedia categories (computer science, technology, education)\n",
    "    wiki_categories = [\n",
    "        'Computer_science',\n",
    "        'Algorithms',\n",
    "        'Data_structures',\n",
    "        'Programming_languages',\n",
    "        'Machine_learning',\n",
    "        'Software_engineering',\n",
    "        'Computer_programming',\n",
    "        'Mathematics',\n",
    "        'Physics',\n",
    "        'Biology'\n",
    "    ]\n",
    "    \n",
    "    for cat in wiki_categories:\n",
    "        urls = scraper.scrape_wikipedia_category(cat, max_pages=200)\n",
    "        productive_sources.extend(urls)\n",
    "        print(f\"  Collected {len(urls)} pages from {cat}\")\n",
    "    \n",
    "    # Add more direct URLs if needed\n",
    "    productive_sources.extend([\n",
    "        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
    "        \"https://en.wikipedia.org/wiki/Deep_learning\",\n",
    "        \"https://en.wikipedia.org/wiki/Neural_network\",\n",
    "        # Add documentation URLs, arXiv abstracts, tech blog URLs here\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nTotal productive URLs collected: {len(productive_sources)}\")\n",
    "    scraper.scrape_mass_urls(productive_sources, 'productive', target=3000)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # UNPRODUCTIVE CONTENT - Target: 3000+ samples\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 2: COLLECTING UNPRODUCTIVE CONTENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    unproductive_sources = []\n",
    "    \n",
    "    # Reddit subreddits (entertainment, memes, gaming)\n",
    "    subreddits = [\n",
    "        ('funny', 'top', 'all'),\n",
    "        ('memes', 'top', 'all'),\n",
    "        ('gaming', 'top', 'all'),\n",
    "        ('movies', 'top', 'all'),\n",
    "        ('television', 'top', 'all'),\n",
    "        ('entertainment', 'top', 'all'),\n",
    "        ('Jokes', 'top', 'all'),\n",
    "        ('AdviceAnimals', 'top', 'all'),\n",
    "        ('facepalm', 'top', 'all'),\n",
    "        ('aww', 'top', 'all')\n",
    "    ]\n",
    "    \n",
    "    for subreddit, sort, time_filter in subreddits:\n",
    "        texts = scraper.scrape_reddit_subreddit(subreddit, sort, time_filter, limit=300)\n",
    "        unproductive_sources.extend(texts)\n",
    "        print(f\"  Collected {len(texts)} posts from r/{subreddit}\")\n",
    "    \n",
    "    print(f\"\\nTotal unproductive items collected: {len(unproductive_sources)}\")\n",
    "    scraper.scrape_mass_urls(unproductive_sources, 'unproductive', target=3000)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    scraper.print_summary()\n",
    "    \n",
    "    print(f\"\\n✓ Dataset ready at: {scraper.base_dir}/\")\n",
    "    print(\"  - Minimum 2000+ samples per class for training\")\n",
    "    print(\"  - Ready for DistilBERT fine-tuning\")\n",
    "    print(\"  - No overfitting on toy dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be77fed5-84a0-4f31-87cc-decb4f353fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UNPRODUCTIVE CONTENT SCRAPER\n",
      "Target: 3000+ samples\n",
      "Current unproductive samples: Check your dataset/unproductive/ folder\n",
      "======================================================================\n",
      "\n",
      "Current samples: 132\n",
      "Target samples: 3000\n",
      "Need to collect: 2868\n",
      "\n",
      "Scraping 55 subreddits...\n",
      "\n",
      "[Reddit] Scraping r/funny (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/memes (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/dankmemes (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/me_irl (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/meirl (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/AdviceAnimals (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/wholesomememes (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/movies (top/all)\n",
      "  Collected 15 posts\n",
      "\n",
      "[Reddit] Scraping r/television (top/all)\n",
      "  Collected 15 posts\n",
      "\n",
      "[Reddit] Scraping r/entertainment (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/Music (top/all)\n",
      "  Collected 25 posts\n",
      "\n",
      "[Reddit] Scraping r/Netflix (top/all)\n",
      "  Collected 58 posts\n",
      "\n",
      "[Reddit] Scraping r/gaming (top/all)\n",
      "  Collected 6 posts\n",
      "\n",
      "[Reddit] Scraping r/Games (top/all)\n",
      "  Collected 27 posts\n",
      "\n",
      "[Reddit] Scraping r/pcgaming (top/all)\n",
      "  Collected 55 posts\n",
      "\n",
      "[Reddit] Scraping r/PS4 (top/all)\n",
      "  Collected 19 posts\n",
      "\n",
      "[Reddit] Scraping r/xboxone (top/all)\n",
      "  Collected 10 posts\n",
      "\n",
      "[Reddit] Scraping r/sports (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/nfl (top/all)\n",
      "  Collected 26 posts\n",
      "\n",
      "[Reddit] Scraping r/nba (top/all)\n",
      "  Collected 52 posts\n",
      "\n",
      "[Reddit] Scraping r/soccer (top/all)\n",
      "  Collected 17 posts\n",
      "\n",
      "[Reddit] Scraping r/baseball (top/all)\n",
      "  Collected 13 posts\n",
      "\n",
      "[Reddit] Scraping r/AskReddit (top/month)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/CasualConversation (top/all)\n",
      "  Collected 235 posts\n",
      "\n",
      "Saving 577 items...\n",
      "  Progress: 50 saved\n",
      "  Progress: 100 saved\n",
      "  Progress: 150 saved\n",
      "  Progress: 200 saved\n",
      "  Progress: 250 saved\n",
      "  Progress: 300 saved\n",
      "  Progress: 350 saved\n",
      "  Progress: 400 saved\n",
      "  Progress: 450 saved\n",
      "  Progress: 500 saved\n",
      "  Progress: 550 saved\n",
      "\n",
      "✓ Saved: 577 | Filtered: 0\n",
      "\n",
      "[Reddit] Scraping r/tifu (top/all)\n",
      "  Collected 249 posts\n",
      "\n",
      "[Reddit] Scraping r/Showerthoughts (top/all)\n",
      "  Collected 15 posts\n",
      "\n",
      "[Reddit] Scraping r/LifeProTips (top/all)\n",
      "  Collected 138 posts\n",
      "\n",
      "[Reddit] Scraping r/pics (top/all)\n",
      "  Collected 2 posts\n",
      "\n",
      "[Reddit] Scraping r/gifs (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/videos (top/all)\n",
      "  Collected 8 posts\n",
      "\n",
      "[Reddit] Scraping r/aww (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/Unexpected (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/oddlysatisfying (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/facepalm (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/cringe (top/all)\n",
      "  Collected 26 posts\n",
      "\n",
      "[Reddit] Scraping r/PublicFreakout (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/instant_regret (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/Whatcouldgowrong (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/WatchPeopleDieInside (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/WhitePeopleTwitter (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/BlackPeopleTwitter (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/twitter (top/all)\n",
      "  Collected 45 posts\n",
      "\n",
      "[Reddit] Scraping r/todayilearned (top/all)\n",
      "  Collected 77 posts\n",
      "\n",
      "Saving 561 items...\n",
      "  Progress: 627 saved\n",
      "  Progress: 677 saved\n",
      "  Progress: 727 saved\n",
      "  Progress: 777 saved\n",
      "  Progress: 827 saved\n",
      "  Progress: 877 saved\n",
      "  Progress: 927 saved\n",
      "  Progress: 977 saved\n",
      "  Progress: 1027 saved\n",
      "  Progress: 1077 saved\n",
      "  Progress: 1127 saved\n",
      "\n",
      "✓ Saved: 1138 | Filtered: 0\n",
      "\n",
      "[Reddit] Scraping r/mildlyinteresting (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/interestingasfuck (top/all)\n",
      "  Collected 3 posts\n",
      "\n",
      "[Reddit] Scraping r/Damnthatsinteresting (top/all)\n",
      "  Collected 8 posts\n",
      "\n",
      "[Reddit] Scraping r/KidsAreFuckingStupid (top/all)\n",
      "  Collected 1 posts\n",
      "\n",
      "[Reddit] Scraping r/AnimalsBeingDerps (top/all)\n",
      "  Collected 0 posts\n",
      "\n",
      "[Reddit] Scraping r/therewasanattempt (top/all)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 259\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Target reached!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_reddit_subreddit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubreddit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m all_texts\u001b[38;5;241m.\u001b[39mextend(texts)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# Save in batches\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 82\u001b[0m, in \u001b[0;36mUnproductiveScraper.scrape_reddit_subreddit\u001b[1;34m(self, subreddit, sort, time_filter, limit)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after:\n\u001b[0;32m     80\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&after=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mafter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m, in \u001b[0;36mUnproductiveScraper.fetch_url\u001b[1;34m(self, url, retries)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch URL with retry logic.\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\site-packages\\urllib3\\connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch_env\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "class UnproductiveScraper:\n",
    "    def __init__(self, base_dir=\"dataset\", min_words=50, delay=(1, 2), max_retries=3):\n",
    "        \"\"\"Scraper focused on unproductive content only.\"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.min_words = min_words\n",
    "        self.delay = delay\n",
    "        self.max_retries = max_retries\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        self.unproductive_dir = Path(base_dir) / \"unproductive\"\n",
    "        self.unproductive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.stats = {'saved': 0, 'filtered': 0, 'failed': 0}\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\\\"]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def count_words(self, text):\n",
    "        \"\"\"Count words in text.\"\"\"\n",
    "        return len(text.split())\n",
    "    \n",
    "    def fetch_url(self, url, retries=0):\n",
    "        \"\"\"Fetch URL with retry logic.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except requests.RequestException as e:\n",
    "            if retries < self.max_retries:\n",
    "                wait = random.uniform(2, 5)\n",
    "                time.sleep(wait)\n",
    "                return self.fetch_url(url, retries + 1)\n",
    "            return None\n",
    "    \n",
    "    def get_next_filename(self):\n",
    "        \"\"\"Get next sequential filename.\"\"\"\n",
    "        existing_files = list(self.unproductive_dir.glob(\"*.txt\"))\n",
    "        if not existing_files:\n",
    "            return \"00001.txt\"\n",
    "        \n",
    "        numbers = [int(re.match(r'(\\d+)\\.txt', f.name).group(1)) \n",
    "                   for f in existing_files if re.match(r'(\\d+)\\.txt', f.name)]\n",
    "        next_num = max(numbers) + 1 if numbers else 1\n",
    "        return f\"{next_num:05d}.txt\"\n",
    "    \n",
    "    def save_text(self, text):\n",
    "        \"\"\"Save text to file.\"\"\"\n",
    "        filename = self.get_next_filename()\n",
    "        filepath = self.unproductive_dir / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        self.stats['saved'] += 1\n",
    "        return filepath\n",
    "    \n",
    "    def scrape_reddit_subreddit(self, subreddit, sort='top', time_filter='all', limit=500):\n",
    "        \"\"\"Scrape Reddit posts using JSON API.\"\"\"\n",
    "        print(f\"\\n[Reddit] Scraping r/{subreddit} ({sort}/{time_filter})\")\n",
    "        texts = []\n",
    "        after = None\n",
    "        \n",
    "        while len(texts) < limit:\n",
    "            url = f\"https://old.reddit.com/r/{subreddit}/{sort}.json?t={time_filter}&limit=100\"\n",
    "            if after:\n",
    "                url += f\"&after={after}\"\n",
    "            \n",
    "            response = self.fetch_url(url)\n",
    "            if not response:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "                posts = data['data']['children']\n",
    "                \n",
    "                for post in posts:\n",
    "                    post_data = post['data']\n",
    "                    title = post_data.get('title', '')\n",
    "                    selftext = post_data.get('selftext', '')\n",
    "                    combined = f\"{title}. {selftext}\".strip()\n",
    "                    \n",
    "                    if self.count_words(combined) >= self.min_words:\n",
    "                        texts.append(combined)\n",
    "                \n",
    "                after = data['data']['after']\n",
    "                if not after or len(texts) >= limit:\n",
    "                    break\n",
    "                \n",
    "                time.sleep(random.uniform(*self.delay))\n",
    "            except Exception as e:\n",
    "                print(f\"  Error: {e}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"  Collected {len(texts)} posts\")\n",
    "        return texts\n",
    "    \n",
    "    def scrape_and_save(self, texts, target=None):\n",
    "        \"\"\"Save texts to files.\"\"\"\n",
    "        print(f\"\\nSaving {len(texts)} items...\")\n",
    "        \n",
    "        for i, text in enumerate(texts, 1):\n",
    "            if target and self.stats['saved'] >= target:\n",
    "                print(f\"\\n✓ Target reached: {self.stats['saved']} samples\")\n",
    "                break\n",
    "            \n",
    "            word_count = self.count_words(text)\n",
    "            \n",
    "            if word_count >= self.min_words:\n",
    "                self.save_text(text)\n",
    "                if i % 50 == 0:\n",
    "                    print(f\"  Progress: {self.stats['saved']} saved\")\n",
    "            else:\n",
    "                self.stats['filtered'] += 1\n",
    "            \n",
    "            time.sleep(random.uniform(0.1, 0.3))  # Fast saving\n",
    "        \n",
    "        print(f\"\\n✓ Saved: {self.stats['saved']} | Filtered: {self.stats['filtered']}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNPRODUCTIVE CONTENT COLLECTION - FOCUSED ON BALANCING\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = UnproductiveScraper(\n",
    "        base_dir=\"dataset\",\n",
    "        min_words=50,\n",
    "        delay=(1, 2),\n",
    "        max_retries=3\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"UNPRODUCTIVE CONTENT SCRAPER\")\n",
    "    print(f\"Target: 3000+ samples\")\n",
    "    print(f\"Current unproductive samples: Check your dataset/unproductive/ folder\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate how many we need\n",
    "    current_count = len(list(scraper.unproductive_dir.glob(\"*.txt\")))\n",
    "    target = 3000\n",
    "    needed = target - current_count\n",
    "    \n",
    "    print(f\"\\nCurrent samples: {current_count}\")\n",
    "    print(f\"Target samples: {target}\")\n",
    "    print(f\"Need to collect: {max(0, needed)}\")\n",
    "    \n",
    "    if needed <= 0:\n",
    "        print(\"\\n✓ Already balanced! No need to scrape.\")\n",
    "        exit()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MASSIVE SUBREDDIT LIST - Entertainment, Memes, Gaming, Casual\n",
    "    # ========================================================================\n",
    "    \n",
    "    all_texts = []\n",
    "    \n",
    "    subreddits = [\n",
    "        # Humor & Memes\n",
    "        ('funny', 'top', 'all', 500),\n",
    "        ('memes', 'top', 'all', 500),\n",
    "        ('dankmemes', 'top', 'all', 500),\n",
    "        ('me_irl', 'top', 'all', 400),\n",
    "        ('meirl', 'top', 'all', 400),\n",
    "        ('AdviceAnimals', 'top', 'all', 300),\n",
    "        ('wholesomememes', 'top', 'all', 300),\n",
    "        \n",
    "        # Entertainment\n",
    "        ('movies', 'top', 'all', 400),\n",
    "        ('television', 'top', 'all', 400),\n",
    "        ('entertainment', 'top', 'all', 300),\n",
    "        ('Music', 'top', 'all', 300),\n",
    "        ('Netflix', 'top', 'all', 300),\n",
    "        \n",
    "        # Gaming\n",
    "        ('gaming', 'top', 'all', 500),\n",
    "        ('Games', 'top', 'all', 400),\n",
    "        ('pcgaming', 'top', 'all', 300),\n",
    "        ('PS4', 'top', 'all', 300),\n",
    "        ('xboxone', 'top', 'all', 300),\n",
    "        \n",
    "        # Sports\n",
    "        ('sports', 'top', 'all', 400),\n",
    "        ('nfl', 'top', 'all', 300),\n",
    "        ('nba', 'top', 'all', 300),\n",
    "        ('soccer', 'top', 'all', 300),\n",
    "        ('baseball', 'top', 'all', 200),\n",
    "        \n",
    "        # Social/Casual\n",
    "        ('AskReddit', 'top', 'month', 500),\n",
    "        ('CasualConversation', 'top', 'all', 300),\n",
    "        ('tifu', 'top', 'all', 400),\n",
    "        ('Showerthoughts', 'top', 'all', 400),\n",
    "        ('LifeProTips', 'top', 'all', 300),\n",
    "        \n",
    "        # Visual/Reaction\n",
    "        ('pics', 'top', 'all', 300),\n",
    "        ('gifs', 'top', 'all', 300),\n",
    "        ('videos', 'top', 'all', 300),\n",
    "        ('aww', 'top', 'all', 300),\n",
    "        ('Unexpected', 'top', 'all', 300),\n",
    "        ('oddlysatisfying', 'top', 'all', 300),\n",
    "        \n",
    "        # Cringe/Reaction\n",
    "        ('facepalm', 'top', 'all', 300),\n",
    "        ('cringe', 'top', 'all', 300),\n",
    "        ('PublicFreakout', 'top', 'all', 300),\n",
    "        ('instant_regret', 'top', 'all', 300),\n",
    "        ('Whatcouldgowrong', 'top', 'all', 300),\n",
    "        ('WatchPeopleDieInside', 'top', 'all', 300),\n",
    "        \n",
    "        # Twitter/Social Media\n",
    "        ('WhitePeopleTwitter', 'top', 'all', 400),\n",
    "        ('BlackPeopleTwitter', 'top', 'all', 400),\n",
    "        ('twitter', 'top', 'all', 300),\n",
    "        \n",
    "        # Interesting but unproductive\n",
    "        ('todayilearned', 'top', 'all', 400),\n",
    "        ('mildlyinteresting', 'top', 'all', 400),\n",
    "        ('interestingasfuck', 'top', 'all', 300),\n",
    "        ('Damnthatsinteresting', 'top', 'all', 300),\n",
    "        \n",
    "        # Random/Kids\n",
    "        ('KidsAreFuckingStupid', 'top', 'all', 300),\n",
    "        ('AnimalsBeingDerps', 'top', 'all', 300),\n",
    "        ('therewasanattempt', 'top', 'all', 300),\n",
    "        ('cursedcomments', 'top', 'all', 400),\n",
    "        \n",
    "        # Food/Lifestyle (casual)\n",
    "        ('food', 'top', 'all', 300),\n",
    "        ('FoodPorn', 'top', 'all', 300),\n",
    "        ('recipes', 'top', 'all', 200),\n",
    "        \n",
    "        # Gossip/Celebrity\n",
    "        ('entertainment', 'top', 'all', 300),\n",
    "        ('celebrity', 'top', 'all', 200),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nScraping {len(subreddits)} subreddits...\")\n",
    "    \n",
    "    for subreddit, sort, time_filter, limit in subreddits:\n",
    "        if scraper.stats['saved'] >= target:\n",
    "            print(f\"\\n✓ Target reached!\")\n",
    "            break\n",
    "        \n",
    "        texts = scraper.scrape_reddit_subreddit(subreddit, sort, time_filter, limit)\n",
    "        all_texts.extend(texts)\n",
    "        \n",
    "        # Save in batches\n",
    "        if len(all_texts) >= 500:\n",
    "            scraper.scrape_and_save(all_texts, target=target)\n",
    "            all_texts = []\n",
    "    \n",
    "    # Save remaining\n",
    "    if all_texts and scraper.stats['saved'] < target:\n",
    "        scraper.scrape_and_save(all_texts, target=target)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    final_count = len(list(scraper.unproductive_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Unproductive samples: {final_count}\")\n",
    "    print(f\"Newly added: {scraper.stats['saved']}\")\n",
    "    print(f\"Filtered (too short): {scraper.stats['filtered']}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n✓ Dataset balanced at: {scraper.base_dir}/unproductive/\")\n",
    "    print(\"  Ready for DistilBERT fine-tuning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d38dfd-1ed3-4466-a0d1-66feb1cac09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PRODUCTIVE CONTENT SCRAPER\n",
      "Target: 400 additional samples\n",
      "======================================================================\n",
      "\n",
      "Current samples: 803\n",
      "Target samples: 1203\n",
      "Need to collect: 400\n",
      "\n",
      "Collecting URLs from 14 Wikipedia categories...\n",
      "\n",
      "[Wikipedia] Scraping category: Artificial_intelligence\n",
      "  Collected 205 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Data_science\n",
      "  Collected 24 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Computer_networks\n",
      "  Collected 72 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Databases\n",
      "  Collected 135 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Cryptography\n",
      "  Collected 224 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Operating_systems\n",
      "  Collected 31 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Web_development\n",
      "  Collected 95 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Cybersecurity\n",
      "  Collected 0 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Computational_linguistics\n",
      "  Collected 215 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Theoretical_computer_science\n",
      "  Collected 138 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Computer_architecture\n",
      "  Collected 91 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Distributed_computing\n",
      "  Collected 77 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Cloud_computing\n",
      "  Collected 159 pages\n",
      "\n",
      "[Wikipedia] Scraping category: Quantum_computing\n",
      "  Collected 109 pages\n",
      "\n",
      "Total URLs collected: 445\n",
      "\n",
      "Processing 445 URLs...\n",
      "[1/445] 0 saved | https://en.wikipedia.org/wiki/Artificial_intelligence...\n",
      "  ✓ Saved\n",
      "[2/445] 1 saved | https://en.wikipedia.org/wiki/Actor-critic_algorithm...\n",
      "  ✓ Saved\n",
      "[3/445] 2 saved | https://en.wikipedia.org/wiki/Admissible_heuristic...\n",
      "  ✓ Saved\n",
      "[4/445] 3 saved | https://en.wikipedia.org/wiki/Agentic_AI...\n",
      "  ✓ Saved\n",
      "[5/445] 4 saved | https://en.wikipedia.org/wiki/.ai...\n",
      "  ✓ Saved\n",
      "[6/445] 5 saved | https://en.wikipedia.org/wiki/AI_alignment...\n",
      "  ✓ Saved\n",
      "[7/445] 6 saved | https://en.wikipedia.org/wiki/AI_browser...\n",
      "  ✓ Saved\n",
      "[8/445] 7 saved | https://en.wikipedia.org/wiki/AI_literacy...\n",
      "  ✓ Saved\n",
      "[9/445] 8 saved | https://en.wikipedia.org/wiki/AI_Mode...\n",
      "  ✓ Saved\n",
      "[10/445] 9 saved | https://en.wikipedia.org/wiki/AI_nationalism...\n",
      "  ✓ Saved\n",
      "[11/445] 10 saved | https://en.wikipedia.org/wiki/AI_Overviews...\n",
      "  ✓ Saved\n",
      "[12/445] 11 saved | https://en.wikipedia.org/wiki/AI_safety...\n",
      "  ✓ Saved\n",
      "[13/445] 12 saved | https://en.wikipedia.org/wiki/AI_veganism...\n",
      "  ✓ Saved\n",
      "[14/445] 13 saved | https://en.wikipedia.org/wiki/AI_washing...\n",
      "  ✓ Saved\n",
      "[15/445] 14 saved | https://en.wikipedia.org/wiki/AI-assisted_software_developme...\n",
      "  ✓ Saved\n",
      "[16/445] 15 saved | https://en.wikipedia.org/wiki/AI-complete...\n",
      "  ✓ Saved\n",
      "[17/445] 16 saved | https://en.wikipedia.org/wiki/AIOps...\n",
      "  ✓ Saved\n",
      "[18/445] 17 saved | https://en.wikipedia.org/wiki/Algorithmic_probability...\n",
      "  ✓ Saved\n",
      "[19/445] 18 saved | https://en.wikipedia.org/wiki/Ameca_(robot)...\n",
      "  ✓ Saved\n",
      "[20/445] 19 saved | https://en.wikipedia.org/wiki/And–or_tree...\n",
      "  ✓ Saved\n",
      "[21/445] 20 saved | https://en.wikipedia.org/wiki/Answer_engine_optimization...\n",
      "  ✓ Saved\n",
      "[22/445] 21 saved | https://en.wikipedia.org/wiki/Argumentation_framework...\n",
      "  ✓ Saved\n",
      "[23/445] 22 saved | https://en.wikipedia.org/wiki/Artificial_brain...\n",
      "  ✓ Saved\n",
      "[24/445] 23 saved | https://en.wikipedia.org/wiki/Artificial_consciousness...\n",
      "  ✓ Saved\n",
      "[25/445] 24 saved | https://en.wikipedia.org/wiki/Artificial_general_intelligenc...\n",
      "  ✓ Saved\n",
      "[26/445] 25 saved | https://en.wikipedia.org/wiki/Timeline_of_artificial_intelli...\n",
      "  ✓ Saved\n",
      "[27/445] 26 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_and_el...\n",
      "  ✓ Saved\n",
      "[28/445] 27 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_arms_r...\n",
      "  ✓ Saved\n",
      "[29/445] 28 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_contro...\n",
      "  ✓ Saved\n",
      "[30/445] 29 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_in_edu...\n",
      "  ✓ Saved\n",
      "[31/445] 30 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_in_spi...\n",
      "  ✓ Saved\n",
      "[32/445] 31 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_in_the...\n",
      "  ✓ Saved\n",
      "[33/445] 32 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_of_thi...\n",
      "  ✓ Saved\n",
      "[34/445] 33 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_optimi...\n",
      "  ✓ Saved\n",
      "[35/445] 34 saved | https://en.wikipedia.org/wiki/Artificial_intimacy...\n",
      "  ✓ Saved\n",
      "[36/445] 35 saved | https://en.wikipedia.org/wiki/Artificial_Inventor_Project...\n",
      "  ✓ Saved\n",
      "[37/445] 36 saved | https://en.wikipedia.org/wiki/Artificial_psychology...\n",
      "  ✓ Saved\n",
      "[38/445] 37 saved | https://en.wikipedia.org/wiki/Artificial_reproduction...\n",
      "  ✓ Saved\n",
      "[39/445] 38 saved | https://en.wikipedia.org/wiki/Artificial_wisdom...\n",
      "  ✓ Saved\n",
      "[40/445] 39 saved | https://en.wikipedia.org/wiki/ASR-complete...\n",
      "  ✓ Saved\n",
      "[41/445] 40 saved | https://en.wikipedia.org/wiki/Attributional_calculus...\n",
      "  ✓ Saved\n",
      "[42/445] 41 saved | https://en.wikipedia.org/wiki/Autognostics...\n",
      "  ✓ Saved\n",
      "[43/445] 42 saved | https://en.wikipedia.org/wiki/Automated_machine_learning...\n",
      "  ✓ Saved\n",
      "[44/445] 43 saved | https://en.wikipedia.org/wiki/Automated_Mathematician...\n",
      "  ✓ Saved\n",
      "[45/445] 44 saved | https://en.wikipedia.org/wiki/Automated_medical_scribe...\n",
      "  ✓ Saved\n",
      "[46/445] 45 saved | https://en.wikipedia.org/wiki/Automated_negotiation...\n",
      "  ✓ Saved\n",
      "[47/445] 46 saved | https://en.wikipedia.org/wiki/Autonomic_networking...\n",
      "  ✓ Saved\n",
      "[48/445] 47 saved | https://en.wikipedia.org/wiki/Autonomous_agent...\n",
      "  ✓ Saved\n",
      "[49/445] 48 saved | https://en.wikipedia.org/wiki/AZFinText...\n",
      "  ✓ Saved\n",
      "[50/445] 49 saved | https://en.wikipedia.org/wiki/Bayesian_programming...\n",
      "  ✓ Saved\n",
      "[51/445] 50 saved | https://en.wikipedia.org/wiki/Data_science...\n",
      "  ✓ Saved\n",
      "[52/445] 51 saved | https://en.wikipedia.org/wiki/Jeph_Acheampong...\n",
      "  ✓ Saved\n",
      "[53/445] 52 saved | https://en.wikipedia.org/wiki/Art_Recognition...\n",
      "  ✓ Saved\n",
      "[54/445] 53 saved | https://en.wikipedia.org/wiki/Artificial_intelligence...\n",
      "  ✓ Saved\n",
      "[55/445] 54 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_conten...\n",
      "  ✓ Saved\n",
      "[56/445] 55 saved | https://en.wikipedia.org/wiki/Biomedical_data_science...\n",
      "  ✓ Saved\n",
      "[57/445] 56 saved | https://en.wikipedia.org/wiki/Data-driven_astronomy...\n",
      "  ✓ Saved\n",
      "[58/445] 57 saved | https://en.wikipedia.org/wiki/Deep_Learning_Indaba...\n",
      "  ✓ Saved\n",
      "[59/445] 58 saved | https://en.wikipedia.org/wiki/How_Data_Happened...\n",
      "  ✓ Saved\n",
      "[60/445] 59 saved | https://en.wikipedia.org/wiki/List_of_data_science_journals...\n",
      "  ✓ Saved\n",
      "[61/445] 60 saved | https://en.wikipedia.org/wiki/List_of_data_science_software...\n",
      "  ✓ Saved\n",
      "[62/445] 61 saved | https://en.wikipedia.org/wiki/List_of_publications_in_data_s...\n",
      "  ✓ Saved\n",
      "[63/445] 62 saved | https://en.wikipedia.org/wiki/Machine_learning...\n",
      "  ✓ Saved\n",
      "[64/445] 63 saved | https://en.wikipedia.org/wiki/Model-based_clustering...\n",
      "  ✓ Saved\n",
      "[65/445] 64 saved | https://en.wikipedia.org/wiki/Netvibes...\n",
      "  ✓ Saved\n",
      "[66/445] 65 saved | https://en.wikipedia.org/wiki/Observational_Health_Data_Scie...\n",
      "  ✓ Saved\n",
      "[67/445] 66 saved | https://en.wikipedia.org/wiki/Persistence_barcode...\n",
      "  ✓ Saved\n",
      "[68/445] 67 saved | https://en.wikipedia.org/wiki/Data_physicalization...\n",
      "  ✓ Saved\n",
      "[69/445] 68 saved | https://en.wikipedia.org/wiki/Social_data_science...\n",
      "  ✓ Saved\n",
      "[70/445] 69 saved | https://en.wikipedia.org/wiki/Statistical_thinking...\n",
      "  ✓ Saved\n",
      "[71/445] 70 saved | https://en.wikipedia.org/wiki/TidyTuesday...\n",
      "  ✓ Saved\n",
      "[72/445] 71 saved | https://en.wikipedia.org/wiki/Toy_problem...\n",
      "  ✓ Saved\n",
      "[73/445] 72 saved | https://en.wikipedia.org/wiki/Toyota_Connected_North_America...\n",
      "  ✓ Saved\n",
      "[74/445] 73 saved | https://en.wikipedia.org/wiki/Data_universalism...\n",
      "  ✓ Saved\n",
      "[75/445] 74 saved | https://en.wikipedia.org/wiki/Computer_network...\n",
      "  ✓ Saved\n",
      "[76/445] 75 saved | https://en.wikipedia.org/wiki/Localhost...\n",
      "  ✓ Saved\n",
      "[77/445] 76 saved | https://en.wikipedia.org/wiki/ACTS_Gigabit_Satellite_Network...\n",
      "  ✓ Saved\n",
      "[78/445] 77 saved | https://en.wikipedia.org/wiki/Air_Force_Network...\n",
      "  ✓ Saved\n",
      "[79/445] 78 saved | https://en.wikipedia.org/wiki/Airborne_Networking...\n",
      "  ✓ Saved\n",
      "[80/445] 79 saved | https://en.wikipedia.org/wiki/Application_delivery_network...\n",
      "  ✓ Saved\n",
      "[81/445] 80 saved | https://en.wikipedia.org/wiki/AS1_(networking)...\n",
      "  ✓ Saved\n",
      "[82/445] 81 saved | https://en.wikipedia.org/wiki/AS2...\n",
      "  ✓ Saved\n",
      "[83/445] 82 saved | https://en.wikipedia.org/wiki/Back-Up_Interceptor_Control...\n",
      "  ✓ Saved\n",
      "[84/445] 83 saved | https://en.wikipedia.org/wiki/List_of_broadband_over_power_l...\n",
      "  ✓ Saved\n",
      "[85/445] 84 saved | https://en.wikipedia.org/wiki/Campus_network...\n",
      "  ✓ Saved\n",
      "[86/445] 85 saved | https://en.wikipedia.org/wiki/CANaerospace...\n",
      "  ✓ Saved\n",
      "[87/445] 86 saved | https://en.wikipedia.org/wiki/Center_for_Resilient_Networks_...\n",
      "  ✓ Saved\n",
      "[88/445] 87 saved | https://en.wikipedia.org/wiki/Computer_network_engineering...\n",
      "  ✓ Saved\n",
      "[89/445] 88 saved | https://en.wikipedia.org/wiki/Coreu...\n",
      "  ✓ Saved\n",
      "[90/445] 89 saved | https://en.wikipedia.org/wiki/ISO_15765-2...\n",
      "  ✓ Saved\n",
      "[91/445] 90 saved | https://en.wikipedia.org/wiki/Defence_Information_Infrastruc...\n",
      "  ✓ Saved\n",
      "[92/445] 91 saved | https://en.wikipedia.org/wiki/Distributed_operating_system...\n",
      "  ✓ Saved\n",
      "[93/445] 92 saved | https://en.wikipedia.org/wiki/Eduroam...\n",
      "  ✓ Saved\n",
      "[94/445] 93 saved | https://en.wikipedia.org/wiki/European_Grid_Infrastructure...\n",
      "  ✓ Saved\n",
      "[95/445] 94 saved | https://en.wikipedia.org/wiki/Experimental_SAGE_Subsector...\n",
      "  ✓ Saved\n",
      "[96/445] 95 saved | https://en.wikipedia.org/wiki/Frame_(networking)...\n",
      "  ✓ Saved\n",
      "[97/445] 96 saved | https://en.wikipedia.org/wiki/G.9963...\n",
      "  ✓ Saved\n",
      "[98/445] 97 saved | https://en.wikipedia.org/wiki/G.9970...\n",
      "  ✓ Saved\n",
      "[99/445] 98 saved | https://en.wikipedia.org/wiki/G.9972...\n",
      "  ✓ Saved\n",
      "[100/445] 99 saved | https://en.wikipedia.org/wiki/G.hn...\n",
      "  ✓ Saved\n",
      "[101/445] 100 saved | https://en.wikipedia.org/wiki/Government_Secure_Intranet...\n",
      "  ✓ Saved\n",
      "[102/445] 101 saved | https://en.wikipedia.org/wiki/Hilscher_netx_network_controll...\n",
      "  ✓ Saved\n",
      "[103/445] 102 saved | https://en.wikipedia.org/wiki/IBM_37xx...\n",
      "  ✓ Saved\n",
      "[104/445] 103 saved | https://en.wikipedia.org/wiki/IBM_remote_batch_terminals...\n",
      "  ✓ Saved\n",
      "[105/445] 104 saved | https://en.wikipedia.org/wiki/IEBus...\n",
      "  ✓ Saved\n",
      "[106/445] 105 saved | https://en.wikipedia.org/wiki/InfiniBand...\n",
      "  ✓ Saved\n",
      "[107/445] 106 saved | https://en.wikipedia.org/wiki/Information_Networking_Institu...\n",
      "  ✓ Saved\n",
      "[108/445] 107 saved | https://en.wikipedia.org/wiki/Intent-based_network...\n",
      "  ✓ Saved\n",
      "[109/445] 108 saved | https://en.wikipedia.org/wiki/Internet...\n",
      "  ✓ Saved\n",
      "[110/445] 109 saved | https://en.wikipedia.org/wiki/Internet_Security_Alliance...\n",
      "  ✓ Saved\n",
      "[111/445] 110 saved | https://en.wikipedia.org/wiki/Interplanetary_Internet...\n",
      "  ✓ Saved\n",
      "[112/445] 111 saved | https://en.wikipedia.org/wiki/Intranet...\n",
      "  ✓ Saved\n",
      "[113/445] 112 saved | https://en.wikipedia.org/wiki/IWARP...\n",
      "  ✓ Saved\n",
      "[114/445] 113 saved | https://en.wikipedia.org/wiki/List_of_network_buses...\n",
      "  ✓ Saved\n",
      "[115/445] 114 saved | https://en.wikipedia.org/wiki/Database...\n",
      "  ✓ Saved\n",
      "[116/445] 115 saved | https://en.wikipedia.org/wiki/Database_dump...\n",
      "  ✓ Saved\n",
      "[117/445] 116 saved | https://en.wikipedia.org/wiki/Outline_of_databases...\n",
      "  ✓ Saved\n",
      "[118/445] 117 saved | https://en.wikipedia.org/wiki/Altibase...\n",
      "  ✓ Saved\n",
      "[119/445] 118 saved | https://en.wikipedia.org/wiki/Database_application...\n",
      "  ✓ Saved\n",
      "[120/445] 119 saved | https://en.wikipedia.org/wiki/Autocommit...\n",
      "  ✓ Saved\n",
      "[121/445] 120 saved | https://en.wikipedia.org/wiki/Big_data...\n",
      "  ✓ Saved\n",
      "[122/445] 121 saved | https://en.wikipedia.org/wiki/Catalog_server...\n",
      "  ✓ Saved\n",
      "[123/445] 122 saved | https://en.wikipedia.org/wiki/Central_Equipment_Identity_Reg...\n",
      "  ✓ Saved\n",
      "[124/445] 123 saved | https://en.wikipedia.org/wiki/Clone_(database)...\n",
      "  ✓ Saved\n",
      "[125/445] 124 saved | https://en.wikipedia.org/wiki/Commitment_ordering...\n",
      "  ✓ Saved\n",
      "[126/445] 125 saved | https://en.wikipedia.org/wiki/Common_data_model...\n",
      "  ✓ Saved\n",
      "[127/445] 126 saved | https://en.wikipedia.org/wiki/Composite_index_(database)...\n",
      "  ✓ Saved\n",
      "[128/445] 127 saved | https://en.wikipedia.org/wiki/Concurrency_control...\n",
      "  ✓ Saved\n",
      "[129/445] 128 saved | https://en.wikipedia.org/wiki/Connection_string...\n",
      "  ✓ Saved\n",
      "[130/445] 129 saved | https://en.wikipedia.org/wiki/Couchbase_Server...\n",
      "  ✓ Saved\n",
      "[131/445] 130 saved | https://en.wikipedia.org/wiki/CrocBITE...\n",
      "  ✓ Saved\n",
      "[132/445] 131 saved | https://en.wikipedia.org/wiki/Dark_data...\n",
      "  ✓ Saved\n",
      "[133/445] 132 saved | https://en.wikipedia.org/wiki/Data_access_layer...\n",
      "  ✓ Saved\n",
      "[134/445] 133 saved | https://en.wikipedia.org/wiki/Data_administration...\n",
      "  ✓ Saved\n",
      "[135/445] 134 saved | https://en.wikipedia.org/wiki/Data_event...\n",
      "  ✓ Saved\n",
      "[136/445] 135 saved | https://en.wikipedia.org/wiki/Data_item...\n",
      "  ✓ Saved\n",
      "[137/445] 136 saved | https://en.wikipedia.org/wiki/Data_masking...\n",
      "  ✓ Saved\n",
      "[138/445] 137 saved | https://en.wikipedia.org/wiki/Data_mesh...\n",
      "  ✓ Saved\n",
      "[139/445] 138 saved | https://en.wikipedia.org/wiki/Data_pack...\n",
      "  ✓ Saved\n",
      "[140/445] 139 saved | https://en.wikipedia.org/wiki/Data_redundancy...\n",
      "  ✓ Saved\n",
      "[141/445] 140 saved | https://en.wikipedia.org/wiki/Data_store...\n",
      "  ✓ Saved\n",
      "[142/445] 141 saved | https://en.wikipedia.org/wiki/Data_system...\n",
      "  ✓ Saved\n",
      "[143/445] 142 saved | https://en.wikipedia.org/wiki/Database_(journal)...\n",
      "  ✓ Saved\n",
      "[144/445] 143 saved | https://en.wikipedia.org/wiki/Database_connection...\n",
      "  ✓ Saved\n",
      "[145/445] 144 saved | https://en.wikipedia.org/wiki/Database_design...\n",
      "  ✓ Saved\n",
      "[146/445] 145 saved | https://en.wikipedia.org/wiki/Database_firewall...\n",
      "  ✓ Saved\n",
      "[147/445] 146 saved | https://en.wikipedia.org/wiki/Database_machine...\n",
      "  ✓ Saved\n",
      "[148/445] 147 saved | https://en.wikipedia.org/wiki/Database_preservation...\n",
      "  ✓ Saved\n",
      "[149/445] 148 saved | https://en.wikipedia.org/wiki/Database_publishing...\n",
      "  ✓ Saved\n",
      "[150/445] 149 saved | https://en.wikipedia.org/wiki/Database_refactoring...\n",
      "  ✓ Saved\n",
      "[151/445] 150 saved | https://en.wikipedia.org/wiki/Database_transaction_schedule...\n",
      "  ✓ Saved\n",
      "[152/445] 151 saved | https://en.wikipedia.org/wiki/Database_virtualization...\n",
      "  ✓ Saved\n",
      "[153/445] 152 saved | https://en.wikipedia.org/wiki/Database-as-IPC...\n",
      "  ✓ Saved\n",
      "[154/445] 153 saved | https://en.wikipedia.org/wiki/Datasource...\n",
      "  ✓ Saved\n",
      "[155/445] 154 saved | https://en.wikipedia.org/wiki/Cryptography...\n",
      "  ✓ Saved\n",
      "[156/445] 155 saved | https://en.wikipedia.org/wiki/123_Reg...\n",
      "  ✓ Saved\n",
      "[157/445] 156 saved | https://en.wikipedia.org/wiki/Accumulator_(cryptography)...\n",
      "  ✓ Saved\n",
      "[158/445] 157 saved | https://en.wikipedia.org/wiki/Adaptive_redaction...\n",
      "  ✓ Saved\n",
      "[159/445] 158 saved | https://en.wikipedia.org/wiki/Advanced_Encryption_Standard...\n",
      "  ✓ Saved\n",
      "[160/445] 159 saved | https://en.wikipedia.org/wiki/Alice_and_Bob...\n",
      "  ✓ Saved\n",
      "[161/445] 160 saved | https://en.wikipedia.org/wiki/Anonymous_matching...\n",
      "  ✓ Saved\n",
      "[162/445] 161 saved | https://en.wikipedia.org/wiki/Anonymous_remailer...\n",
      "  ✓ Saved\n",
      "[163/445] 162 saved | https://en.wikipedia.org/wiki/Arkham_(cryptocurrency_exchang...\n",
      "  ✓ Saved\n",
      "[164/445] 163 saved | https://en.wikipedia.org/wiki/Array_controller_based_encrypt...\n",
      "  ✓ Saved\n",
      "[165/445] 164 saved | https://en.wikipedia.org/wiki/Backdoor_(computing)...\n",
      "  ✓ Saved\n",
      "[166/445] 165 saved | https://en.wikipedia.org/wiki/Batch_cryptography...\n",
      "  ✓ Saved\n",
      "[167/445] 166 saved | https://en.wikipedia.org/wiki/Serge_Belamant...\n",
      "  ✓ Saved\n",
      "[168/445] 167 saved | https://en.wikipedia.org/wiki/Bitcoin_Gold...\n",
      "  ✓ Saved\n",
      "[169/445] 168 saved | https://en.wikipedia.org/wiki/Bitcoin_Satoshi_Vision...\n",
      "  ✓ Saved\n",
      "[170/445] 169 saved | https://en.wikipedia.org/wiki/Blacker_(security)...\n",
      "  ✓ Saved\n",
      "[171/445] 170 saved | https://en.wikipedia.org/wiki/Blinding_(cryptography)...\n",
      "  ✓ Saved\n",
      "[172/445] 171 saved | https://en.wikipedia.org/wiki/Blocknots...\n",
      "  ✓ Saved\n",
      "[173/445] 172 saved | https://en.wikipedia.org/wiki/Branch_number...\n",
      "  ✓ Saved\n",
      "[174/445] 173 saved | https://en.wikipedia.org/wiki/BREACH...\n",
      "  ✓ Saved\n",
      "[175/445] 174 saved | https://en.wikipedia.org/wiki/Bring_your_own_encryption...\n",
      "  ✓ Saved\n",
      "[176/445] 175 saved | https://en.wikipedia.org/wiki/Bus_encryption...\n",
      "  ✓ Saved\n",
      "[177/445] 176 saved | https://en.wikipedia.org/wiki/Chaffing_and_winnowing...\n",
      "  ✓ Saved\n",
      "[178/445] 177 saved | https://en.wikipedia.org/wiki/Chaos_Communication_Congress...\n",
      "  ✓ Saved\n",
      "[179/445] 178 saved | https://en.wikipedia.org/wiki/Chaotic_cryptology...\n",
      "  ✓ Saved\n",
      "[180/445] 179 saved | https://en.wikipedia.org/wiki/Cipher...\n",
      "  ✓ Saved\n",
      "[181/445] 180 saved | https://en.wikipedia.org/wiki/Cipher_device...\n",
      "  ✓ Saved\n",
      "[182/445] 181 saved | https://en.wikipedia.org/wiki/Ciphertext...\n",
      "  ✓ Saved\n",
      "[183/445] 182 saved | https://en.wikipedia.org/wiki/Ciphertext_expansion...\n",
      "  ✓ Saved\n",
      "[184/445] 183 saved | https://en.wikipedia.org/wiki/Client-side_encryption...\n",
      "  ✓ Saved\n",
      "[185/445] 184 saved | https://en.wikipedia.org/wiki/Code_(cryptography)...\n",
      "  ✓ Saved\n",
      "[186/445] 185 saved | https://en.wikipedia.org/wiki/Code_word_(communication)...\n",
      "  ✓ Saved\n",
      "[187/445] 186 saved | https://en.wikipedia.org/wiki/Codebook...\n",
      "  ✓ Saved\n",
      "[188/445] 187 saved | https://en.wikipedia.org/wiki/Codress_message...\n",
      "  ✓ Saved\n",
      "[189/445] 188 saved | https://en.wikipedia.org/wiki/Colored_Coins...\n",
      "  ✓ Saved\n",
      "[190/445] 189 saved | https://en.wikipedia.org/wiki/Communications_security...\n",
      "  ✓ Saved\n",
      "[191/445] 190 saved | https://en.wikipedia.org/wiki/Completeness_(cryptography)...\n",
      "  ✓ Saved\n",
      "[192/445] 191 saved | https://en.wikipedia.org/wiki/Computer_security...\n",
      "  ✓ Saved\n",
      "[193/445] 192 saved | https://en.wikipedia.org/wiki/Conjugate_coding...\n",
      "  ✓ Saved\n",
      "[194/445] 193 saved | https://en.wikipedia.org/wiki/Convergent_encryption...\n",
      "  ✓ Saved\n",
      "[195/445] 194 saved | https://en.wikipedia.org/wiki/Operating_system...\n",
      "  ✓ Saved\n",
      "[196/445] 195 saved | https://en.wikipedia.org/wiki/Comparison_of_operating_system...\n",
      "  ✓ Saved\n",
      "[197/445] 196 saved | https://en.wikipedia.org/wiki/History_of_operating_systems...\n",
      "  ✓ Saved\n",
      "[198/445] 197 saved | https://en.wikipedia.org/wiki/List_of_operating_systems...\n",
      "  ✓ Saved\n",
      "[199/445] 198 saved | https://en.wikipedia.org/wiki/Timeline_of_operating_systems...\n",
      "  ✓ Saved\n",
      "[200/445] 199 saved | https://en.wikipedia.org/wiki/Usage_share_of_operating_syste...\n",
      "  ✓ Saved\n",
      "[201/445] 200 saved | https://en.wikipedia.org/wiki/Bare_machine...\n",
      "  ✓ Saved\n",
      "[202/445] 201 saved | https://en.wikipedia.org/wiki/Comparison_of_user_features_of...\n",
      "  ✓ Saved\n",
      "[203/445] 202 saved | https://en.wikipedia.org/wiki/DBOS...\n",
      "  ✓ Saved\n",
      "[204/445] 203 saved | https://en.wikipedia.org/wiki/Distributed_operating_system...\n",
      "  ✓ Saved\n",
      "[205/445] 204 saved | https://en.wikipedia.org/wiki/Friend_(operating_system)...\n",
      "  ✓ Saved\n",
      "[206/445] 205 saved | https://en.wikipedia.org/wiki/Glossary_of_operating_systems_...\n",
      "  ✓ Saved\n",
      "[207/445] 206 saved | https://en.wikipedia.org/wiki/History_of_RISC_OS...\n",
      "  ✓ Saved\n",
      "[208/445] 207 saved | https://en.wikipedia.org/wiki/Holborn_9100...\n",
      "  ✓ Saved\n",
      "[209/445] 208 saved | https://en.wikipedia.org/wiki/Human68k...\n",
      "  ✓ Saved\n",
      "[210/445] 209 saved | https://en.wikipedia.org/wiki/Internet_OS...\n",
      "  ✓ Saved\n",
      "[211/445] 210 saved | https://en.wikipedia.org/wiki/Just_enough_operating_system...\n",
      "  ✓ Saved\n",
      "[212/445] 211 saved | https://en.wikipedia.org/wiki/Kernel_(operating_system)...\n",
      "  ✓ Saved\n",
      "[213/445] 212 saved | https://en.wikipedia.org/wiki/LCARS...\n",
      "  ✓ Saved\n",
      "[214/445] 213 saved | https://en.wikipedia.org/wiki/Linux...\n",
      "  ✓ Saved\n",
      "[215/445] 214 saved | https://en.wikipedia.org/wiki/Linux_kernel...\n",
      "  ✓ Saved\n",
      "[216/445] 215 saved | https://en.wikipedia.org/wiki/Memory_management_(operating_s...\n",
      "  ✓ Saved\n",
      "[217/445] 216 saved | https://en.wikipedia.org/wiki/Mobile_operating_system...\n",
      "  ✓ Saved\n",
      "[218/445] 217 saved | https://en.wikipedia.org/wiki/Network_operating_system...\n",
      "  ✓ Saved\n",
      "[219/445] 218 saved | https://en.wikipedia.org/wiki/NSDOS...\n",
      "  ✓ Saved\n",
      "[220/445] 219 saved | https://en.wikipedia.org/wiki/Operating_System_Concepts...\n",
      "  ✓ Saved\n",
      "[221/445] 220 saved | https://en.wikipedia.org/wiki/Real-time_operating_system...\n",
      "  ✓ Saved\n",
      "[222/445] 221 saved | https://en.wikipedia.org/wiki/Single_address_space_operating...\n",
      "  ✓ Saved\n",
      "[223/445] 222 saved | https://en.wikipedia.org/wiki/Supercomputer_operating_system...\n",
      "  ✓ Saved\n",
      "[224/445] 223 saved | https://en.wikipedia.org/wiki/UCSD_Pascal...\n",
      "  ✓ Saved\n",
      "[225/445] 224 saved | https://en.wikipedia.org/wiki/Visopsys...\n",
      "  ✓ Saved\n",
      "[226/445] 225 saved | https://en.wikipedia.org/wiki/Outline_of_web_design_and_web_...\n",
      "  ✓ Saved\n",
      "[227/445] 226 saved | https://en.wikipedia.org/wiki/Web_development...\n",
      "  ✓ Saved\n",
      "[228/445] 227 saved | https://en.wikipedia.org/wiki/Agile_web_development...\n",
      "  ✓ Saved\n",
      "[229/445] 228 saved | https://en.wikipedia.org/wiki/Ajax_(programming)...\n",
      "  ✓ Saved\n",
      "[230/445] 229 saved | https://en.wikipedia.org/wiki/Asynchronous_module_definition...\n",
      "  ✓ Saved\n",
      "[231/445] 230 saved | https://en.wikipedia.org/wiki/Awwwards...\n",
      "  ✓ Saved\n",
      "[232/445] 231 saved | https://en.wikipedia.org/wiki/Backend_as_a_service...\n",
      "  ✓ Saved\n",
      "[233/445] 232 saved | https://en.wikipedia.org/wiki/Blend4Web...\n",
      "  ✓ Saved\n",
      "[234/445] 233 saved | https://en.wikipedia.org/wiki/Bookmarklet...\n",
      "  ✓ Saved\n",
      "[235/445] 234 saved | https://en.wikipedia.org/wiki/Bootstrap_(front-end_framework...\n",
      "  ✓ Saved\n",
      "[236/445] 235 saved | https://en.wikipedia.org/wiki/Browser_sniffing...\n",
      "  ✓ Saved\n",
      "[237/445] 236 saved | https://en.wikipedia.org/wiki/CodePen...\n",
      "  ✓ Saved\n",
      "[238/445] 237 saved | https://en.wikipedia.org/wiki/Comet_(programming)...\n",
      "  ✓ Saved\n",
      "[239/445] 238 saved | https://en.wikipedia.org/wiki/Comparison_of_JavaScript-based...\n",
      "  ✓ Saved\n",
      "[240/445] 239 saved | https://en.wikipedia.org/wiki/Content_adaptation...\n",
      "  ✓ Saved\n",
      "[241/445] 240 saved | https://en.wikipedia.org/wiki/Content_strategy...\n",
      "  ✓ Saved\n",
      "[242/445] 241 saved | https://en.wikipedia.org/wiki/Conversion_path...\n",
      "  ✓ Saved\n",
      "[243/445] 242 saved | https://en.wikipedia.org/wiki/CSS_box_model...\n",
      "  ✓ Saved\n",
      "[244/445] 243 saved | https://en.wikipedia.org/wiki/CSS_HTML_Validator...\n",
      "  ✓ Saved\n",
      "[245/445] 244 saved | https://en.wikipedia.org/wiki/CU-RTC-WEB...\n",
      "  ✓ Saved\n",
      "[246/445] 245 saved | https://en.wikipedia.org/wiki/Dynamic_web_page...\n",
      "  ✓ Saved\n",
      "[247/445] 246 saved | https://en.wikipedia.org/wiki/Electronic_business...\n",
      "  ✓ Saved\n",
      "[248/445] 247 saved | https://en.wikipedia.org/wiki/Far-Play...\n",
      "  ✓ Saved\n",
      "[249/445] 248 saved | https://en.wikipedia.org/wiki/Feature_detection_(web_develop...\n",
      "  ✓ Saved\n",
      "[250/445] 249 saved | https://en.wikipedia.org/wiki/Font_Bomb...\n",
      "  ✓ Saved\n",
      "[251/445] 250 saved | https://en.wikipedia.org/wiki/Front-end_web_development...\n",
      "  ✓ Saved\n",
      "[252/445] 251 saved | https://en.wikipedia.org/wiki/GlTF...\n",
      "  ✓ Saved\n",
      "[253/445] 252 saved | https://en.wikipedia.org/wiki/Homeboyz_Interactive...\n",
      "  ✓ Saved\n",
      "[254/445] 253 saved | https://en.wikipedia.org/wiki/HTML5_Boilerplate...\n",
      "  ✓ Saved\n",
      "[255/445] 254 saved | https://en.wikipedia.org/wiki/HtmlUnit...\n",
      "  ✓ Saved\n",
      "[256/445] 255 saved | https://en.wikipedia.org/wiki/HTTP_compression...\n",
      "  ✓ Saved\n",
      "[257/445] 256 saved | https://en.wikipedia.org/wiki/Hydration_(web_development)...\n",
      "  ✓ Saved\n",
      "[258/445] 257 saved | https://en.wikipedia.org/wiki/International_Webmasters_Assoc...\n",
      "  ✓ Saved\n",
      "[259/445] 258 saved | https://en.wikipedia.org/wiki/International_World_Wide_Web_C...\n",
      "  ✓ Saved\n",
      "[260/445] 259 saved | https://en.wikipedia.org/wiki/JQuery...\n",
      "  ✓ Saved\n",
      "[261/445] 260 saved | https://en.wikipedia.org/wiki/Kimchi_(software)...\n",
      "  ✓ Saved\n",
      "[262/445] 261 saved | https://en.wikipedia.org/wiki/Link-richness...\n",
      "  ✓ Saved\n",
      "[263/445] 262 saved | https://en.wikipedia.org/wiki/List_of_PHP_software_and_tools...\n",
      "  ✓ Saved\n",
      "[264/445] 263 saved | https://en.wikipedia.org/wiki/List_of_WebGL_frameworks...\n",
      "  ✓ Saved\n",
      "[265/445] 264 saved | https://en.wikipedia.org/wiki/Mike_Little...\n",
      "  ✓ Saved\n",
      "[266/445] 265 saved | https://en.wikipedia.org/wiki/Computational_linguistics...\n",
      "  ✓ Saved\n",
      "[267/445] 266 saved | https://en.wikipedia.org/wiki/ACL_Data_Collection_Initiative...\n",
      "  ✓ Saved\n",
      "[268/445] 267 saved | https://en.wikipedia.org/wiki/Acoustic_model...\n",
      "  ✓ Saved\n",
      "[269/445] 268 saved | https://en.wikipedia.org/wiki/Adversarial_stylometry...\n",
      "  ✓ Saved\n",
      "[270/445] 269 saved | https://en.wikipedia.org/wiki/Aggregation_(linguistics)...\n",
      "  ✓ Saved\n",
      "[271/445] 270 saved | https://en.wikipedia.org/wiki/Aikuma...\n",
      "  ✓ Saved\n",
      "[272/445] 271 saved | https://en.wikipedia.org/wiki/ALPAC...\n",
      "  ✓ Saved\n",
      "[273/445] 272 saved | https://en.wikipedia.org/wiki/American_National_Corpus...\n",
      "  ✓ Saved\n",
      "[274/445] 273 saved | https://en.wikipedia.org/wiki/Analogical_modeling...\n",
      "  ✓ Saved\n",
      "[275/445] 274 saved | https://en.wikipedia.org/wiki/Arabic_Ontology...\n",
      "  ✓ Saved\n",
      "[276/445] 275 saved | https://en.wikipedia.org/wiki/Argument_mining...\n",
      "  ✓ Saved\n",
      "[277/445] 276 saved | https://en.wikipedia.org/wiki/Articulatory_phonology...\n",
      "  ✓ Saved\n",
      "[278/445] 277 saved | https://en.wikipedia.org/wiki/Articulatory_speech_recognitio...\n",
      "  ✓ Saved\n",
      "[279/445] 278 saved | https://en.wikipedia.org/wiki/Artificial_grammar_learning...\n",
      "  ✓ Saved\n",
      "[280/445] 279 saved | https://en.wikipedia.org/wiki/Artificial_intelligence_conten...\n",
      "  ✓ Saved\n",
      "[281/445] 280 saved | https://en.wikipedia.org/wiki/Artificial_Solutions...\n",
      "  ✓ Saved\n",
      "[282/445] 281 saved | https://en.wikipedia.org/wiki/Association_for_Computational_...\n",
      "  ✓ Saved\n",
      "[283/445] 282 saved | https://en.wikipedia.org/wiki/Audio_mining...\n",
      "  ✓ Saved\n",
      "[284/445] 283 saved | https://en.wikipedia.org/wiki/Audio-visual_speech_recognitio...\n",
      "  ✓ Saved\n",
      "[285/445] 284 saved | https://en.wikipedia.org/wiki/Australasian_Language_Technolo...\n",
      "  ✓ Saved\n",
      "[286/445] 285 saved | https://en.wikipedia.org/wiki/Automated_essay_scoring...\n",
      "  ✓ Saved\n",
      "[287/445] 286 saved | https://en.wikipedia.org/wiki/Automated_Lip_Reading...\n",
      "  ✓ Saved\n",
      "[288/445] 287 saved | https://en.wikipedia.org/wiki/Automated_Similarity_Judgment_...\n",
      "  ✓ Saved\n",
      "[289/445] 288 saved | https://en.wikipedia.org/wiki/Automatic_acquisition_of_sense...\n",
      "  ✓ Saved\n",
      "[290/445] 289 saved | https://en.wikipedia.org/wiki/Automatic_summarization...\n",
      "  ✓ Saved\n",
      "[291/445] 290 saved | https://en.wikipedia.org/wiki/Babelfy...\n",
      "  ✓ Saved\n",
      "[292/445] 291 saved | https://en.wikipedia.org/wiki/BabelNet...\n",
      "  ✓ Saved\n",
      "[293/445] 292 saved | https://en.wikipedia.org/wiki/Bradford's_law...\n",
      "  ✓ Saved\n",
      "[294/445] 293 saved | https://en.wikipedia.org/wiki/Brown_clustering...\n",
      "  ✓ Saved\n",
      "[295/445] 294 saved | https://en.wikipedia.org/wiki/BulNet...\n",
      "  ✓ Saved\n",
      "[296/445] 295 saved | https://en.wikipedia.org/wiki/Theoretical_computer_science...\n",
      "  ✓ Saved\n",
      "[297/445] 296 saved | https://en.wikipedia.org/wiki/ACM_Doctoral_Dissertation_Awar...\n",
      "  ✓ Saved\n",
      "[298/445] 297 saved | https://en.wikipedia.org/wiki/ACM_SIGACT...\n",
      "  ✓ Saved\n",
      "[299/445] 298 saved | https://en.wikipedia.org/wiki/Algorithm...\n",
      "  ✓ Saved\n",
      "[300/445] 299 saved | https://en.wikipedia.org/wiki/Algorithm_engineering...\n",
      "  ✓ Saved\n",
      "[301/445] 300 saved | https://en.wikipedia.org/wiki/Algorithmic_logic...\n",
      "  ✓ Saved\n",
      "[302/445] 301 saved | https://en.wikipedia.org/wiki/Algorithmic_technique...\n",
      "  ✓ Saved\n",
      "[303/445] 302 saved | https://en.wikipedia.org/wiki/Algorithmic_transparency...\n",
      "  ✓ Saved\n",
      "[304/445] 303 saved | https://en.wikipedia.org/wiki/Ambient_calculus...\n",
      "  ✓ Saved\n",
      "[305/445] 304 saved | https://en.wikipedia.org/wiki/Analysis_of_Boolean_functions...\n",
      "  ✓ Saved\n",
      "[306/445] 305 saved | https://en.wikipedia.org/wiki/Angelic_non-determinism...\n",
      "  ✓ Saved\n",
      "[307/445] 306 saved | https://en.wikipedia.org/wiki/API-Calculus...\n",
      "  ✓ Saved\n",
      "[308/445] 307 saved | https://en.wikipedia.org/wiki/Automated_reasoning...\n",
      "  ✓ Saved\n",
      "[309/445] 308 saved | https://en.wikipedia.org/wiki/Bigraph...\n",
      "  ✓ Saved\n",
      "[310/445] 309 saved | https://en.wikipedia.org/wiki/Bio-inspired_computing...\n",
      "  ✓ Saved\n",
      "[311/445] 310 saved | https://en.wikipedia.org/wiki/Bird–Meertens_formalism...\n",
      "  ✓ Saved\n",
      "[312/445] 311 saved | https://en.wikipedia.org/wiki/Bisimulation...\n",
      "  ✓ Saved\n",
      "[313/445] 312 saved | https://en.wikipedia.org/wiki/Bridging_model...\n",
      "  ✓ Saved\n",
      "[314/445] 313 saved | https://en.wikipedia.org/wiki/British_Colloquium_for_Theoret...\n",
      "  ✓ Saved\n",
      "[315/445] 314 saved | https://en.wikipedia.org/wiki/Calculating_Space...\n",
      "  ✓ Saved\n",
      "[316/445] 315 saved | https://en.wikipedia.org/wiki/Categorical_logic...\n",
      "  ✓ Saved\n",
      "[317/445] 316 saved | https://en.wikipedia.org/wiki/Chaos_computing...\n",
      "  ✓ Saved\n",
      "[318/445] 317 saved | https://en.wikipedia.org/wiki/Chemical_computer...\n",
      "  ✓ Saved\n",
      "[319/445] 318 saved | https://en.wikipedia.org/wiki/Circuit_value_problem...\n",
      "  ✓ Saved\n",
      "[320/445] 319 saved | https://en.wikipedia.org/wiki/Cobham's_theorem...\n",
      "  ✓ Saved\n",
      "[321/445] 320 saved | https://en.wikipedia.org/wiki/Coinduction...\n",
      "  ✓ Saved\n",
      "[322/445] 321 saved | https://en.wikipedia.org/wiki/Combinatorial_optimization...\n",
      "  ✓ Saved\n",
      "[323/445] 322 saved | https://en.wikipedia.org/wiki/Comp.theory...\n",
      "  ✓ Saved\n",
      "[324/445] 323 saved | https://en.wikipedia.org/wiki/Complexity_class...\n",
      "  ✓ Saved\n",
      "[325/445] 324 saved | https://en.wikipedia.org/wiki/Complexity_function...\n",
      "  ✓ Saved\n",
      "[326/445] 325 saved | https://en.wikipedia.org/wiki/Computer_architecture...\n",
      "  ✓ Saved\n",
      "[327/445] 326 saved | https://en.wikipedia.org/wiki/Abstraction_layer...\n",
      "  ✓ Saved\n",
      "[328/445] 327 saved | https://en.wikipedia.org/wiki/Address_space...\n",
      "  ✓ Saved\n",
      "[329/445] 328 saved | https://en.wikipedia.org/wiki/Addressing_mode...\n",
      "  ✓ Saved\n",
      "[330/445] 329 saved | https://en.wikipedia.org/wiki/Aperture_(computer_memory)...\n",
      "  ✓ Saved\n",
      "[331/445] 330 saved | https://en.wikipedia.org/wiki/Approximate_computing...\n",
      "  ✓ Saved\n",
      "[332/445] 331 saved | https://en.wikipedia.org/wiki/Arithmetic_logic_unit...\n",
      "  ✓ Saved\n",
      "[333/445] 332 saved | https://en.wikipedia.org/wiki/Autonomous_decentralized_syste...\n",
      "  ✓ Saved\n",
      "[334/445] 333 saved | https://en.wikipedia.org/wiki/Bare_machine_computing...\n",
      "  ✓ Saved\n",
      "[335/445] 334 saved | https://en.wikipedia.org/wiki/Berkeley_IRAM_project...\n",
      "  ✓ Saved\n",
      "[336/445] 335 saved | https://en.wikipedia.org/wiki/Branch_Queue...\n",
      "  ✓ Saved\n",
      "[337/445] 336 saved | https://en.wikipedia.org/wiki/Bridging_model...\n",
      "  ✓ Saved\n",
      "[338/445] 337 saved | https://en.wikipedia.org/wiki/Byte_addressing...\n",
      "  ✓ Saved\n",
      "[339/445] 338 saved | https://en.wikipedia.org/wiki/Cache_(computing)...\n",
      "  ✓ Saved\n",
      "[340/445] 339 saved | https://en.wikipedia.org/wiki/Cache_control_instruction...\n",
      "  ✓ Saved\n",
      "[341/445] 340 saved | https://en.wikipedia.org/wiki/Cache_hierarchy...\n",
      "  ✓ Saved\n",
      "[342/445] 341 saved | https://en.wikipedia.org/wiki/Cache_pollution...\n",
      "  ✓ Saved\n",
      "[343/445] 342 saved | https://en.wikipedia.org/wiki/Capability_Hardware_Enhanced_R...\n",
      "  ✓ Saved\n",
      "[344/445] 343 saved | https://en.wikipedia.org/wiki/Cellular_architecture...\n",
      "  ✓ Saved\n",
      "[345/445] 344 saved | https://en.wikipedia.org/wiki/Comparison_of_CPU_microarchite...\n",
      "  ✓ Saved\n",
      "[346/445] 345 saved | https://en.wikipedia.org/wiki/Comparison_of_instruction_set_...\n",
      "  ✓ Saved\n",
      "[347/445] 346 saved | https://en.wikipedia.org/wiki/Computational_RAM...\n",
      "  ✓ Saved\n",
      "[348/445] 347 saved | https://en.wikipedia.org/wiki/Computer_architecture_simulato...\n",
      "  ✓ Saved\n",
      "[349/445] 348 saved | https://en.wikipedia.org/wiki/Computer_data_storage...\n",
      "  ✓ Saved\n",
      "[350/445] 349 saved | https://en.wikipedia.org/wiki/Data_memory-dependent_prefetch...\n",
      "  ✓ Saved\n",
      "[351/445] 350 saved | https://en.wikipedia.org/wiki/Dataflow...\n",
      "  ✓ Saved\n",
      "[352/445] 351 saved | https://en.wikipedia.org/wiki/Dataflow_architecture...\n",
      "  ✓ Saved\n",
      "[353/445] 352 saved | https://en.wikipedia.org/wiki/Directory-based_cache_coherenc...\n",
      "  ✓ Saved\n",
      "[354/445] 353 saved | https://en.wikipedia.org/wiki/Directory-based_coherence...\n",
      "  ✓ Saved\n",
      "[355/445] 354 saved | https://en.wikipedia.org/wiki/Domain-specific_architecture...\n",
      "  ✓ Saved\n",
      "[356/445] 355 saved | https://en.wikipedia.org/wiki/Decentralized_computing...\n",
      "  ✓ Saved\n",
      "[357/445] 356 saved | https://en.wikipedia.org/wiki/Distributed_computing...\n",
      "  ✓ Saved\n",
      "[358/445] 357 saved | https://en.wikipedia.org/wiki/ActivityPub...\n",
      "  ✓ Saved\n",
      "[359/445] 358 saved | https://en.wikipedia.org/wiki/AT_Protocol...\n",
      "  ✓ Saved\n",
      "[360/445] 359 saved | https://en.wikipedia.org/wiki/Availability_zone...\n",
      "  ✓ Saved\n",
      "[361/445] 360 saved | https://en.wikipedia.org/wiki/Botnet...\n",
      "  ✓ Saved\n",
      "[362/445] 361 saved | https://en.wikipedia.org/wiki/CAP_theorem...\n",
      "  ✓ Saved\n",
      "[363/445] 362 saved | https://en.wikipedia.org/wiki/CockroachDB...\n",
      "  ✓ Saved\n",
      "[364/445] 363 saved | https://en.wikipedia.org/wiki/Collective_operation...\n",
      "  ✓ Saved\n",
      "[365/445] 364 saved | https://en.wikipedia.org/wiki/Comparison_of_synchronous_and_...\n",
      "  ✓ Saved\n",
      "[366/445] 365 saved | https://en.wikipedia.org/wiki/Confidential_Consortium_Framew...\n",
      "  ✓ Saved\n",
      "[367/445] 366 saved | https://en.wikipedia.org/wiki/Consensus_dynamics...\n",
      "  ✓ Saved\n",
      "[368/445] 367 saved | https://en.wikipedia.org/wiki/Data-centric_programming_langu...\n",
      "  ✓ Saved\n",
      "[369/445] 368 saved | https://en.wikipedia.org/wiki/Deadlock_prevention_algorithms...\n",
      "  ✓ Saved\n",
      "[370/445] 369 saved | https://en.wikipedia.org/wiki/Decentralized_application...\n",
      "  ✓ Saved\n",
      "[371/445] 370 saved | https://en.wikipedia.org/wiki/Decentralized_autonomous_organ...\n",
      "  ✓ Saved\n",
      "[372/445] 371 saved | https://en.wikipedia.org/wiki/Decomposable_aggregation_funct...\n",
      "  ✓ Saved\n",
      "[373/445] 372 saved | https://en.wikipedia.org/wiki/Distributed_algorithmic_mechan...\n",
      "  ✓ Saved\n",
      "[374/445] 373 saved | https://en.wikipedia.org/wiki/Distributed_cache...\n",
      "  ✓ Saved\n",
      "[375/445] 374 saved | https://en.wikipedia.org/wiki/Distributed_Computing_(journal...\n",
      "  ✓ Saved\n",
      "[376/445] 375 saved | https://en.wikipedia.org/wiki/Distributed_Computing_Environm...\n",
      "  ✓ Saved\n",
      "[377/445] 376 saved | https://en.wikipedia.org/wiki/Distributed_Data_Management_Ar...\n",
      "  ✓ Saved\n",
      "[378/445] 377 saved | https://en.wikipedia.org/wiki/Distributed_ledger...\n",
      "  ✓ Saved\n",
      "[379/445] 378 saved | https://en.wikipedia.org/wiki/Double-spending...\n",
      "  ✓ Saved\n",
      "[380/445] 379 saved | https://en.wikipedia.org/wiki/Elasticity_(computing)...\n",
      "  ✓ Saved\n",
      "[381/445] 380 saved | https://en.wikipedia.org/wiki/Entera...\n",
      "  ✓ Saved\n",
      "[382/445] 381 saved | https://en.wikipedia.org/wiki/Failure_detector...\n",
      "  ✓ Saved\n",
      "[383/445] 382 saved | https://en.wikipedia.org/wiki/Failure_transparency...\n",
      "  ✓ Saved\n",
      "[384/445] 383 saved | https://en.wikipedia.org/wiki/Federation_(information_techno...\n",
      "  ✓ Saved\n",
      "[385/445] 384 saved | https://en.wikipedia.org/wiki/General_Inter-ORB_Protocol...\n",
      "  ✓ Saved\n",
      "[386/445] 385 saved | https://en.wikipedia.org/wiki/Cloud_computing...\n",
      "  ✓ Saved\n",
      "[387/445] 386 saved | https://en.wikipedia.org/wiki/Abiquo_Enterprise_Edition...\n",
      "  ✓ Saved\n",
      "[388/445] 387 saved | https://en.wikipedia.org/wiki/Alibaba_Cloud...\n",
      "  ✓ Saved\n",
      "[389/445] 388 saved | https://en.wikipedia.org/wiki/Amazon_Elastic_Compute_Cloud...\n",
      "  ✓ Saved\n",
      "[390/445] 389 saved | https://en.wikipedia.org/wiki/Amazon_Kinesis...\n",
      "  ✓ Saved\n",
      "[391/445] 390 saved | https://en.wikipedia.org/wiki/Ampere_Computing...\n",
      "  ✓ Saved\n",
      "[392/445] 391 saved | https://en.wikipedia.org/wiki/Apache_Drill...\n",
      "  ✓ Saved\n",
      "[393/445] 392 saved | https://en.wikipedia.org/wiki/Apache_Hama...\n",
      "  ✓ Saved\n",
      "[394/445] 393 saved | https://en.wikipedia.org/wiki/Army_Chief_Information_Officer...\n",
      "  ✓ Saved\n",
      "[395/445] 394 saved | https://en.wikipedia.org/wiki/Autoscaling...\n",
      "  ✓ Saved\n",
      "[396/445] 395 saved | https://en.wikipedia.org/wiki/Availability_zone...\n",
      "  ✓ Saved\n",
      "[397/445] 396 saved | https://en.wikipedia.org/wiki/Azure_Data_Lake...\n",
      "  ✓ Saved\n",
      "[398/445] 397 saved | https://en.wikipedia.org/wiki/Azure_Maps...\n",
      "  ✓ Saved\n",
      "[399/445] 398 saved | https://en.wikipedia.org/wiki/Azure_Stream_Analytics...\n",
      "  ✓ Saved\n",
      "[400/445] 399 saved | https://en.wikipedia.org/wiki/BioBIKE...\n",
      "  ✓ Saved\n",
      "\n",
      "✓ Target reached: 400 samples\n",
      "\n",
      "✓ Saved: 400 | Filtered: 0 | Failed: 0\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "Productive samples: 1203\n",
      "Newly added: 400\n",
      "Filtered (too short): 0\n",
      "Failed: 0\n",
      "======================================================================\n",
      "\n",
      "✓ Dataset ready at: dataset/productive/\n",
      "  400 more productive samples collected!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "class ProductiveScraper:\n",
    "    def __init__(self, base_dir=\"dataset\", min_words=50, delay=(1, 2), max_retries=3):\n",
    "        \"\"\"Scraper focused on productive content only.\"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.min_words = min_words\n",
    "        self.delay = delay\n",
    "        self.max_retries = max_retries\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        self.productive_dir = Path(base_dir) / \"productive\"\n",
    "        self.productive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.stats = {'saved': 0, 'filtered': 0, 'failed': 0}\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize text.\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\\\"]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def extract_text(self, html):\n",
    "        \"\"\"Extract clean text from HTML.\"\"\"\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe', 'form']):\n",
    "            tag.decompose()\n",
    "        \n",
    "        text = \"\"\n",
    "        content_selectors = ['article', 'main', '.content', '#content', '.post-content', '.entry-content']\n",
    "        \n",
    "        for selector in content_selectors:\n",
    "            elements = soup.select(selector) if selector.startswith(('.', '#')) else soup.find_all(selector)\n",
    "            if elements:\n",
    "                text = ' '.join([elem.get_text(separator=' ', strip=True) for elem in elements])\n",
    "                break\n",
    "        \n",
    "        if not text:\n",
    "            body = soup.find('body')\n",
    "            text = body.get_text(separator=' ', strip=True) if body else \"\"\n",
    "        \n",
    "        return self.clean_text(text)\n",
    "    \n",
    "    def count_words(self, text):\n",
    "        \"\"\"Count words in text.\"\"\"\n",
    "        return len(text.split())\n",
    "    \n",
    "    def fetch_url(self, url, retries=0):\n",
    "        \"\"\"Fetch URL with retry logic.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except requests.RequestException as e:\n",
    "            if retries < self.max_retries:\n",
    "                wait = random.uniform(2, 5)\n",
    "                time.sleep(wait)\n",
    "                return self.fetch_url(url, retries + 1)\n",
    "            return None\n",
    "    \n",
    "    def get_next_filename(self):\n",
    "        \"\"\"Get next sequential filename.\"\"\"\n",
    "        existing_files = list(self.productive_dir.glob(\"*.txt\"))\n",
    "        if not existing_files:\n",
    "            return \"00001.txt\"\n",
    "        \n",
    "        numbers = [int(re.match(r'(\\d+)\\.txt', f.name).group(1)) \n",
    "                   for f in existing_files if re.match(r'(\\d+)\\.txt', f.name)]\n",
    "        next_num = max(numbers) + 1 if numbers else 1\n",
    "        return f\"{next_num:05d}.txt\"\n",
    "    \n",
    "    def save_text(self, text):\n",
    "        \"\"\"Save text to file.\"\"\"\n",
    "        filename = self.get_next_filename()\n",
    "        filepath = self.productive_dir / filename\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        self.stats['saved'] += 1\n",
    "        return filepath\n",
    "    \n",
    "    def scrape_wikipedia_category(self, category_name, max_pages=100):\n",
    "        \"\"\"Scrape Wikipedia pages from a category.\"\"\"\n",
    "        print(f\"\\n[Wikipedia] Scraping category: {category_name}\")\n",
    "        api_url = \"https://en.wikipedia.org/w/api.php\"\n",
    "        \n",
    "        urls = []\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'list': 'categorymembers',\n",
    "            'cmtitle': f'Category:{category_name}',\n",
    "            'cmlimit': 500,\n",
    "            'format': 'json'\n",
    "        }\n",
    "        \n",
    "        while len(urls) < max_pages:\n",
    "            response = self.fetch_url(api_url + '?' + '&'.join([f'{k}={v}' for k, v in params.items()]))\n",
    "            if not response:\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                data = json.loads(response)\n",
    "                members = data.get('query', {}).get('categorymembers', [])\n",
    "                \n",
    "                for member in members:\n",
    "                    if member.get('ns') == 0:  # Main namespace only\n",
    "                        title = member['title'].replace(' ', '_')\n",
    "                        urls.append(f\"https://en.wikipedia.org/wiki/{title}\")\n",
    "                \n",
    "                if 'continue' not in data or len(urls) >= max_pages:\n",
    "                    break\n",
    "                \n",
    "                params['cmcontinue'] = data['continue']['cmcontinue']\n",
    "                time.sleep(random.uniform(*self.delay))\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        print(f\"  Collected {len(urls)} pages\")\n",
    "        return urls[:max_pages]\n",
    "    \n",
    "    def process_url(self, url):\n",
    "        \"\"\"Process a single URL and save if valid.\"\"\"\n",
    "        html = self.fetch_url(url)\n",
    "        if html is None:\n",
    "            self.stats['failed'] += 1\n",
    "            return False\n",
    "        \n",
    "        text = self.extract_text(html)\n",
    "        word_count = self.count_words(text)\n",
    "        \n",
    "        if word_count < self.min_words:\n",
    "            self.stats['filtered'] += 1\n",
    "            return False\n",
    "        \n",
    "        self.save_text(text)\n",
    "        return True\n",
    "    \n",
    "    def scrape_urls(self, urls, target=None):\n",
    "        \"\"\"Scrape list of URLs.\"\"\"\n",
    "        print(f\"\\nProcessing {len(urls)} URLs...\")\n",
    "        \n",
    "        for i, url in enumerate(urls, 1):\n",
    "            if target and self.stats['saved'] >= target:\n",
    "                print(f\"\\n✓ Target reached: {self.stats['saved']} samples\")\n",
    "                break\n",
    "            \n",
    "            print(f\"[{i}/{len(urls)}] {self.stats['saved']} saved | {url[:60]}...\")\n",
    "            \n",
    "            success = self.process_url(url)\n",
    "            if success:\n",
    "                print(f\"  ✓ Saved\")\n",
    "            \n",
    "            time.sleep(random.uniform(*self.delay))\n",
    "        \n",
    "        print(f\"\\n✓ Saved: {self.stats['saved']} | Filtered: {self.stats['filtered']} | Failed: {self.stats['failed']}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PRODUCTIVE CONTENT COLLECTION - 400 MORE SAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = ProductiveScraper(\n",
    "        base_dir=\"dataset\",\n",
    "        min_words=50,\n",
    "        delay=(1, 2),\n",
    "        max_retries=3\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PRODUCTIVE CONTENT SCRAPER\")\n",
    "    print(f\"Target: 400 additional samples\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    current_count = len(list(scraper.productive_dir.glob(\"*.txt\")))\n",
    "    target = current_count + 400\n",
    "    \n",
    "    print(f\"\\nCurrent samples: {current_count}\")\n",
    "    print(f\"Target samples: {target}\")\n",
    "    print(f\"Need to collect: 400\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # WIKIPEDIA CATEGORIES - Technical & Educational\n",
    "    # ========================================================================\n",
    "    \n",
    "    all_urls = []\n",
    "    \n",
    "    # Core tech categories\n",
    "    wiki_categories = [\n",
    "        ('Artificial_intelligence', 50),\n",
    "        ('Data_science', 50),\n",
    "        ('Computer_networks', 40),\n",
    "        ('Databases', 40),\n",
    "        ('Cryptography', 40),\n",
    "        ('Operating_systems', 40),\n",
    "        ('Web_development', 40),\n",
    "        ('Cybersecurity', 40),\n",
    "        ('Computational_linguistics', 30),\n",
    "        ('Theoretical_computer_science', 30),\n",
    "        ('Computer_architecture', 30),\n",
    "        ('Distributed_computing', 30),\n",
    "        ('Cloud_computing', 30),\n",
    "        ('Quantum_computing', 30),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nCollecting URLs from {len(wiki_categories)} Wikipedia categories...\")\n",
    "    \n",
    "    for category, max_pages in wiki_categories:\n",
    "        if scraper.stats['saved'] >= 400:\n",
    "            break\n",
    "        \n",
    "        urls = scraper.scrape_wikipedia_category(category, max_pages=max_pages)\n",
    "        all_urls.extend(urls)\n",
    "    \n",
    "    print(f\"\\nTotal URLs collected: {len(all_urls)}\")\n",
    "    \n",
    "    # Scrape URLs\n",
    "    scraper.scrape_urls(all_urls, target=400)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    final_count = len(list(scraper.productive_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Productive samples: {final_count}\")\n",
    "    print(f\"Newly added: {scraper.stats['saved']}\")\n",
    "    print(f\"Filtered (too short): {scraper.stats['filtered']}\")\n",
    "    print(f\"Failed: {scraper.stats['failed']}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n✓ Dataset ready at: {scraper.base_dir}/productive/\")\n",
    "    print(\"  400 more productive samples collected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a8ef45d-cade-42cb-ba02-3cf401200a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ALTERNATIVE TEXT SCRAPER (Better than YouTube!)\n",
      "======================================================================\n",
      "\n",
      "Current productive: 1203\n",
      "Current unproductive: 1270\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: PRODUCTIVE CONTENT\n",
      "======================================================================\n",
      "\n",
      "[Medium] Scraping tag: machine-learning\n",
      "  Found 5 article URLs\n",
      "\n",
      "[Medium] Scraping tag: data-science\n",
      "  Found 5 article URLs\n",
      "\n",
      "[Medium] Scraping tag: programming\n",
      "  Found 8 article URLs\n",
      "\n",
      "[Medium] Scraping tag: artificial-intelligence\n",
      "  Found 5 article URLs\n",
      "\n",
      "[Medium] Scraping tag: python\n",
      "  Found 2 article URLs\n",
      "\n",
      "[Medium] Scraping tag: javascript\n",
      "  Found 8 article URLs\n",
      "\n",
      "[Medium] Scraping tag: web-development\n",
      "  Found 5 article URLs\n",
      "\n",
      "[Medium] Scraping tag: software-engineering\n",
      "  Found 5 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: python\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: javascript\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: webdev\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: machinelearning\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: datascience\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: programming\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: tutorial\n",
      "  Found 25 article URLs\n",
      "\n",
      "[Dev.to] Scraping tag: beginners\n",
      "  Found 25 article URLs\n",
      "\n",
      "[HackerNoon] Scraping topic: programming\n",
      "  Found 1 article URLs\n",
      "\n",
      "[HackerNoon] Scraping topic: machine-learning\n",
      "  Found 1 article URLs\n",
      "\n",
      "[HackerNoon] Scraping topic: blockchain\n",
      "  Found 0 article URLs\n",
      "\n",
      "[HackerNoon] Scraping topic: cybersecurity\n",
      "  Found 1 article URLs\n",
      "\n",
      "Total productive URLs collected: 246\n",
      "\n",
      "======================================================================\n",
      "Processing 246 URLs for: PRODUCTIVE\n",
      "Target: 400 samples\n",
      "======================================================================\n",
      "\n",
      "[1/246] ✗ Failed or too short\n",
      "[2/246] ✓ Saved: 1 | https://medium.com/@ignacio.de.gregorio.noblejas?s...\n",
      "[3/246] ✓ Saved: 2 | https://medium.com/@ignacio.de.gregorio.noblejas?s...\n",
      "[4/246] ✓ Saved: 3 | https://medium.com/@ignacio.de.gregorio.noblejas/a...\n",
      "[5/246] ✓ Saved: 4 | https://medium.com/@ignacio.de.gregorio.noblejas/a...\n",
      "[6/246] ✓ Saved: 5 | https://medium.com/@prithwish.nath?source=topic_po...\n",
      "[7/246] ✓ Saved: 6 | https://medium.com/@chrisperkins505?source=topic_p...\n",
      "[8/246] ✓ Saved: 7 | https://medium.com/@chrisperkins505?source=topic_p...\n",
      "[9/246] ✓ Saved: 8 | https://medium.com/@chrisperkins505/the-experience...\n",
      "[10/246] ✓ Saved: 9 | https://medium.com/@chrisperkins505/the-experience...\n",
      "[11/246] ✓ Saved: 10 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[12/246] ✓ Saved: 11 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[13/246] ✓ Saved: 12 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[14/246] ✓ Saved: 13 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[15/246] ✓ Saved: 14 | https://medium.com/@wlockett?source=topic_portal--...\n",
      "[16/246] ✓ Saved: 15 | https://medium.com/@wlockett?source=topic_portal--...\n",
      "[17/246] ✓ Saved: 16 | https://medium.com/@wlockett/the-godfather-of-ai-j...\n",
      "[18/246] ✓ Saved: 17 | https://medium.com/@wlockett/the-godfather-of-ai-j...\n",
      "[19/246] ✓ Saved: 18 | https://medium.com/@nickfthilton?source=topic_port...\n",
      "[20/246] ✓ Saved: 19 | https://medium.com/@nickfthilton?source=topic_port...\n",
      "[21/246] ✓ Saved: 20 | https://medium.com/@nickfthilton/the-tsunamai-are-...\n",
      "[22/246] ✓ Saved: 21 | https://medium.com/@nickfthilton/the-tsunamai-are-...\n",
      "[23/246] ✓ Saved: 22 | https://medium.com/@prithwish.nath?source=topic_po...\n",
      "[24/246] ✓ Saved: 23 | https://medium.com/@kuriko-iwai?source=topic_porta...\n",
      "[25/246] ✓ Saved: 24 | https://medium.com/@lee_vaughan?source=topic_porta...\n",
      "[26/246] ✓ Saved: 25 | https://medium.com/@fleker?source=topic_portal---r...\n",
      "[27/246] ✓ Saved: 26 | https://medium.com/@fleker?source=topic_portal---r...\n",
      "[28/246] ✓ Saved: 27 | https://medium.com/@fleker/gemini-api-and-structur...\n",
      "[29/246] ✓ Saved: 28 | https://medium.com/@fleker/gemini-api-and-structur...\n",
      "[30/246] ✓ Saved: 29 | https://medium.com/@tobrien?source=topic_portal---...\n",
      "[31/246] ✓ Saved: 30 | https://medium.com/@tobrien?source=topic_portal---...\n",
      "[32/246] ✓ Saved: 31 | https://medium.com/@tobrien/the-developers-laptop-...\n",
      "[33/246] ✓ Saved: 32 | https://medium.com/@tobrien/the-developers-laptop-...\n",
      "[34/246] ✓ Saved: 33 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[35/246] ✓ Saved: 34 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[36/246] ✓ Saved: 35 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[37/246] ✓ Saved: 36 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[38/246] ✓ Saved: 37 | https://medium.com/@bahulneel?source=topic_portal-...\n",
      "[39/246] ✓ Saved: 38 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[40/246] ✓ Saved: 39 | https://medium.com/@dimillian?source=topic_portal-...\n",
      "[41/246] ✓ Saved: 40 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[42/246] ✓ Saved: 41 | https://medium.com/@dimillian/does-the-code-matter...\n",
      "[43/246] ✓ Saved: 42 | https://medium.com/@alex-daubois?source=topic_port...\n",
      "[44/246] ✗ Failed or too short\n",
      "[45/246] ✗ Failed or too short\n",
      "[46/246] ✗ Failed or too short\n",
      "[47/246] ✗ Failed or too short\n",
      "[48/246] ✗ Failed or too short\n",
      "[49/246] ✗ Failed or too short\n",
      "[50/246] ✗ Failed or too short\n",
      "[51/246] ✗ Failed or too short\n",
      "[52/246] ✗ Failed or too short\n",
      "[53/246] ✗ Failed or too short\n",
      "[54/246] ✗ Failed or too short\n",
      "[55/246] ✗ Failed or too short\n",
      "[56/246] ✗ Failed or too short\n",
      "[57/246] ✗ Failed or too short\n",
      "[58/246] ✗ Failed or too short\n",
      "[59/246] ✗ Failed or too short\n",
      "[60/246] ✗ Failed or too short\n",
      "[61/246] ✗ Failed or too short\n",
      "[62/246] ✗ Failed or too short\n",
      "[63/246] ✗ Failed or too short\n",
      "[64/246] ✗ Failed or too short\n",
      "[65/246] ✗ Failed or too short\n",
      "[66/246] ✗ Failed or too short\n",
      "[67/246] ✗ Failed or too short\n",
      "[68/246] ✗ Failed or too short\n",
      "[69/246] ✗ Failed or too short\n",
      "[70/246] ✗ Failed or too short\n",
      "[71/246] ✗ Failed or too short\n",
      "[72/246] ✗ Failed or too short\n",
      "[73/246] ✗ Failed or too short\n",
      "[74/246] ✗ Failed or too short\n",
      "[75/246] ✗ Failed or too short\n",
      "[76/246] ✗ Failed or too short\n",
      "[77/246] ✗ Failed or too short\n",
      "[78/246] ✗ Failed or too short\n",
      "[79/246] ✗ Failed or too short\n",
      "[80/246] ✗ Failed or too short\n",
      "[81/246] ✗ Failed or too short\n",
      "[82/246] ✗ Failed or too short\n",
      "[83/246] ✗ Failed or too short\n",
      "[84/246] ✗ Failed or too short\n",
      "[85/246] ✗ Failed or too short\n",
      "[86/246] ✗ Failed or too short\n",
      "[87/246] ✗ Failed or too short\n",
      "[88/246] ✗ Failed or too short\n",
      "[89/246] ✗ Failed or too short\n",
      "[90/246] ✗ Failed or too short\n",
      "[91/246] ✗ Failed or too short\n",
      "[92/246] ✗ Failed or too short\n",
      "[93/246] ✗ Failed or too short\n",
      "[94/246] ✗ Failed or too short\n",
      "[95/246] ✗ Failed or too short\n",
      "[96/246] ✗ Failed or too short\n",
      "[97/246] ✗ Failed or too short\n",
      "[98/246] ✗ Failed or too short\n",
      "[99/246] ✗ Failed or too short\n",
      "[100/246] ✗ Failed or too short\n",
      "[101/246] ✗ Failed or too short\n",
      "[102/246] ✗ Failed or too short\n",
      "[103/246] ✗ Failed or too short\n",
      "[104/246] ✗ Failed or too short\n",
      "[105/246] ✗ Failed or too short\n",
      "[106/246] ✗ Failed or too short\n",
      "[107/246] ✗ Failed or too short\n",
      "[108/246] ✗ Failed or too short\n",
      "[109/246] ✗ Failed or too short\n",
      "[110/246] ✗ Failed or too short\n",
      "[111/246] ✗ Failed or too short\n",
      "[112/246] ✗ Failed or too short\n",
      "[113/246] ✗ Failed or too short\n",
      "[114/246] ✗ Failed or too short\n",
      "[115/246] ✗ Failed or too short\n",
      "[116/246] ✗ Failed or too short\n",
      "[117/246] ✗ Failed or too short\n",
      "[118/246] ✗ Failed or too short\n",
      "[119/246] ✗ Failed or too short\n",
      "[120/246] ✗ Failed or too short\n",
      "[121/246] ✗ Failed or too short\n",
      "[122/246] ✗ Failed or too short\n",
      "[123/246] ✗ Failed or too short\n",
      "[124/246] ✗ Failed or too short\n",
      "[125/246] ✗ Failed or too short\n",
      "[126/246] ✗ Failed or too short\n",
      "[127/246] ✗ Failed or too short\n",
      "[128/246] ✗ Failed or too short\n",
      "[129/246] ✗ Failed or too short\n",
      "[130/246] ✗ Failed or too short\n",
      "[131/246] ✗ Failed or too short\n",
      "[132/246] ✗ Failed or too short\n",
      "[133/246] ✗ Failed or too short\n",
      "[134/246] ✗ Failed or too short\n",
      "[135/246] ✗ Failed or too short\n",
      "[136/246] ✗ Failed or too short\n",
      "[137/246] ✗ Failed or too short\n",
      "[138/246] ✗ Failed or too short\n",
      "[139/246] ✗ Failed or too short\n",
      "[140/246] ✗ Failed or too short\n",
      "[141/246] ✗ Failed or too short\n",
      "[142/246] ✗ Failed or too short\n",
      "[143/246] ✗ Failed or too short\n",
      "[144/246] ✗ Failed or too short\n",
      "[145/246] ✗ Failed or too short\n",
      "[146/246] ✗ Failed or too short\n",
      "[147/246] ✗ Failed or too short\n",
      "[148/246] ✗ Failed or too short\n",
      "[149/246] ✗ Failed or too short\n",
      "[150/246] ✗ Failed or too short\n",
      "[151/246] ✗ Failed or too short\n",
      "[152/246] ✗ Failed or too short\n",
      "[153/246] ✗ Failed or too short\n",
      "[154/246] ✗ Failed or too short\n",
      "[155/246] ✗ Failed or too short\n",
      "[156/246] ✗ Failed or too short\n",
      "[157/246] ✗ Failed or too short\n",
      "[158/246] ✗ Failed or too short\n",
      "[159/246] ✗ Failed or too short\n",
      "[160/246] ✗ Failed or too short\n",
      "[161/246] ✗ Failed or too short\n",
      "[162/246] ✗ Failed or too short\n",
      "[163/246] ✗ Failed or too short\n",
      "[164/246] ✗ Failed or too short\n",
      "[165/246] ✗ Failed or too short\n",
      "[166/246] ✗ Failed or too short\n",
      "[167/246] ✗ Failed or too short\n",
      "[168/246] ✗ Failed or too short\n",
      "[169/246] ✗ Failed or too short\n",
      "[170/246] ✗ Failed or too short\n",
      "[171/246] ✗ Failed or too short\n",
      "[172/246] ✗ Failed or too short\n",
      "[173/246] ✗ Failed or too short\n",
      "[174/246] ✗ Failed or too short\n",
      "[175/246] ✗ Failed or too short\n",
      "[176/246] ✗ Failed or too short\n",
      "[177/246] ✗ Failed or too short\n",
      "[178/246] ✗ Failed or too short\n",
      "[179/246] ✗ Failed or too short\n",
      "[180/246] ✗ Failed or too short\n",
      "[181/246] ✗ Failed or too short\n",
      "[182/246] ✗ Failed or too short\n",
      "[183/246] ✗ Failed or too short\n",
      "[184/246] ✗ Failed or too short\n",
      "[185/246] ✗ Failed or too short\n",
      "[186/246] ✗ Failed or too short\n",
      "[187/246] ✗ Failed or too short\n",
      "[188/246] ✗ Failed or too short\n",
      "[189/246] ✗ Failed or too short\n",
      "[190/246] ✗ Failed or too short\n",
      "[191/246] ✗ Failed or too short\n",
      "[192/246] ✗ Failed or too short\n",
      "[193/246] ✗ Failed or too short\n",
      "[194/246] ✗ Failed or too short\n",
      "[195/246] ✗ Failed or too short\n",
      "[196/246] ✗ Failed or too short\n",
      "[197/246] ✗ Failed or too short\n",
      "[198/246] ✗ Failed or too short\n",
      "[199/246] ✗ Failed or too short\n",
      "[200/246] ✗ Failed or too short\n",
      "[201/246] ✗ Failed or too short\n",
      "[202/246] ✗ Failed or too short\n",
      "[203/246] ✗ Failed or too short\n",
      "[204/246] ✗ Failed or too short\n",
      "[205/246] ✗ Failed or too short\n",
      "[206/246] ✗ Failed or too short\n",
      "[207/246] ✗ Failed or too short\n",
      "[208/246] ✗ Failed or too short\n",
      "[209/246] ✗ Failed or too short\n",
      "[210/246] ✗ Failed or too short\n",
      "[211/246] ✗ Failed or too short\n",
      "[212/246] ✗ Failed or too short\n",
      "[213/246] ✗ Failed or too short\n",
      "[214/246] ✗ Failed or too short\n",
      "[215/246] ✗ Failed or too short\n",
      "[216/246] ✗ Failed or too short\n",
      "[217/246] ✗ Failed or too short\n",
      "[218/246] ✗ Failed or too short\n",
      "[219/246] ✗ Failed or too short\n",
      "[220/246] ✗ Failed or too short\n",
      "[221/246] ✗ Failed or too short\n",
      "[222/246] ✗ Failed or too short\n",
      "[223/246] ✗ Failed or too short\n",
      "[224/246] ✗ Failed or too short\n",
      "[225/246] ✗ Failed or too short\n",
      "[226/246] ✗ Failed or too short\n",
      "[227/246] ✗ Failed or too short\n",
      "[228/246] ✗ Failed or too short\n",
      "[229/246] ✗ Failed or too short\n",
      "[230/246] ✗ Failed or too short\n",
      "[231/246] ✗ Failed or too short\n",
      "[232/246] ✗ Failed or too short\n",
      "[233/246] ✗ Failed or too short\n",
      "[234/246] ✗ Failed or too short\n",
      "[235/246] ✗ Failed or too short\n",
      "[236/246] ✗ Failed or too short\n",
      "[237/246] ✗ Failed or too short\n",
      "[238/246] ✗ Failed or too short\n",
      "[239/246] ✗ Failed or too short\n",
      "[240/246] ✗ Failed or too short\n",
      "[241/246] ✗ Failed or too short\n",
      "[242/246] ✗ Failed or too short\n",
      "[243/246] ✗ Failed or too short\n",
      "[244/246] ✓ Saved: 43 | https://hackernoon.com/c/programming...\n",
      "[245/246] ✓ Saved: 44 | https://hackernoon.com/c/machine-learning...\n",
      "[246/246] ✓ Saved: 45 | https://hackernoon.com/c/cybersecurity...\n",
      "\n",
      "======================================================================\n",
      "PRODUCTIVE Summary: 45 saved, 201 failed\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: UNPRODUCTIVE CONTENT\n",
      "======================================================================\n",
      "\n",
      "[BuzzFeed] Scraping trending\n",
      "  Found 43 article URLs\n",
      "\n",
      "[9GAG] Scraping hot\n",
      "  Found 0 text posts\n",
      "\n",
      "Total unproductive items collected: 43\n",
      "\n",
      "======================================================================\n",
      "Processing 43 URLs for: UNPRODUCTIVE\n",
      "Target: 400 samples\n",
      "======================================================================\n",
      "\n",
      "[1/43] ✓ Saved: 1 | https://www.buzzfeed.com?origin=tb...\n",
      "[2/43] ✓ Saved: 2 | https://www.buzzfeed.com/in/quizzes...\n",
      "[3/43] ✓ Saved: 3 | https://www.buzzfeed.com/in/tvandmovies...\n",
      "[4/43] ✓ Saved: 4 | https://www.buzzfeed.com/in/shopping...\n",
      "[5/43] ✓ Saved: 5 | https://www.buzzfeed.com/in/quizzes...\n",
      "[6/43] ✓ Saved: 6 | https://www.buzzfeed.com/in/tvandmovies...\n",
      "[7/43] ✓ Saved: 7 | https://www.buzzfeed.com/in/shopping...\n",
      "[8/43] ✗ Failed or too short\n",
      "[9/43] ✓ Saved: 8 | https://www.buzzfeed.com/in/lol...\n",
      "[10/43] ✓ Saved: 9 | https://www.buzzfeed.com/in/wtf...\n",
      "[11/43] ✓ Saved: 10 | https://www.buzzfeed.com/in/omg...\n",
      "[12/43] ✓ Saved: 11 | https://www.buzzfeed.com/in/cute...\n",
      "[13/43] ✗ Failed or too short\n",
      "[14/43] ✓ Saved: 12 | https://www.buzzfeed.com/in/tvandmovies...\n",
      "[15/43] ✓ Saved: 13 | https://www.buzzfeed.com/in/celebrity...\n",
      "[16/43] ✓ Saved: 14 | https://www.buzzfeed.com/in/bestoftheinternet...\n",
      "[17/43] ✓ Saved: 15 | https://www.buzzfeed.com/tag/animals...\n",
      "[18/43] ✓ Saved: 16 | https://www.buzzfeed.com/in/music...\n",
      "[19/43] ✓ Saved: 17 | https://www.buzzfeed.com/in/rewind...\n",
      "[20/43] ✓ Saved: 18 | https://www.buzzfeed.com/in/books...\n",
      "[21/43] ✓ Saved: 19 | https://www.buzzfeed.com/in/quizzes...\n",
      "[22/43] ✓ Saved: 20 | https://www.buzzfeed.com/in/quizzes...\n",
      "[23/43] ✓ Saved: 21 | https://www.buzzfeed.com/in/trending/quizzes...\n",
      "[24/43] ✓ Saved: 22 | https://www.buzzfeed.com/in/quizzes/food...\n",
      "[25/43] ✓ Saved: 23 | https://www.buzzfeed.com/in/quizzes/love...\n",
      "[26/43] ✓ Saved: 24 | https://www.buzzfeed.com/in/quizzes/trivia...\n",
      "[27/43] ✗ Failed or too short\n",
      "[28/43] ✓ Saved: 25 | https://www.buzzfeed.com/travel...\n",
      "[29/43] ✓ Saved: 26 | https://www.buzzfeed.com/in/goodful...\n",
      "[30/43] ✓ Saved: 27 | https://www.buzzfeed.com/in/parents...\n",
      "[31/43] ✓ Saved: 28 | https://www.buzzfeed.com/in/food...\n",
      "[32/43] ✓ Saved: 29 | https://www.buzzfeed.com/in/weddings...\n",
      "[33/43] ✓ Saved: 30 | https://www.buzzfeed.com/community...\n",
      "[34/43] ✓ Saved: 31 | https://www.buzzfeed.com/community/contribute...\n",
      "[35/43] ✓ Saved: 32 | https://www.buzzfeed.com/community...\n",
      "[36/43] ✓ Saved: 33 | https://www.buzzfeed.com/community/leaderboard...\n",
      "[37/43] ✓ Saved: 34 | https://www.buzzfeed.com/about/jobs...\n",
      "[38/43] ✓ Saved: 35 | https://www.buzzfeed.com/about/privacy...\n",
      "[39/43] ✓ Saved: 36 | https://www.buzzfeed.com/consent-preferences...\n",
      "[40/43] ✓ Saved: 37 | https://www.buzzfeed.com/about/useragreement...\n",
      "[41/43] ✓ Saved: 38 | https://www.buzzfeed.com/about/privacy#adchoices...\n",
      "[42/43] ✓ Saved: 39 | https://www.buzzfeed.com/about/contact...\n",
      "[43/43] ✓ Saved: 40 | https://www.buzzfeed.com/archive...\n",
      "\n",
      "======================================================================\n",
      "UNPRODUCTIVE Summary: 40 saved, 3 failed\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY\n",
      "======================================================================\n",
      "Productive: 1248 (added 45)\n",
      "Unproductive: 1310 (added 40)\n",
      "Total: 2558\n",
      "======================================================================\n",
      "\n",
      "✓ Dataset complete! No YouTube transcripts needed.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "class AlternativeTextScraper:\n",
    "    def __init__(self, base_dir=\"dataset\", min_words=50, delay=(1, 2)):\n",
    "        self.base_dir = base_dir\n",
    "        self.min_words = min_words\n",
    "        self.delay = delay\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        self.productive_dir = Path(base_dir) / \"productive\"\n",
    "        self.unproductive_dir = Path(base_dir) / \"unproductive\"\n",
    "        self.productive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.unproductive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.stats = {\n",
    "            'productive': {'saved': 0, 'failed': 0},\n",
    "            'unproductive': {'saved': 0, 'failed': 0}\n",
    "        }\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\\\"]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def get_next_index(self, category):\n",
    "        directory = self.productive_dir if category == 'productive' else self.unproductive_dir\n",
    "        files = list(directory.glob(\"*.txt\"))\n",
    "        if not files:\n",
    "            return 1\n",
    "        numbers = [int(re.match(r'(\\d+)\\.txt', f.name).group(1)) \n",
    "                   for f in files if re.match(r'(\\d+)\\.txt', f.name)]\n",
    "        return max(numbers) + 1 if numbers else 1\n",
    "    \n",
    "    def save_text(self, text, category):\n",
    "        directory = self.productive_dir if category == 'productive' else self.unproductive_dir\n",
    "        idx = self.get_next_index(category)\n",
    "        filename = directory / f\"{idx:05d}.txt\"\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        self.stats[category]['saved'] += 1\n",
    "        return filename\n",
    "    \n",
    "    def fetch_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PRODUCTIVE SOURCES\n",
    "    # =========================================================================\n",
    "    \n",
    "    def scrape_medium_tech(self, tag, max_articles=100):\n",
    "        \"\"\"Scrape Medium tech articles\"\"\"\n",
    "        print(f\"\\n[Medium] Scraping tag: {tag}\")\n",
    "        articles = []\n",
    "        \n",
    "        url = f\"https://medium.com/tag/{tag}\"\n",
    "        html = self.fetch_url(url)\n",
    "        \n",
    "        if not html:\n",
    "            return articles\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        article_links = soup.find_all('a', href=True)\n",
    "        \n",
    "        for link in article_links[:max_articles]:\n",
    "            href = link['href']\n",
    "            if '/p/' in href or '@' in href:\n",
    "                full_url = f\"https://medium.com{href}\" if href.startswith('/') else href\n",
    "                articles.append(full_url)\n",
    "        \n",
    "        print(f\"  Found {len(articles)} article URLs\")\n",
    "        return articles\n",
    "    \n",
    "    def scrape_dev_to(self, tag, max_articles=100):\n",
    "        \"\"\"Scrape Dev.to articles\"\"\"\n",
    "        print(f\"\\n[Dev.to] Scraping tag: {tag}\")\n",
    "        articles = []\n",
    "        \n",
    "        url = f\"https://dev.to/t/{tag}\"\n",
    "        html = self.fetch_url(url)\n",
    "        \n",
    "        if not html:\n",
    "            return articles\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        article_divs = soup.find_all('div', class_='crayons-story')\n",
    "        \n",
    "        for div in article_divs[:max_articles]:\n",
    "            link = div.find('a', class_='crayons-story__hidden-navigation-link')\n",
    "            if link and link.get('href'):\n",
    "                articles.append(f\"https://dev.to{link['href']}\")\n",
    "        \n",
    "        print(f\"  Found {len(articles)} article URLs\")\n",
    "        return articles\n",
    "    \n",
    "    def scrape_hackernoon(self, topic, max_articles=50):\n",
    "        \"\"\"Scrape HackerNoon articles\"\"\"\n",
    "        print(f\"\\n[HackerNoon] Scraping topic: {topic}\")\n",
    "        articles = []\n",
    "        \n",
    "        url = f\"https://hackernoon.com/tagged/{topic}\"\n",
    "        html = self.fetch_url(url)\n",
    "        \n",
    "        if not html:\n",
    "            return articles\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        links = soup.find_all('a', href=True)\n",
    "        \n",
    "        for link in links[:max_articles]:\n",
    "            href = link['href']\n",
    "            if href.startswith('/') and len(href) > 10:\n",
    "                articles.append(f\"https://hackernoon.com{href}\")\n",
    "        \n",
    "        print(f\"  Found {len(articles)} article URLs\")\n",
    "        return articles\n",
    "    \n",
    "    # =========================================================================\n",
    "    # UNPRODUCTIVE SOURCES\n",
    "    # =========================================================================\n",
    "    \n",
    "    def scrape_buzzfeed(self, max_articles=100):\n",
    "        \"\"\"Scrape BuzzFeed articles\"\"\"\n",
    "        print(f\"\\n[BuzzFeed] Scraping trending\")\n",
    "        articles = []\n",
    "        \n",
    "        url = \"https://www.buzzfeed.com/trending\"\n",
    "        html = self.fetch_url(url)\n",
    "        \n",
    "        if not html:\n",
    "            return articles\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        links = soup.find_all('a', href=True)\n",
    "        \n",
    "        for link in links[:max_articles]:\n",
    "            href = link['href']\n",
    "            if 'buzzfeed.com' in href and len(href) > 30:\n",
    "                articles.append(href)\n",
    "        \n",
    "        print(f\"  Found {len(articles)} article URLs\")\n",
    "        return articles\n",
    "    \n",
    "    def scrape_9gag_text(self, section='hot', max_posts=50):\n",
    "        \"\"\"Scrape 9GAG post titles and descriptions\"\"\"\n",
    "        print(f\"\\n[9GAG] Scraping {section}\")\n",
    "        texts = []\n",
    "        \n",
    "        url = f\"https://9gag.com/{section}\"\n",
    "        html = self.fetch_url(url)\n",
    "        \n",
    "        if not html:\n",
    "            return texts\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        posts = soup.find_all('article')\n",
    "        \n",
    "        for post in posts[:max_posts]:\n",
    "            title_elem = post.find('h1')\n",
    "            desc_elem = post.find('p')\n",
    "            \n",
    "            title = title_elem.get_text(strip=True) if title_elem else \"\"\n",
    "            desc = desc_elem.get_text(strip=True) if desc_elem else \"\"\n",
    "            \n",
    "            combined = f\"{title}. {desc}\".strip()\n",
    "            if len(combined.split()) >= self.min_words:\n",
    "                texts.append(combined)\n",
    "        \n",
    "        print(f\"  Found {len(texts)} text posts\")\n",
    "        return texts\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GENERIC SCRAPING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def extract_article_text(self, url):\n",
    "        \"\"\"Extract main article text from any URL\"\"\"\n",
    "        html = self.fetch_url(url)\n",
    "        if not html:\n",
    "            return None\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Remove unwanted elements\n",
    "        for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe', 'form', 'button']):\n",
    "            tag.decompose()\n",
    "        \n",
    "        # Try common article selectors\n",
    "        selectors = ['article', 'main', '.post-content', '.entry-content', '.article-content', '.story-body']\n",
    "        \n",
    "        text = \"\"\n",
    "        for selector in selectors:\n",
    "            elements = soup.select(selector) if selector.startswith(('.', '#')) else soup.find_all(selector)\n",
    "            if elements:\n",
    "                text = ' '.join([elem.get_text(separator=' ', strip=True) for elem in elements])\n",
    "                break\n",
    "        \n",
    "        if not text:\n",
    "            body = soup.find('body')\n",
    "            text = body.get_text(separator=' ', strip=True) if body else \"\"\n",
    "        \n",
    "        return self.clean_text(text)\n",
    "    \n",
    "    def scrape_urls(self, urls, category, target=None):\n",
    "        \"\"\"Scrape list of URLs and save\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Processing {len(urls)} URLs for: {category.upper()}\")\n",
    "        if target:\n",
    "            print(f\"Target: {target} samples\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, item in enumerate(urls, 1):\n",
    "            if target and self.stats[category]['saved'] >= target:\n",
    "                print(f\"\\n✓ Target reached!\")\n",
    "                break\n",
    "            \n",
    "            # Check if it's a URL or direct text\n",
    "            if isinstance(item, str) and item.startswith('http'):\n",
    "                text = self.extract_article_text(item)\n",
    "                if text and len(text.split()) >= self.min_words:\n",
    "                    self.save_text(text, category)\n",
    "                    print(f\"[{i}/{len(urls)}] ✓ Saved: {self.stats[category]['saved']} | {item[:50]}...\")\n",
    "                else:\n",
    "                    self.stats[category]['failed'] += 1\n",
    "                    print(f\"[{i}/{len(urls)}] ✗ Failed or too short\")\n",
    "            else:\n",
    "                # Direct text\n",
    "                if len(item.split()) >= self.min_words:\n",
    "                    self.save_text(item, category)\n",
    "                    print(f\"[{i}/{len(urls)}] ✓ Saved: {self.stats[category]['saved']} | Direct text\")\n",
    "                else:\n",
    "                    self.stats[category]['failed'] += 1\n",
    "            \n",
    "            time.sleep(random.uniform(*self.delay))\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{category.upper()} Summary: {self.stats[category]['saved']} saved, {self.stats[category]['failed']} failed\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = AlternativeTextScraper(\n",
    "        base_dir=r\"C:\\my_notebook\\eda\\dataset\",\n",
    "        min_words=50,\n",
    "        delay=(1, 2)\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ALTERNATIVE TEXT SCRAPER (Better than YouTube!)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Current counts\n",
    "    current_prod = len(list(scraper.productive_dir.glob(\"*.txt\")))\n",
    "    current_unprod = len(list(scraper.unproductive_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    print(f\"\\nCurrent productive: {current_prod}\")\n",
    "    print(f\"Current unproductive: {current_unprod}\")\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # PRODUCTIVE CONTENT\n",
    "    # ==========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 1: PRODUCTIVE CONTENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    productive_urls = []\n",
    "    \n",
    "    # Medium tech articles\n",
    "    medium_tags = ['machine-learning', 'data-science', 'programming', 'artificial-intelligence', \n",
    "                   'python', 'javascript', 'web-development', 'software-engineering']\n",
    "    for tag in medium_tags:\n",
    "        urls = scraper.scrape_medium_tech(tag, max_articles=30)\n",
    "        productive_urls.extend(urls)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Dev.to articles\n",
    "    devto_tags = ['python', 'javascript', 'webdev', 'machinelearning', 'datascience', \n",
    "                  'programming', 'tutorial', 'beginners']\n",
    "    for tag in devto_tags:\n",
    "        urls = scraper.scrape_dev_to(tag, max_articles=30)\n",
    "        productive_urls.extend(urls)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # HackerNoon\n",
    "    hackernoon_topics = ['programming', 'machine-learning', 'blockchain', 'cybersecurity']\n",
    "    for topic in hackernoon_topics:\n",
    "        urls = scraper.scrape_hackernoon(topic, max_articles=20)\n",
    "        productive_urls.extend(urls)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"\\nTotal productive URLs collected: {len(productive_urls)}\")\n",
    "    scraper.scrape_urls(productive_urls, 'productive', target=400)\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # UNPRODUCTIVE CONTENT\n",
    "    # ==========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 2: UNPRODUCTIVE CONTENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    unproductive_sources = []\n",
    "    \n",
    "    # BuzzFeed\n",
    "    buzzfeed_urls = scraper.scrape_buzzfeed(max_articles=100)\n",
    "    unproductive_sources.extend(buzzfeed_urls)\n",
    "    \n",
    "    # 9GAG text posts\n",
    "    gag_texts = scraper.scrape_9gag_text('hot', max_posts=50)\n",
    "    unproductive_sources.extend(gag_texts)\n",
    "    \n",
    "    print(f\"\\nTotal unproductive items collected: {len(unproductive_sources)}\")\n",
    "    scraper.scrape_urls(unproductive_sources, 'unproductive', target=400)\n",
    "    \n",
    "    # ==========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ==========================================================================\n",
    "    \n",
    "    final_prod = len(list(scraper.productive_dir.glob(\"*.txt\")))\n",
    "    final_unprod = len(list(scraper.unproductive_dir.glob(\"*.txt\")))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Productive: {final_prod} (added {final_prod - current_prod})\")\n",
    "    print(f\"Unproductive: {final_unprod} (added {final_unprod - current_unprod})\")\n",
    "    print(f\"Total: {final_prod + final_unprod}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n✓ Dataset complete! No YouTube transcripts needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b521ecb-dd7b-473c-b114-e01ba712ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "YOUTUBE METADATA SCRAPER\n",
      "(Title + Description + Comments)\n",
      "======================================================================\n",
      "\n",
      "Current productive samples: 1248\n",
      "Current unproductive samples: 1310\n",
      "Target per class: 500 videos\n",
      "\n",
      "Method: Using YouTube Data API (more reliable)\n",
      "Includes: Title + Description + Top 20 Comments\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: PRODUCTIVE VIDEOS\n",
      "======================================================================\n",
      "Found 306 productive video IDs\n",
      "\n",
      "[1/306] ✓ Saved: 01249.txt (56 words) | Total: 1\n",
      "[2/306] ✓ Saved: 01250.txt (334 words) | Total: 2\n",
      "[3/306] ✓ Saved: 01251.txt (231 words) | Total: 3\n",
      "[4/306] ✓ Saved: 01252.txt (410 words) | Total: 4\n",
      "[5/306] ✓ Saved: 01253.txt (272 words) | Total: 5\n",
      "[6/306] ✓ Saved: 01254.txt (210 words) | Total: 6\n",
      "[7/306] ✓ Saved: 01255.txt (215 words) | Total: 7\n",
      "[8/306] ✓ Saved: 01256.txt (316 words) | Total: 8\n",
      "[9/306] ✓ Saved: 01257.txt (260 words) | Total: 9\n",
      "[10/306] ✓ Saved: 01258.txt (139 words) | Total: 10\n",
      "[11/306] ✓ Saved: 01259.txt (182 words) | Total: 11\n",
      "[12/306] ✓ Saved: 01260.txt (377 words) | Total: 12\n",
      "[13/306] ✓ Saved: 01261.txt (856 words) | Total: 13\n",
      "[14/306] ✓ Saved: 01262.txt (204 words) | Total: 14\n",
      "[15/306] ✗ Skipped JfYrlKw12jk: too short (8 words)\n",
      "[16/306] ✓ Saved: 01263.txt (256 words) | Total: 15\n",
      "[17/306] ✓ Saved: 01264.txt (213 words) | Total: 16\n",
      "[18/306] ✓ Saved: 01265.txt (140 words) | Total: 17\n",
      "[19/306] ✓ Saved: 01266.txt (256 words) | Total: 18\n",
      "[20/306] ✗ Skipped hpIrLFJgMmQ: too short (16 words)\n",
      "[21/306] ✓ Saved: 01267.txt (188 words) | Total: 19\n",
      "[22/306] ✓ Saved: 01268.txt (384 words) | Total: 20\n",
      "[23/306] ✓ Saved: 01269.txt (305 words) | Total: 21\n",
      "[24/306] ✓ Saved: 01270.txt (268 words) | Total: 22\n",
      "[25/306] ✓ Saved: 01271.txt (218 words) | Total: 23\n",
      "[26/306] ✓ Saved: 01272.txt (167 words) | Total: 24\n",
      "[27/306] ✓ Saved: 01273.txt (356 words) | Total: 25\n",
      "[28/306] ✓ Saved: 01274.txt (122 words) | Total: 26\n",
      "[29/306] ✓ Saved: 01275.txt (195 words) | Total: 27\n",
      "[30/306] ✓ Saved: 01276.txt (184 words) | Total: 28\n",
      "[31/306] ✓ Saved: 01277.txt (243 words) | Total: 29\n",
      "[32/306] ✓ Saved: 01278.txt (270 words) | Total: 30\n",
      "[33/306] ✓ Saved: 01279.txt (220 words) | Total: 31\n",
      "[34/306] ✓ Saved: 01280.txt (320 words) | Total: 32\n",
      "[35/306] ✓ Saved: 01281.txt (633 words) | Total: 33\n",
      "[36/306] ✓ Saved: 01282.txt (602 words) | Total: 34\n",
      "[37/306] ✓ Saved: 01283.txt (190 words) | Total: 35\n",
      "[38/306] ✓ Saved: 01284.txt (129 words) | Total: 36\n",
      "[39/306] ✓ Saved: 01285.txt (296 words) | Total: 37\n",
      "[40/306] ✓ Saved: 01286.txt (247 words) | Total: 38\n",
      "[41/306] ✓ Saved: 01287.txt (150 words) | Total: 39\n",
      "[42/306] ✓ Saved: 01288.txt (349 words) | Total: 40\n",
      "[43/306] ✓ Saved: 01289.txt (911 words) | Total: 41\n",
      "[44/306] ✓ Saved: 01290.txt (990 words) | Total: 42\n",
      "[45/306] ✓ Saved: 01291.txt (471 words) | Total: 43\n",
      "[46/306] ✗ Skipped iLZl4Mar6Yw: too short (12 words)\n",
      "[47/306] ✓ Saved: 01292.txt (219 words) | Total: 44\n",
      "[48/306] ✓ Saved: 01293.txt (277 words) | Total: 45\n",
      "[49/306] ✓ Saved: 01294.txt (208 words) | Total: 46\n",
      "[50/306] ✓ Saved: 01295.txt (164 words) | Total: 47\n",
      "[51/306] ✗ Skipped _BHjXykHhYU: too short (49 words)\n",
      "[52/306] ✗ Skipped XcpTgxDEe6w: too short (36 words)\n",
      "[53/306] ✓ Saved: 01296.txt (55 words) | Total: 48\n",
      "[54/306] ✓ Saved: 01297.txt (69 words) | Total: 49\n",
      "[55/306] ✓ Saved: 01298.txt (69 words) | Total: 50\n",
      "[56/306] ✗ Skipped Q_lXws-cBHA: too short (49 words)\n",
      "[57/306] ✓ Saved: 01299.txt (60 words) | Total: 51\n",
      "[58/306] ✓ Saved: 01300.txt (515 words) | Total: 52\n",
      "[59/306] ✗ Skipped OYed3yy9Ouo: too short (11 words)\n",
      "[60/306] ✓ Saved: 01301.txt (228 words) | Total: 53\n",
      "[61/306] ✓ Saved: 01302.txt (97 words) | Total: 54\n",
      "[62/306] ✓ Saved: 01303.txt (836 words) | Total: 55\n",
      "[63/306] ✓ Saved: 01304.txt (130 words) | Total: 56\n",
      "[64/306] ✓ Saved: 01305.txt (405 words) | Total: 57\n",
      "[65/306] ✓ Saved: 01306.txt (117 words) | Total: 58\n",
      "[66/306] ✓ Saved: 01307.txt (122 words) | Total: 59\n",
      "[67/306] ✓ Saved: 01308.txt (162 words) | Total: 60\n",
      "[68/306] ✓ Saved: 01309.txt (146 words) | Total: 61\n",
      "[69/306] ✓ Saved: 01310.txt (64 words) | Total: 62\n",
      "[70/306] ✓ Saved: 01311.txt (229 words) | Total: 63\n",
      "[71/306] ✓ Saved: 01312.txt (79 words) | Total: 64\n",
      "[72/306] ✓ Saved: 01313.txt (104 words) | Total: 65\n",
      "[73/306] ✓ Saved: 01314.txt (197 words) | Total: 66\n",
      "[74/306] ✓ Saved: 01315.txt (687 words) | Total: 67\n",
      "[75/306] ✓ Saved: 01316.txt (207 words) | Total: 68\n",
      "[76/306] ✓ Saved: 01317.txt (159 words) | Total: 69\n",
      "[77/306] ✓ Saved: 01318.txt (76 words) | Total: 70\n",
      "[78/306] ✗ Skipped KgwNYI8iv4I: too short (16 words)\n",
      "[79/306] ✗ Skipped H_bsQyNlaX0: too short (26 words)\n",
      "[80/306] ✓ Saved: 01319.txt (317 words) | Total: 71\n",
      "[81/306] ✓ Saved: 01320.txt (177 words) | Total: 72\n",
      "[82/306] ✓ Saved: 01321.txt (387 words) | Total: 73\n",
      "[83/306] ✓ Saved: 01322.txt (775 words) | Total: 74\n",
      "[84/306] ✓ Saved: 01323.txt (191 words) | Total: 75\n",
      "[85/306] ✓ Saved: 01324.txt (148 words) | Total: 76\n",
      "[86/306] ✓ Saved: 01325.txt (69 words) | Total: 77\n",
      "[87/306] ✓ Saved: 01326.txt (349 words) | Total: 78\n",
      "[88/306] ✓ Saved: 01327.txt (243 words) | Total: 79\n",
      "[89/306] ✗ Skipped Ci7emFkN7Zc: too short (11 words)\n",
      "[90/306] ✓ Saved: 01328.txt (101 words) | Total: 80\n",
      "[91/306] ✓ Saved: 01329.txt (342 words) | Total: 81\n",
      "[92/306] ✗ Skipped qFTWNgrJmEY: too short (11 words)\n",
      "[93/306] ✓ Saved: 01330.txt (360 words) | Total: 82\n",
      "[94/306] ✓ Saved: 01331.txt (159 words) | Total: 83\n",
      "[95/306] ✓ Saved: 01332.txt (75 words) | Total: 84\n",
      "[96/306] ✓ Saved: 01333.txt (455 words) | Total: 85\n",
      "[97/306] ✓ Saved: 01334.txt (233 words) | Total: 86\n",
      "[98/306] ✓ Saved: 01335.txt (153 words) | Total: 87\n",
      "[99/306] ✓ Saved: 01336.txt (151 words) | Total: 88\n",
      "[100/306] ✓ Saved: 01337.txt (149 words) | Total: 89\n",
      "[101/306] ✓ Saved: 01338.txt (456 words) | Total: 90\n",
      "[102/306] ✓ Saved: 01339.txt (1091 words) | Total: 91\n",
      "[103/306] ✓ Saved: 01340.txt (1473 words) | Total: 92\n",
      "[104/306] ✓ Saved: 01341.txt (1110 words) | Total: 93\n",
      "[105/306] ✓ Saved: 01342.txt (418 words) | Total: 94\n",
      "[106/306] ✓ Saved: 01343.txt (201 words) | Total: 95\n",
      "[107/306] ✓ Saved: 01344.txt (626 words) | Total: 96\n",
      "[108/306] ✓ Saved: 01345.txt (573 words) | Total: 97\n",
      "[109/306] ✓ Saved: 01346.txt (1372 words) | Total: 98\n",
      "[110/306] ✓ Saved: 01347.txt (458 words) | Total: 99\n",
      "[111/306] ✓ Saved: 01348.txt (421 words) | Total: 100\n",
      "[112/306] ✓ Saved: 01349.txt (490 words) | Total: 101\n",
      "[113/306] ✓ Saved: 01350.txt (661 words) | Total: 102\n",
      "[114/306] ✓ Saved: 01351.txt (258 words) | Total: 103\n",
      "[115/306] ✓ Saved: 01352.txt (310 words) | Total: 104\n",
      "[116/306] ✓ Saved: 01353.txt (616 words) | Total: 105\n",
      "[117/306] ✓ Saved: 01354.txt (450 words) | Total: 106\n",
      "[118/306] ✓ Saved: 01355.txt (559 words) | Total: 107\n",
      "[119/306] ✓ Saved: 01356.txt (252 words) | Total: 108\n",
      "[120/306] ✓ Saved: 01357.txt (305 words) | Total: 109\n",
      "[121/306] ✓ Saved: 01358.txt (527 words) | Total: 110\n",
      "[122/306] ✓ Saved: 01359.txt (817 words) | Total: 111\n",
      "[123/306] ✓ Saved: 01360.txt (417 words) | Total: 112\n",
      "[124/306] ✓ Saved: 01361.txt (431 words) | Total: 113\n",
      "[125/306] ✓ Saved: 01362.txt (244 words) | Total: 114\n",
      "[126/306] ✓ Saved: 01363.txt (403 words) | Total: 115\n",
      "[127/306] ✓ Saved: 01364.txt (147 words) | Total: 116\n",
      "[128/306] ✓ Saved: 01365.txt (225 words) | Total: 117\n",
      "[129/306] ✓ Saved: 01366.txt (460 words) | Total: 118\n",
      "[130/306] ✓ Saved: 01367.txt (528 words) | Total: 119\n",
      "[131/306] ✓ Saved: 01368.txt (131 words) | Total: 120\n",
      "[132/306] ✓ Saved: 01369.txt (610 words) | Total: 121\n",
      "[133/306] ✓ Saved: 01370.txt (368 words) | Total: 122\n",
      "[134/306] ✓ Saved: 01371.txt (301 words) | Total: 123\n",
      "[135/306] ✓ Saved: 01372.txt (645 words) | Total: 124\n",
      "[136/306] ✓ Saved: 01373.txt (382 words) | Total: 125\n",
      "[137/306] ✓ Saved: 01374.txt (575 words) | Total: 126\n",
      "[138/306] ✓ Saved: 01375.txt (339 words) | Total: 127\n",
      "[139/306] ✓ Saved: 01376.txt (366 words) | Total: 128\n",
      "[140/306] ✓ Saved: 01377.txt (2728 words) | Total: 129\n",
      "[141/306] ✓ Saved: 01378.txt (526 words) | Total: 130\n",
      "[142/306] ✓ Saved: 01379.txt (164 words) | Total: 131\n",
      "[143/306] ✓ Saved: 01380.txt (187 words) | Total: 132\n",
      "[144/306] ✓ Saved: 01381.txt (1128 words) | Total: 133\n",
      "[145/306] ✓ Saved: 01382.txt (82 words) | Total: 134\n",
      "[146/306] ✓ Saved: 01383.txt (117 words) | Total: 135\n",
      "[147/306] ✓ Saved: 01384.txt (69 words) | Total: 136\n",
      "[148/306] ✓ Saved: 01385.txt (560 words) | Total: 137\n",
      "[149/306] ✓ Saved: 01386.txt (348 words) | Total: 138\n",
      "[150/306] ✓ Saved: 01387.txt (373 words) | Total: 139\n",
      "[151/306] ✓ Saved: 01388.txt (1107 words) | Total: 140\n",
      "[152/306] ✓ Saved: 01389.txt (466 words) | Total: 141\n",
      "[153/306] ✓ Saved: 01390.txt (717 words) | Total: 142\n",
      "[154/306] ✓ Saved: 01391.txt (1281 words) | Total: 143\n",
      "[155/306] ✓ Saved: 01392.txt (623 words) | Total: 144\n",
      "[156/306] ✓ Saved: 01393.txt (2100 words) | Total: 145\n",
      "[157/306] ✓ Saved: 01394.txt (1128 words) | Total: 146\n",
      "[158/306] ✓ Saved: 01395.txt (569 words) | Total: 147\n",
      "[159/306] ✓ Saved: 01396.txt (982 words) | Total: 148\n",
      "[160/306] ✓ Saved: 01397.txt (512 words) | Total: 149\n",
      "[161/306] ✓ Saved: 01398.txt (751 words) | Total: 150\n",
      "[162/306] ✓ Saved: 01399.txt (737 words) | Total: 151\n",
      "[163/306] ✓ Saved: 01400.txt (746 words) | Total: 152\n",
      "[164/306] ✓ Saved: 01401.txt (1086 words) | Total: 153\n",
      "[165/306] ✓ Saved: 01402.txt (1100 words) | Total: 154\n",
      "[166/306] ✓ Saved: 01403.txt (780 words) | Total: 155\n",
      "[167/306] ✓ Saved: 01404.txt (831 words) | Total: 156\n",
      "[168/306] ✓ Saved: 01405.txt (845 words) | Total: 157\n",
      "[169/306] ✓ Saved: 01406.txt (1090 words) | Total: 158\n",
      "[170/306] ✓ Saved: 01407.txt (1136 words) | Total: 159\n",
      "[171/306] ✓ Saved: 01408.txt (905 words) | Total: 160\n",
      "[172/306] ✓ Saved: 01409.txt (614 words) | Total: 161\n",
      "[173/306] ✓ Saved: 01410.txt (850 words) | Total: 162\n",
      "[174/306] ✓ Saved: 01411.txt (1202 words) | Total: 163\n",
      "[175/306] ✓ Saved: 01412.txt (885 words) | Total: 164\n",
      "[176/306] ✓ Saved: 01413.txt (1234 words) | Total: 165\n",
      "[177/306] ✓ Saved: 01414.txt (1797 words) | Total: 166\n",
      "[178/306] ✓ Saved: 01415.txt (650 words) | Total: 167\n",
      "[179/306] ✓ Saved: 01416.txt (665 words) | Total: 168\n",
      "[180/306] ✓ Saved: 01417.txt (1586 words) | Total: 169\n",
      "[181/306] ✓ Saved: 01418.txt (1169 words) | Total: 170\n",
      "[182/306] ✓ Saved: 01419.txt (2021 words) | Total: 171\n",
      "[183/306] ✓ Saved: 01420.txt (1640 words) | Total: 172\n",
      "[184/306] ✓ Saved: 01421.txt (210 words) | Total: 173\n",
      "[185/306] ✓ Saved: 01422.txt (488 words) | Total: 174\n",
      "[186/306] ✓ Saved: 01423.txt (670 words) | Total: 175\n",
      "[187/306] ✓ Saved: 01424.txt (761 words) | Total: 176\n",
      "[188/306] ✓ Saved: 01425.txt (623 words) | Total: 177\n",
      "[189/306] ✓ Saved: 01426.txt (804 words) | Total: 178\n",
      "[190/306] ✓ Saved: 01427.txt (808 words) | Total: 179\n",
      "[191/306] ✓ Saved: 01428.txt (1761 words) | Total: 180\n",
      "[192/306] ✓ Saved: 01429.txt (859 words) | Total: 181\n",
      "[193/306] ✓ Saved: 01430.txt (748 words) | Total: 182\n",
      "[194/306] ✓ Saved: 01431.txt (346 words) | Total: 183\n",
      "[195/306] ✓ Saved: 01432.txt (1314 words) | Total: 184\n",
      "[196/306] ✓ Saved: 01433.txt (190 words) | Total: 185\n",
      "[197/306] ✓ Saved: 01434.txt (363 words) | Total: 186\n",
      "[198/306] ✓ Saved: 01435.txt (1015 words) | Total: 187\n",
      "[199/306] ✓ Saved: 01436.txt (1066 words) | Total: 188\n",
      "[200/306] ✓ Saved: 01437.txt (414 words) | Total: 189\n",
      "[201/306] ✓ Saved: 01438.txt (513 words) | Total: 190\n",
      "[202/306] ✓ Saved: 01439.txt (351 words) | Total: 191\n",
      "[203/306] ✓ Saved: 01440.txt (589 words) | Total: 192\n",
      "[204/306] ✓ Saved: 01441.txt (625 words) | Total: 193\n",
      "[205/306] ✓ Saved: 01442.txt (663 words) | Total: 194\n",
      "[206/306] ✓ Saved: 01443.txt (2279 words) | Total: 195\n",
      "[207/306] ✓ Saved: 01444.txt (479 words) | Total: 196\n",
      "[208/306] ✓ Saved: 01445.txt (968 words) | Total: 197\n",
      "[209/306] ✓ Saved: 01446.txt (698 words) | Total: 198\n",
      "[210/306] ✓ Saved: 01447.txt (748 words) | Total: 199\n",
      "[211/306] ✓ Saved: 01448.txt (1268 words) | Total: 200\n",
      "[212/306] ✓ Saved: 01449.txt (883 words) | Total: 201\n",
      "[213/306] ✓ Saved: 01450.txt (248 words) | Total: 202\n",
      "[214/306] ✓ Saved: 01451.txt (82 words) | Total: 203\n",
      "[215/306] ✓ Saved: 01452.txt (698 words) | Total: 204\n",
      "[216/306] ✓ Saved: 01453.txt (796 words) | Total: 205\n",
      "[217/306] ✓ Saved: 01454.txt (355 words) | Total: 206\n",
      "[218/306] ✓ Saved: 01455.txt (545 words) | Total: 207\n",
      "[219/306] ✓ Saved: 01456.txt (981 words) | Total: 208\n",
      "[220/306] ✓ Saved: 01457.txt (538 words) | Total: 209\n",
      "[221/306] ✓ Saved: 01458.txt (1081 words) | Total: 210\n",
      "[222/306] ✓ Saved: 01459.txt (181 words) | Total: 211\n",
      "[223/306] ✓ Saved: 01460.txt (328 words) | Total: 212\n",
      "[224/306] ✓ Saved: 01461.txt (457 words) | Total: 213\n",
      "[225/306] ✓ Saved: 01462.txt (300 words) | Total: 214\n",
      "[226/306] ✓ Saved: 01463.txt (156 words) | Total: 215\n",
      "[227/306] ✓ Saved: 01464.txt (500 words) | Total: 216\n",
      "[228/306] ✓ Saved: 01465.txt (490 words) | Total: 217\n",
      "[229/306] ✓ Saved: 01466.txt (508 words) | Total: 218\n",
      "[230/306] ✓ Saved: 01467.txt (344 words) | Total: 219\n",
      "[231/306] ✓ Saved: 01468.txt (541 words) | Total: 220\n",
      "[232/306] ✓ Saved: 01469.txt (739 words) | Total: 221\n",
      "[233/306] ✓ Saved: 01470.txt (862 words) | Total: 222\n",
      "[234/306] ✓ Saved: 01471.txt (657 words) | Total: 223\n",
      "[235/306] ✓ Saved: 01472.txt (797 words) | Total: 224\n",
      "[236/306] ✓ Saved: 01473.txt (451 words) | Total: 225\n",
      "[237/306] ✓ Saved: 01474.txt (146 words) | Total: 226\n",
      "[238/306] ✓ Saved: 01475.txt (585 words) | Total: 227\n",
      "[239/306] ✓ Saved: 01476.txt (308 words) | Total: 228\n",
      "[240/306] ✓ Saved: 01477.txt (81 words) | Total: 229\n",
      "[241/306] ✓ Saved: 01478.txt (520 words) | Total: 230\n",
      "[242/306] ✓ Saved: 01479.txt (517 words) | Total: 231\n",
      "[243/306] ✓ Saved: 01480.txt (368 words) | Total: 232\n",
      "[244/306] ✓ Saved: 01481.txt (388 words) | Total: 233\n",
      "[245/306] ✓ Saved: 01482.txt (241 words) | Total: 234\n",
      "[246/306] ✓ Saved: 01483.txt (286 words) | Total: 235\n",
      "[247/306] ✓ Saved: 01484.txt (451 words) | Total: 236\n",
      "[248/306] ✓ Saved: 01485.txt (465 words) | Total: 237\n",
      "[249/306] ✓ Saved: 01486.txt (482 words) | Total: 238\n",
      "[250/306] ✓ Saved: 01487.txt (1051 words) | Total: 239\n",
      "[251/306] ✓ Saved: 01488.txt (124 words) | Total: 240\n",
      "[252/306] ✓ Saved: 01489.txt (243 words) | Total: 241\n",
      "[253/306] ✓ Saved: 01490.txt (398 words) | Total: 242\n",
      "[254/306] ✓ Saved: 01491.txt (1055 words) | Total: 243\n",
      "[255/306] ✓ Saved: 01492.txt (455 words) | Total: 244\n",
      "[256/306] ✓ Saved: 01493.txt (327 words) | Total: 245\n",
      "[257/306] ✓ Saved: 01494.txt (417 words) | Total: 246\n",
      "[258/306] ✓ Saved: 01495.txt (393 words) | Total: 247\n",
      "[259/306] ✓ Saved: 01496.txt (181 words) | Total: 248\n",
      "[260/306] ✓ Saved: 01497.txt (597 words) | Total: 249\n",
      "[261/306] ✓ Saved: 01498.txt (584 words) | Total: 250\n",
      "[262/306] ✓ Saved: 01499.txt (811 words) | Total: 251\n",
      "[263/306] ✓ Saved: 01500.txt (254 words) | Total: 252\n",
      "[264/306] ✓ Saved: 01501.txt (145 words) | Total: 253\n",
      "[265/306] ✓ Saved: 01502.txt (255 words) | Total: 254\n",
      "[266/306] ✓ Saved: 01503.txt (1071 words) | Total: 255\n",
      "[267/306] ✓ Saved: 01504.txt (1275 words) | Total: 256\n",
      "[268/306] ✓ Saved: 01505.txt (446 words) | Total: 257\n",
      "[269/306] ✓ Saved: 01506.txt (841 words) | Total: 258\n",
      "[270/306] ✓ Saved: 01507.txt (588 words) | Total: 259\n",
      "[271/306] ✓ Saved: 01508.txt (534 words) | Total: 260\n",
      "[272/306] ✓ Saved: 01509.txt (716 words) | Total: 261\n",
      "[273/306] ✓ Saved: 01510.txt (359 words) | Total: 262\n",
      "[274/306] ✓ Saved: 01511.txt (1450 words) | Total: 263\n",
      "[275/306] ✓ Saved: 01512.txt (452 words) | Total: 264\n",
      "[276/306] ✗ Skipped _GVL4gm-Y3I: too short (44 words)\n",
      "[277/306] ✓ Saved: 01513.txt (201 words) | Total: 265\n",
      "[278/306] ✓ Saved: 01514.txt (465 words) | Total: 266\n",
      "[279/306] ✓ Saved: 01515.txt (323 words) | Total: 267\n",
      "[280/306] ✓ Saved: 01516.txt (345 words) | Total: 268\n",
      "[281/306] ✓ Saved: 01517.txt (381 words) | Total: 269\n",
      "[282/306] ✓ Saved: 01518.txt (713 words) | Total: 270\n",
      "[283/306] ✓ Saved: 01519.txt (2416 words) | Total: 271\n",
      "[284/306] ✓ Saved: 01520.txt (127 words) | Total: 272\n",
      "[285/306] ✓ Saved: 01521.txt (227 words) | Total: 273\n",
      "[286/306] ✓ Saved: 01522.txt (191 words) | Total: 274\n",
      "[287/306] ✓ Saved: 01523.txt (199 words) | Total: 275\n",
      "[288/306] ✓ Saved: 01524.txt (261 words) | Total: 276\n",
      "[289/306] ✓ Saved: 01525.txt (302 words) | Total: 277\n",
      "[290/306] ✓ Saved: 01526.txt (417 words) | Total: 278\n",
      "[291/306] ✓ Saved: 01527.txt (285 words) | Total: 279\n",
      "[292/306] ✓ Saved: 01528.txt (118 words) | Total: 280\n",
      "[293/306] ✓ Saved: 01529.txt (673 words) | Total: 281\n",
      "[294/306] ✓ Saved: 01530.txt (127 words) | Total: 282\n",
      "[295/306] ✓ Saved: 01531.txt (345 words) | Total: 283\n",
      "[296/306] ✓ Saved: 01532.txt (168 words) | Total: 284\n",
      "[297/306] ✓ Saved: 01533.txt (843 words) | Total: 285\n",
      "[298/306] ✓ Saved: 01534.txt (141 words) | Total: 286\n",
      "[299/306] ✓ Saved: 01535.txt (145 words) | Total: 287\n",
      "[300/306] ✓ Saved: 01536.txt (666 words) | Total: 288\n",
      "[301/306] ✓ Saved: 01537.txt (1029 words) | Total: 289\n",
      "[302/306] ✓ Saved: 01538.txt (97 words) | Total: 290\n",
      "[303/306] ✓ Saved: 01539.txt (502 words) | Total: 291\n",
      "[304/306] ✓ Saved: 01540.txt (640 words) | Total: 292\n",
      "[305/306] ✓ Saved: 01541.txt (247 words) | Total: 293\n",
      "[306/306] ✓ Saved: 01542.txt (277 words) | Total: 294\n",
      "\n",
      "============================================================\n",
      "Summary for C:\\my_notebook\\eda\\dataset\\productive:\n",
      "  Saved: 294\n",
      "  Skipped: 12\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: UNPRODUCTIVE VIDEOS\n",
      "======================================================================\n",
      "Found 334 unproductive video IDs\n",
      "\n",
      "[1/334] ✓ Saved: 01311.txt (238 words) | Total: 1\n",
      "[2/334] ✓ Saved: 01312.txt (238 words) | Total: 2\n",
      "[3/334] ✓ Saved: 01313.txt (208 words) | Total: 3\n",
      "[4/334] ✓ Saved: 01314.txt (209 words) | Total: 4\n",
      "[5/334] ✓ Saved: 01315.txt (260 words) | Total: 5\n",
      "[6/334] ✓ Saved: 01316.txt (413 words) | Total: 6\n",
      "[7/334] ✓ Saved: 01317.txt (191 words) | Total: 7\n",
      "[8/334] ✓ Saved: 01318.txt (234 words) | Total: 8\n",
      "[9/334] ✓ Saved: 01319.txt (160 words) | Total: 9\n",
      "[10/334] ✓ Saved: 01320.txt (173 words) | Total: 10\n",
      "[11/334] ✓ Saved: 01321.txt (200 words) | Total: 11\n",
      "[12/334] ✓ Saved: 01322.txt (139 words) | Total: 12\n",
      "[13/334] ✓ Saved: 01323.txt (304 words) | Total: 13\n",
      "[14/334] ✓ Saved: 01324.txt (236 words) | Total: 14\n",
      "[15/334] ✓ Saved: 01325.txt (484 words) | Total: 15\n",
      "[16/334] ✓ Saved: 01326.txt (222 words) | Total: 16\n",
      "[17/334] ✓ Saved: 01327.txt (317 words) | Total: 17\n",
      "[18/334] ✓ Saved: 01328.txt (202 words) | Total: 18\n",
      "[19/334] ✓ Saved: 01329.txt (267 words) | Total: 19\n",
      "[20/334] ✓ Saved: 01330.txt (343 words) | Total: 20\n",
      "[21/334] ✓ Saved: 01331.txt (154 words) | Total: 21\n",
      "[22/334] ✓ Saved: 01332.txt (199 words) | Total: 22\n",
      "[23/334] ✓ Saved: 01333.txt (149 words) | Total: 23\n",
      "[24/334] ✓ Saved: 01334.txt (137 words) | Total: 24\n",
      "[25/334] ✓ Saved: 01335.txt (138 words) | Total: 25\n",
      "[26/334] ✓ Saved: 01336.txt (321 words) | Total: 26\n",
      "[27/334] ✓ Saved: 01337.txt (197 words) | Total: 27\n",
      "[28/334] ✓ Saved: 01338.txt (166 words) | Total: 28\n",
      "[29/334] ✓ Saved: 01339.txt (139 words) | Total: 29\n",
      "[30/334] ✓ Saved: 01340.txt (78 words) | Total: 30\n",
      "[31/334] ✓ Saved: 01341.txt (183 words) | Total: 31\n",
      "[32/334] ✓ Saved: 01342.txt (269 words) | Total: 32\n",
      "[33/334] ✓ Saved: 01343.txt (199 words) | Total: 33\n",
      "[34/334] ✓ Saved: 01344.txt (172 words) | Total: 34\n",
      "[35/334] ✓ Saved: 01345.txt (179 words) | Total: 35\n",
      "[36/334] ✓ Saved: 01346.txt (170 words) | Total: 36\n",
      "[37/334] ✓ Saved: 01347.txt (206 words) | Total: 37\n",
      "[38/334] ✓ Saved: 01348.txt (201 words) | Total: 38\n",
      "[39/334] ✓ Saved: 01349.txt (136 words) | Total: 39\n",
      "[40/334] ✓ Saved: 01350.txt (181 words) | Total: 40\n",
      "[41/334] ✓ Saved: 01351.txt (188 words) | Total: 41\n",
      "[42/334] ✓ Saved: 01352.txt (97 words) | Total: 42\n",
      "[43/334] ✓ Saved: 01353.txt (233 words) | Total: 43\n",
      "[44/334] ✓ Saved: 01354.txt (372 words) | Total: 44\n",
      "[45/334] ✓ Saved: 01355.txt (310 words) | Total: 45\n",
      "[46/334] ✓ Saved: 01356.txt (291 words) | Total: 46\n",
      "[47/334] ✓ Saved: 01357.txt (949 words) | Total: 47\n",
      "[48/334] ✓ Saved: 01358.txt (112 words) | Total: 48\n",
      "[49/334] ✓ Saved: 01359.txt (130 words) | Total: 49\n",
      "[50/334] ✗ Skipped RpymQTlt2Dg: too short (17 words)\n",
      "[51/334] ✓ Saved: 01360.txt (613 words) | Total: 50\n",
      "[52/334] ✓ Saved: 01361.txt (411 words) | Total: 51\n",
      "[53/334] ✓ Saved: 01362.txt (465 words) | Total: 52\n",
      "[54/334] ✓ Saved: 01363.txt (204 words) | Total: 53\n",
      "[55/334] ✓ Saved: 01364.txt (216 words) | Total: 54\n",
      "[56/334] ✓ Saved: 01365.txt (126 words) | Total: 55\n",
      "[57/334] ✗ Skipped 3y8l4hxsZNY: too short (47 words)\n",
      "[58/334] ✓ Saved: 01366.txt (98 words) | Total: 56\n",
      "[59/334] ✓ Saved: 01367.txt (689 words) | Total: 57\n",
      "[60/334] ✓ Saved: 01368.txt (110 words) | Total: 58\n",
      "[61/334] ✓ Saved: 01369.txt (109 words) | Total: 59\n",
      "[62/334] ✓ Saved: 01370.txt (419 words) | Total: 60\n",
      "[63/334] ✓ Saved: 01371.txt (590 words) | Total: 61\n",
      "[64/334] ✓ Saved: 01372.txt (172 words) | Total: 62\n",
      "[65/334] ✓ Saved: 01373.txt (495 words) | Total: 63\n",
      "[66/334] ✓ Saved: 01374.txt (472 words) | Total: 64\n",
      "[67/334] ✗ Skipped ySns2JZEG-g: too short (42 words)\n",
      "[68/334] ✓ Saved: 01375.txt (166 words) | Total: 65\n",
      "[69/334] ✓ Saved: 01376.txt (61 words) | Total: 66\n",
      "[70/334] ✓ Saved: 01377.txt (160 words) | Total: 67\n",
      "[71/334] ✓ Saved: 01378.txt (639 words) | Total: 68\n",
      "[72/334] ✓ Saved: 01379.txt (155 words) | Total: 69\n",
      "[73/334] ✓ Saved: 01380.txt (373 words) | Total: 70\n",
      "[74/334] ✓ Saved: 01381.txt (146 words) | Total: 71\n",
      "[75/334] ✓ Saved: 01382.txt (174 words) | Total: 72\n",
      "[76/334] ✓ Saved: 01383.txt (351 words) | Total: 73\n",
      "[77/334] ✓ Saved: 01384.txt (96 words) | Total: 74\n",
      "[78/334] ✓ Saved: 01385.txt (162 words) | Total: 75\n",
      "[79/334] ✓ Saved: 01386.txt (245 words) | Total: 76\n",
      "[80/334] ✓ Saved: 01387.txt (139 words) | Total: 77\n",
      "[81/334] ✓ Saved: 01388.txt (429 words) | Total: 78\n",
      "[82/334] ✓ Saved: 01389.txt (777 words) | Total: 79\n",
      "[83/334] ✓ Saved: 01390.txt (210 words) | Total: 80\n",
      "[84/334] ✓ Saved: 01391.txt (250 words) | Total: 81\n",
      "[85/334] ✓ Saved: 01392.txt (257 words) | Total: 82\n",
      "[86/334] ✓ Saved: 01393.txt (335 words) | Total: 83\n",
      "[87/334] ✓ Saved: 01394.txt (410 words) | Total: 84\n",
      "[88/334] ✓ Saved: 01395.txt (264 words) | Total: 85\n",
      "[89/334] ✓ Saved: 01396.txt (159 words) | Total: 86\n",
      "[90/334] ✓ Saved: 01397.txt (152 words) | Total: 87\n",
      "[91/334] ✓ Saved: 01398.txt (1092 words) | Total: 88\n",
      "[92/334] ✓ Saved: 01399.txt (123 words) | Total: 89\n",
      "[93/334] ✓ Saved: 01400.txt (138 words) | Total: 90\n",
      "[94/334] ✓ Saved: 01401.txt (209 words) | Total: 91\n",
      "[95/334] ✓ Saved: 01402.txt (554 words) | Total: 92\n",
      "[96/334] ✓ Saved: 01403.txt (93 words) | Total: 93\n",
      "[97/334] ✓ Saved: 01404.txt (245 words) | Total: 94\n",
      "[98/334] ✓ Saved: 01405.txt (415 words) | Total: 95\n",
      "[99/334] ✓ Saved: 01406.txt (633 words) | Total: 96\n",
      "[100/334] ✓ Saved: 01407.txt (98 words) | Total: 97\n",
      "[101/334] ✓ Saved: 01408.txt (241 words) | Total: 98\n",
      "[102/334] ✓ Saved: 01409.txt (331 words) | Total: 99\n",
      "[103/334] ✗ Skipped ntDShIEGQhQ: too short (27 words)\n",
      "[104/334] ✓ Saved: 01410.txt (340 words) | Total: 100\n",
      "[105/334] ✓ Saved: 01411.txt (189 words) | Total: 101\n",
      "[106/334] ✓ Saved: 01412.txt (375 words) | Total: 102\n",
      "[107/334] ✓ Saved: 01413.txt (371 words) | Total: 103\n",
      "[108/334] ✓ Saved: 01414.txt (167 words) | Total: 104\n",
      "[109/334] ✓ Saved: 01415.txt (236 words) | Total: 105\n",
      "[110/334] ✓ Saved: 01416.txt (419 words) | Total: 106\n",
      "[111/334] ✓ Saved: 01417.txt (356 words) | Total: 107\n",
      "[112/334] ✓ Saved: 01418.txt (113 words) | Total: 108\n",
      "[113/334] ✓ Saved: 01419.txt (206 words) | Total: 109\n",
      "[114/334] ✓ Saved: 01420.txt (354 words) | Total: 110\n",
      "[115/334] ✓ Saved: 01421.txt (238 words) | Total: 111\n",
      "[116/334] ✓ Saved: 01422.txt (102 words) | Total: 112\n",
      "[117/334] ✓ Saved: 01423.txt (199 words) | Total: 113\n",
      "[118/334] ✓ Saved: 01424.txt (266 words) | Total: 114\n",
      "[119/334] ✓ Saved: 01425.txt (337 words) | Total: 115\n",
      "[120/334] ✓ Saved: 01426.txt (214 words) | Total: 116\n",
      "[121/334] ✓ Saved: 01427.txt (190 words) | Total: 117\n",
      "[122/334] ✓ Saved: 01428.txt (81 words) | Total: 118\n",
      "[123/334] ✓ Saved: 01429.txt (205 words) | Total: 119\n",
      "[124/334] ✓ Saved: 01430.txt (340 words) | Total: 120\n",
      "[125/334] ✓ Saved: 01431.txt (190 words) | Total: 121\n",
      "[126/334] ✓ Saved: 01432.txt (296 words) | Total: 122\n",
      "[127/334] ✓ Saved: 01433.txt (144 words) | Total: 123\n",
      "[128/334] ✓ Saved: 01434.txt (361 words) | Total: 124\n",
      "[129/334] ✓ Saved: 01435.txt (449 words) | Total: 125\n",
      "[130/334] ✓ Saved: 01436.txt (258 words) | Total: 126\n",
      "[131/334] ✓ Saved: 01437.txt (236 words) | Total: 127\n",
      "[132/334] ✓ Saved: 01438.txt (186 words) | Total: 128\n",
      "[133/334] ✓ Saved: 01439.txt (194 words) | Total: 129\n",
      "[134/334] ✓ Saved: 01440.txt (179 words) | Total: 130\n",
      "[135/334] ✓ Saved: 01441.txt (565 words) | Total: 131\n",
      "[136/334] ✓ Saved: 01442.txt (403 words) | Total: 132\n",
      "[137/334] ✓ Saved: 01443.txt (425 words) | Total: 133\n",
      "[138/334] ✓ Saved: 01444.txt (264 words) | Total: 134\n",
      "[139/334] ✓ Saved: 01445.txt (238 words) | Total: 135\n",
      "[140/334] ✓ Saved: 01446.txt (267 words) | Total: 136\n",
      "[141/334] ✓ Saved: 01447.txt (242 words) | Total: 137\n",
      "[142/334] ✓ Saved: 01448.txt (424 words) | Total: 138\n",
      "[143/334] ✓ Saved: 01449.txt (309 words) | Total: 139\n",
      "[144/334] ✓ Saved: 01450.txt (248 words) | Total: 140\n",
      "[145/334] ✓ Saved: 01451.txt (166 words) | Total: 141\n",
      "[146/334] ✓ Saved: 01452.txt (316 words) | Total: 142\n",
      "[147/334] ✓ Saved: 01453.txt (181 words) | Total: 143\n",
      "[148/334] ✓ Saved: 01454.txt (325 words) | Total: 144\n",
      "[149/334] ✓ Saved: 01455.txt (254 words) | Total: 145\n",
      "[150/334] ✓ Saved: 01456.txt (213 words) | Total: 146\n",
      "[151/334] ✓ Saved: 01457.txt (509 words) | Total: 147\n",
      "[152/334] ✓ Saved: 01458.txt (388 words) | Total: 148\n",
      "[153/334] ✓ Saved: 01459.txt (297 words) | Total: 149\n",
      "[154/334] ✓ Saved: 01460.txt (850 words) | Total: 150\n",
      "[155/334] ✓ Saved: 01461.txt (134 words) | Total: 151\n",
      "[156/334] ✓ Saved: 01462.txt (158 words) | Total: 152\n",
      "[157/334] ✓ Saved: 01463.txt (168 words) | Total: 153\n",
      "[158/334] ✓ Saved: 01464.txt (166 words) | Total: 154\n",
      "[159/334] ✓ Saved: 01465.txt (194 words) | Total: 155\n",
      "[160/334] ✓ Saved: 01466.txt (213 words) | Total: 156\n",
      "[161/334] ✓ Saved: 01467.txt (210 words) | Total: 157\n",
      "[162/334] ✓ Saved: 01468.txt (242 words) | Total: 158\n",
      "[163/334] ✓ Saved: 01469.txt (75 words) | Total: 159\n",
      "[164/334] ✓ Saved: 01470.txt (100 words) | Total: 160\n",
      "[165/334] ✓ Saved: 01471.txt (161 words) | Total: 161\n",
      "[166/334] ✓ Saved: 01472.txt (189 words) | Total: 162\n",
      "[167/334] ✓ Saved: 01473.txt (266 words) | Total: 163\n",
      "[168/334] ✓ Saved: 01474.txt (166 words) | Total: 164\n",
      "[169/334] ✓ Saved: 01475.txt (50 words) | Total: 165\n",
      "[170/334] ✓ Saved: 01476.txt (81 words) | Total: 166\n",
      "[171/334] ✓ Saved: 01477.txt (176 words) | Total: 167\n",
      "[172/334] ✓ Saved: 01478.txt (123 words) | Total: 168\n",
      "[173/334] ✓ Saved: 01479.txt (168 words) | Total: 169\n",
      "[174/334] ✓ Saved: 01480.txt (315 words) | Total: 170\n",
      "[175/334] ✗ Skipped 96DmtEn4vco: too short (33 words)\n",
      "[176/334] ✓ Saved: 01481.txt (120 words) | Total: 171\n",
      "[177/334] ✓ Saved: 01482.txt (132 words) | Total: 172\n",
      "[178/334] ✓ Saved: 01483.txt (429 words) | Total: 173\n",
      "[179/334] ✓ Saved: 01484.txt (876 words) | Total: 174\n",
      "[180/334] ✓ Saved: 01485.txt (132 words) | Total: 175\n",
      "[181/334] ✓ Saved: 01486.txt (216 words) | Total: 176\n",
      "[182/334] ✓ Saved: 01487.txt (150 words) | Total: 177\n",
      "[183/334] ✓ Saved: 01488.txt (228 words) | Total: 178\n",
      "[184/334] ✓ Saved: 01489.txt (190 words) | Total: 179\n",
      "[185/334] ✓ Saved: 01490.txt (57 words) | Total: 180\n",
      "[186/334] ✓ Saved: 01491.txt (202 words) | Total: 181\n",
      "[187/334] ✓ Saved: 01492.txt (382 words) | Total: 182\n",
      "[188/334] ✓ Saved: 01493.txt (204 words) | Total: 183\n",
      "[189/334] ✓ Saved: 01494.txt (352 words) | Total: 184\n",
      "[190/334] ✓ Saved: 01495.txt (237 words) | Total: 185\n",
      "[191/334] ✓ Saved: 01496.txt (189 words) | Total: 186\n",
      "[192/334] ✓ Saved: 01497.txt (122 words) | Total: 187\n",
      "[193/334] ✓ Saved: 01498.txt (236 words) | Total: 188\n",
      "[194/334] ✓ Saved: 01499.txt (510 words) | Total: 189\n",
      "[195/334] ✓ Saved: 01500.txt (704 words) | Total: 190\n",
      "[196/334] ✓ Saved: 01501.txt (141 words) | Total: 191\n",
      "[197/334] ✓ Saved: 01502.txt (242 words) | Total: 192\n",
      "[198/334] ✓ Saved: 01503.txt (231 words) | Total: 193\n",
      "[199/334] ✓ Saved: 01504.txt (245 words) | Total: 194\n",
      "[200/334] ✓ Saved: 01505.txt (114 words) | Total: 195\n",
      "[201/334] ✓ Saved: 01506.txt (208 words) | Total: 196\n",
      "[202/334] ✓ Saved: 01507.txt (285 words) | Total: 197\n",
      "[203/334] ✓ Saved: 01508.txt (156 words) | Total: 198\n",
      "[204/334] ✓ Saved: 01509.txt (123 words) | Total: 199\n",
      "[205/334] ✓ Saved: 01510.txt (317 words) | Total: 200\n",
      "[206/334] ✓ Saved: 01511.txt (69 words) | Total: 201\n",
      "[207/334] ✓ Saved: 01512.txt (370 words) | Total: 202\n",
      "[208/334] ✓ Saved: 01513.txt (200 words) | Total: 203\n",
      "[209/334] ✓ Saved: 01514.txt (214 words) | Total: 204\n",
      "[210/334] ✓ Saved: 01515.txt (632 words) | Total: 205\n",
      "[211/334] ✓ Saved: 01516.txt (146 words) | Total: 206\n",
      "[212/334] ✗ Skipped k4Lu0xaKTTE: too short (29 words)\n",
      "[213/334] ✓ Saved: 01517.txt (249 words) | Total: 207\n",
      "[214/334] ✓ Saved: 01518.txt (327 words) | Total: 208\n",
      "[215/334] ✓ Saved: 01519.txt (119 words) | Total: 209\n",
      "[216/334] ✓ Saved: 01520.txt (108 words) | Total: 210\n",
      "[217/334] ✗ Skipped _nuRo2z12dw: too short (48 words)\n",
      "[218/334] ✓ Saved: 01521.txt (147 words) | Total: 211\n",
      "[219/334] ✓ Saved: 01522.txt (56 words) | Total: 212\n",
      "[220/334] ✗ Skipped OuGFj8EIRHA: too short (2 words)\n",
      "[221/334] ✗ Skipped Juk1g7F-A1o: too short (14 words)\n",
      "[222/334] ✓ Saved: 01523.txt (72 words) | Total: 213\n",
      "[223/334] ✓ Saved: 01524.txt (176 words) | Total: 214\n",
      "[224/334] ✓ Saved: 01525.txt (239 words) | Total: 215\n",
      "[225/334] ✓ Saved: 01526.txt (590 words) | Total: 216\n",
      "[226/334] ✓ Saved: 01527.txt (251 words) | Total: 217\n",
      "[227/334] ✗ Skipped AjOSJHO8STg: too short (10 words)\n",
      "[228/334] ✓ Saved: 01528.txt (148 words) | Total: 218\n",
      "[229/334] ✓ Saved: 01529.txt (129 words) | Total: 219\n",
      "[230/334] ✓ Saved: 01530.txt (174 words) | Total: 220\n",
      "[231/334] ✓ Saved: 01531.txt (150 words) | Total: 221\n",
      "[232/334] ✓ Saved: 01532.txt (156 words) | Total: 222\n",
      "[233/334] ✓ Saved: 01533.txt (132 words) | Total: 223\n",
      "[234/334] ✗ Skipped KIvyaG5wx7w: too short (20 words)\n",
      "[235/334] ✓ Saved: 01534.txt (139 words) | Total: 224\n",
      "[236/334] ✓ Saved: 01535.txt (203 words) | Total: 225\n",
      "[237/334] ✓ Saved: 01536.txt (238 words) | Total: 226\n",
      "[238/334] ✓ Saved: 01537.txt (325 words) | Total: 227\n",
      "[239/334] ✓ Saved: 01538.txt (371 words) | Total: 228\n",
      "[240/334] ✓ Saved: 01539.txt (262 words) | Total: 229\n",
      "[241/334] ✓ Saved: 01540.txt (231 words) | Total: 230\n",
      "[242/334] ✓ Saved: 01541.txt (157 words) | Total: 231\n",
      "[243/334] ✓ Saved: 01542.txt (205 words) | Total: 232\n",
      "[244/334] ✓ Saved: 01543.txt (128 words) | Total: 233\n",
      "[245/334] ✓ Saved: 01544.txt (197 words) | Total: 234\n",
      "[246/334] ✓ Saved: 01545.txt (166 words) | Total: 235\n",
      "[247/334] ✓ Saved: 01546.txt (955 words) | Total: 236\n",
      "[248/334] ✓ Saved: 01547.txt (158 words) | Total: 237\n",
      "[249/334] ✓ Saved: 01548.txt (362 words) | Total: 238\n",
      "[250/334] ✓ Saved: 01549.txt (164 words) | Total: 239\n",
      "[251/334] ✓ Saved: 01550.txt (224 words) | Total: 240\n",
      "[252/334] ✓ Saved: 01551.txt (80 words) | Total: 241\n",
      "[253/334] ✓ Saved: 01552.txt (300 words) | Total: 242\n",
      "[254/334] ✓ Saved: 01553.txt (283 words) | Total: 243\n",
      "[255/334] ✓ Saved: 01554.txt (322 words) | Total: 244\n",
      "[256/334] ✓ Saved: 01555.txt (159 words) | Total: 245\n",
      "[257/334] ✓ Saved: 01556.txt (300 words) | Total: 246\n",
      "[258/334] ✓ Saved: 01557.txt (273 words) | Total: 247\n",
      "[259/334] ✓ Saved: 01558.txt (240 words) | Total: 248\n",
      "[260/334] ✓ Saved: 01559.txt (255 words) | Total: 249\n",
      "[261/334] ✓ Saved: 01560.txt (233 words) | Total: 250\n",
      "[262/334] ✓ Saved: 01561.txt (220 words) | Total: 251\n",
      "[263/334] ✓ Saved: 01562.txt (243 words) | Total: 252\n",
      "[264/334] ✓ Saved: 01563.txt (234 words) | Total: 253\n",
      "[265/334] ✓ Saved: 01564.txt (183 words) | Total: 254\n",
      "[266/334] ✓ Saved: 01565.txt (195 words) | Total: 255\n",
      "[267/334] ✓ Saved: 01566.txt (228 words) | Total: 256\n",
      "[268/334] ✓ Saved: 01567.txt (288 words) | Total: 257\n",
      "[269/334] ✓ Saved: 01568.txt (205 words) | Total: 258\n",
      "[270/334] ✓ Saved: 01569.txt (175 words) | Total: 259\n",
      "[271/334] ✓ Saved: 01570.txt (200 words) | Total: 260\n",
      "[272/334] ✓ Saved: 01571.txt (216 words) | Total: 261\n",
      "[273/334] ✓ Saved: 01572.txt (214 words) | Total: 262\n",
      "[274/334] ✓ Saved: 01573.txt (202 words) | Total: 263\n",
      "[275/334] ✓ Saved: 01574.txt (179 words) | Total: 264\n",
      "[276/334] ✓ Saved: 01575.txt (246 words) | Total: 265\n",
      "[277/334] ✓ Saved: 01576.txt (206 words) | Total: 266\n",
      "[278/334] ✓ Saved: 01577.txt (276 words) | Total: 267\n",
      "[279/334] ✓ Saved: 01578.txt (170 words) | Total: 268\n",
      "[280/334] ✓ Saved: 01579.txt (213 words) | Total: 269\n",
      "[281/334] ✓ Saved: 01580.txt (212 words) | Total: 270\n",
      "[282/334] ✓ Saved: 01581.txt (199 words) | Total: 271\n",
      "[283/334] ✓ Saved: 01582.txt (131 words) | Total: 272\n",
      "[284/334] ✓ Saved: 01583.txt (348 words) | Total: 273\n",
      "[285/334] ✓ Saved: 01584.txt (465 words) | Total: 274\n",
      "[286/334] ✓ Saved: 01585.txt (366 words) | Total: 275\n",
      "[287/334] ✓ Saved: 01586.txt (123 words) | Total: 276\n",
      "[288/334] ✓ Saved: 01587.txt (220 words) | Total: 277\n",
      "[289/334] ✓ Saved: 01588.txt (687 words) | Total: 278\n",
      "[290/334] ✓ Saved: 01589.txt (81 words) | Total: 279\n",
      "[291/334] ✓ Saved: 01590.txt (208 words) | Total: 280\n",
      "[292/334] ✓ Saved: 01591.txt (307 words) | Total: 281\n",
      "[293/334] ✓ Saved: 01592.txt (238 words) | Total: 282\n",
      "[294/334] ✓ Saved: 01593.txt (407 words) | Total: 283\n",
      "[295/334] ✓ Saved: 01594.txt (542 words) | Total: 284\n",
      "[296/334] ✓ Saved: 01595.txt (795 words) | Total: 285\n",
      "[297/334] ✓ Saved: 01596.txt (234 words) | Total: 286\n",
      "[298/334] ✓ Saved: 01597.txt (391 words) | Total: 287\n",
      "[299/334] ✓ Saved: 01598.txt (170 words) | Total: 288\n",
      "[300/334] ✓ Saved: 01599.txt (582 words) | Total: 289\n",
      "[301/334] ✓ Saved: 01600.txt (268 words) | Total: 290\n",
      "[302/334] ✓ Saved: 01601.txt (272 words) | Total: 291\n",
      "[303/334] ✓ Saved: 01602.txt (206 words) | Total: 292\n",
      "[304/334] ✓ Saved: 01603.txt (235 words) | Total: 293\n",
      "[305/334] ✓ Saved: 01604.txt (875 words) | Total: 294\n",
      "[306/334] ✓ Saved: 01605.txt (248 words) | Total: 295\n",
      "[307/334] ✓ Saved: 01606.txt (497 words) | Total: 296\n",
      "[308/334] ✓ Saved: 01607.txt (1045 words) | Total: 297\n",
      "[309/334] ✓ Saved: 01608.txt (163 words) | Total: 298\n",
      "[310/334] ✓ Saved: 01609.txt (175 words) | Total: 299\n",
      "[311/334] ✓ Saved: 01610.txt (561 words) | Total: 300\n",
      "[312/334] ✓ Saved: 01611.txt (463 words) | Total: 301\n",
      "[313/334] ✓ Saved: 01612.txt (345 words) | Total: 302\n",
      "[314/334] ✓ Saved: 01613.txt (537 words) | Total: 303\n",
      "[315/334] ✓ Saved: 01614.txt (353 words) | Total: 304\n",
      "[316/334] ✓ Saved: 01615.txt (543 words) | Total: 305\n",
      "[317/334] ✓ Saved: 01616.txt (210 words) | Total: 306\n",
      "[318/334] ✓ Saved: 01617.txt (349 words) | Total: 307\n",
      "[319/334] ✓ Saved: 01618.txt (197 words) | Total: 308\n",
      "[320/334] ✓ Saved: 01619.txt (470 words) | Total: 309\n",
      "[321/334] ✓ Saved: 01620.txt (249 words) | Total: 310\n",
      "[322/334] ✓ Saved: 01621.txt (251 words) | Total: 311\n",
      "[323/334] ✓ Saved: 01622.txt (188 words) | Total: 312\n",
      "[324/334] ✓ Saved: 01623.txt (210 words) | Total: 313\n",
      "[325/334] ✓ Saved: 01624.txt (164 words) | Total: 314\n",
      "[326/334] ✓ Saved: 01625.txt (113 words) | Total: 315\n",
      "[327/334] ✓ Saved: 01626.txt (145 words) | Total: 316\n",
      "[328/334] ✓ Saved: 01627.txt (711 words) | Total: 317\n",
      "[329/334] ✓ Saved: 01628.txt (230 words) | Total: 318\n",
      "[330/334] ✓ Saved: 01629.txt (689 words) | Total: 319\n",
      "[331/334] ✓ Saved: 01630.txt (382 words) | Total: 320\n",
      "[332/334] ✓ Saved: 01631.txt (195 words) | Total: 321\n",
      "[333/334] ✓ Saved: 01632.txt (250 words) | Total: 322\n",
      "[334/334] ✓ Saved: 01633.txt (251 words) | Total: 323\n",
      "\n",
      "============================================================\n",
      "Summary for C:\\my_notebook\\eda\\dataset\\unproductive:\n",
      "  Saved: 323\n",
      "  Skipped: 11\n",
      "============================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "======================================================================\n",
      "Productive samples: 1542 (added 294)\n",
      "Unproductive samples: 1633 (added 323)\n",
      "Total samples: 3175\n",
      "======================================================================\n",
      "\n",
      "✓ Done! Dataset updated with YouTube metadata.\n",
      "Each file contains: Title + Description + Top Comments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googleapiclient.discovery import build\n",
    "import time\n",
    "import json\n",
    "\n",
    "# =====================\n",
    "# CONFIGURATION\n",
    "# =====================\n",
    "API_KEY = \"AIzaSyAMCAkxznT5CGZTQkKVyT84I1yA_2VTlbc\"\n",
    "SEARCH_QUERY_PRODUCTIVE = [\"tutorial\", \"educational\", \"python programming\", \"machine learning\", \n",
    "                           \"data science tutorial\", \"coding tutorial\", \"math lecture\"]\n",
    "SEARCH_QUERY_UNPRODUCTIVE = [\"funny\", \"entertainment\", \"gaming\", \"memes\", \"funny videos\", \n",
    "                             \"comedy\", \"pranks\", \"vlog\"]\n",
    "VIDEOS_PER_CLASS = 500\n",
    "PRODUCTIVE_PATH = r\"C:\\my_notebook\\eda\\dataset\\productive\"\n",
    "UNPRODUCTIVE_PATH = r\"C:\\my_notebook\\eda\\dataset\\unproductive\"\n",
    "\n",
    "os.makedirs(PRODUCTIVE_PATH, exist_ok=True)\n",
    "os.makedirs(UNPRODUCTIVE_PATH, exist_ok=True)\n",
    "\n",
    "# =====================\n",
    "# HELPER FUNCTIONS\n",
    "# =====================\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing excessive whitespace.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_next_index(folder):\n",
    "    \"\"\"Get next available sequential index in folder\"\"\"\n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".txt\")]\n",
    "    if not files: \n",
    "        return 1\n",
    "    indices = [int(f.split(\".\")[0]) for f in files if f.split(\".\")[0].isdigit()]\n",
    "    return max(indices) + 1 if indices else 1\n",
    "\n",
    "def save_text(text, folder, idx):\n",
    "    \"\"\"Save text to folder with sequential numbering\"\"\"\n",
    "    filename = os.path.join(folder, f\"{idx:05d}.txt\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# =====================\n",
    "# YOUTUBE API FUNCTIONS\n",
    "# =====================\n",
    "def search_youtube(query_list, max_results):\n",
    "    \"\"\"Search YouTube using API and return video IDs\"\"\"\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "    video_ids = []\n",
    "    \n",
    "    for q in query_list:\n",
    "        try:\n",
    "            request = youtube.search().list(\n",
    "                q=q,\n",
    "                part=\"id\",\n",
    "                type=\"video\",\n",
    "                maxResults=50,\n",
    "                relevanceLanguage=\"en\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            for item in response.get(\"items\", []):\n",
    "                vid_id = item[\"id\"][\"videoId\"]\n",
    "                if vid_id not in video_ids:\n",
    "                    video_ids.append(vid_id)\n",
    "                    \n",
    "                if len(video_ids) >= max_results:\n",
    "                    return video_ids\n",
    "                    \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Search error for '{q}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    return video_ids\n",
    "\n",
    "def get_video_metadata_api(video_id):\n",
    "    \"\"\"Get video title and description using YouTube API\"\"\"\n",
    "    try:\n",
    "        youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        if not response.get('items'):\n",
    "            return None, None\n",
    "        \n",
    "        snippet = response['items'][0]['snippet']\n",
    "        title = snippet.get('title', '')\n",
    "        description = snippet.get('description', '')\n",
    "        \n",
    "        return title, description\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "def get_video_comments_api(video_id, max_comments=20):\n",
    "    \"\"\"Get video comments using YouTube API\"\"\"\n",
    "    try:\n",
    "        youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=max_comments,\n",
    "            textFormat=\"plainText\",\n",
    "            order=\"relevance\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        comments = []\n",
    "        for item in response.get('items', []):\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "        \n",
    "        return comments\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# =====================\n",
    "# SCRAPING WITH HTML (BACKUP METHOD)\n",
    "# =====================\n",
    "def get_video_metadata_html(video_id):\n",
    "    \"\"\"Scrape video title and description from HTML (backup method)\"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept-Language': 'en-US,en;q=0.9'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None, None\n",
    "        \n",
    "        html = response.text\n",
    "        \n",
    "        # Extract title\n",
    "        title_match = re.search(r'\"title\":\"(.*?)\"', html)\n",
    "        title = title_match.group(1) if title_match else \"\"\n",
    "        \n",
    "        # Extract description\n",
    "        desc_match = re.search(r'\"shortDescription\":\"(.*?)\"', html)\n",
    "        description = desc_match.group(1) if desc_match else \"\"\n",
    "        \n",
    "        # Unescape unicode\n",
    "        title = title.encode().decode('unicode_escape')\n",
    "        description = description.encode().decode('unicode_escape')\n",
    "        \n",
    "        return title, description\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# =====================\n",
    "# COMBINED SCRAPER\n",
    "# =====================\n",
    "def scrape_video_content(video_id, use_api=True):\n",
    "    \"\"\"\n",
    "    Get video title, description, and comments.\n",
    "    Combines all text into one document.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if use_api:\n",
    "            # Try API first (more reliable)\n",
    "            title, description = get_video_metadata_api(video_id)\n",
    "            comments = get_video_comments_api(video_id, max_comments=20)\n",
    "        else:\n",
    "            # Fallback to HTML scraping\n",
    "            title, description = get_video_metadata_html(video_id)\n",
    "            comments = []\n",
    "        \n",
    "        if not title and not description:\n",
    "            return None\n",
    "        \n",
    "        # Combine all text\n",
    "        full_text = f\"{title}. {description}\"\n",
    "        \n",
    "        if comments:\n",
    "            comments_text = \" \".join(comments[:20])  # Top 20 comments\n",
    "            full_text += f\". Comments: {comments_text}\"\n",
    "        \n",
    "        full_text = clean_text(full_text)\n",
    "        \n",
    "        return full_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def fetch_youtube_metadata(video_ids, folder, use_api=True):\n",
    "    \"\"\"Fetch metadata from YouTube videos and save them\"\"\"\n",
    "    idx = get_next_index(folder)\n",
    "    saved_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for i, vid in enumerate(video_ids, 1):\n",
    "        try:\n",
    "            text = scrape_video_content(vid, use_api=use_api)\n",
    "            \n",
    "            if text is None:\n",
    "                print(f\"[{i}/{len(video_ids)}] ✗ Failed {vid}: No metadata available\")\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "            \n",
    "            word_count = len(text.split())\n",
    "            \n",
    "            if word_count >= 50:\n",
    "                save_text(text, folder, idx)\n",
    "                print(f\"[{i}/{len(video_ids)}] ✓ Saved: {idx:05d}.txt ({word_count} words) | Total: {saved_count + 1}\")\n",
    "                idx += 1\n",
    "                saved_count += 1\n",
    "            else:\n",
    "                print(f\"[{i}/{len(video_ids)}] ✗ Skipped {vid}: too short ({word_count} words)\")\n",
    "                skipped_count += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)[:60]\n",
    "            print(f\"[{i}/{len(video_ids)}] ✗ Failed {vid}: {error_msg}\")\n",
    "            skipped_count += 1\n",
    "        \n",
    "        # Delay to respect rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Summary for {folder}:\")\n",
    "    print(f\"  Saved: {saved_count}\")\n",
    "    print(f\"  Skipped: {skipped_count}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return saved_count\n",
    "\n",
    "# =====================\n",
    "# MAIN SCRIPT\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"YOUTUBE METADATA SCRAPER\")\n",
    "    print(\"(Title + Description + Comments)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get current counts\n",
    "    current_prod = len([f for f in os.listdir(PRODUCTIVE_PATH) if f.endswith('.txt')])\n",
    "    current_unprod = len([f for f in os.listdir(UNPRODUCTIVE_PATH) if f.endswith('.txt')])\n",
    "    \n",
    "    print(f\"\\nCurrent productive samples: {current_prod}\")\n",
    "    print(f\"Current unproductive samples: {current_unprod}\")\n",
    "    print(f\"Target per class: {VIDEOS_PER_CLASS} videos\\n\")\n",
    "    \n",
    "    # Choose method\n",
    "    print(\"Method: Using YouTube Data API (more reliable)\")\n",
    "    print(\"Includes: Title + Description + Top 20 Comments\\n\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # PRODUCTIVE VIDEOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PHASE 1: PRODUCTIVE VIDEOS\")\n",
    "    print(\"=\"*70)\n",
    "    prod_video_ids = search_youtube(SEARCH_QUERY_PRODUCTIVE, VIDEOS_PER_CLASS)\n",
    "    print(f\"Found {len(prod_video_ids)} productive video IDs\\n\")\n",
    "    \n",
    "    prod_saved = fetch_youtube_metadata(prod_video_ids, PRODUCTIVE_PATH, use_api=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # UNPRODUCTIVE VIDEOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PHASE 2: UNPRODUCTIVE VIDEOS\")\n",
    "    print(\"=\"*70)\n",
    "    unprod_video_ids = search_youtube(SEARCH_QUERY_UNPRODUCTIVE, VIDEOS_PER_CLASS)\n",
    "    print(f\"Found {len(unprod_video_ids)} unproductive video IDs\\n\")\n",
    "    \n",
    "    unprod_saved = fetch_youtube_metadata(unprod_video_ids, UNPRODUCTIVE_PATH, use_api=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # ========================================================================\n",
    "    \n",
    "    final_prod = len([f for f in os.listdir(PRODUCTIVE_PATH) if f.endswith('.txt')])\n",
    "    final_unprod = len([f for f in os.listdir(UNPRODUCTIVE_PATH) if f.endswith('.txt')])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL DATASET SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Productive samples: {final_prod} (added {prod_saved})\")\n",
    "    print(f\"Unproductive samples: {final_unprod} (added {unprod_saved})\")\n",
    "    print(f\"Total samples: {final_prod + final_unprod}\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n✓ Done! Dataset updated with YouTube metadata.\")\n",
    "    print(\"Each file contains: Title + Description + Top Comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59f48f-14d8-49e4-a8cc-55b6d7d79572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6272a21-98f4-4c5f-ac1f-ca5e5b1fc3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
